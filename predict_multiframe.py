import pandas as pd
import joblib
import argparse
import os
# from features import compute_features  # –≠—Ç–æ—Ç –∏–º–ø–æ—Ä—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ —Ñ–∞–π–ª–∞ features.py
# from utils import load_latest_data    # –≠—Ç–æ—Ç –∏–º–ø–æ—Ä—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ —Ñ–∞–π–ª–∞ utils.py
from datetime import datetime
import sys  # –î–ª—è Ctrl+C
import logging

# –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ compute_features –µ—Å—Ç—å –≤ preprocess_features.py
# –ù–æ –µ–≥–æ –Ω—É–∂–Ω–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –æ–¥–Ω–∏–º DataFrame –Ω–∞ –≤—Ö–æ–¥–µ
# –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã, —ç—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –æ—Å—Ç–∞–µ—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å, —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º, —á—Ç–æ –æ–Ω –º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å "–∏–∑ –∫–æ—Ä–æ–±–∫–∏"
# –±–µ–∑ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ compute_features –∏–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —ç—Ç–∏—Ö –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –º–æ–¥—É–ª–µ–π.

logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s [MultiFrame] - %(message)s',
                    stream=sys.stdout)

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ===
TIMEFRAMES_MULTI = ['1m', '5m', '15m', '30m', '1h', '4h', '1d']  # –°–≤–æ–π —Å–ø–∏—Å–æ–∫ –¢–§
MODEL_DIR_MULTI = 'models'  # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—É –∂–µ –ø–∞–ø–∫—É –º–æ–¥–µ–ª–µ–π


# DATA_DIR_MULTI = 'data_binance' # –≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –æ–∂–∏–¥–∞–µ—Ç CSV –≤ —ç—Ç–æ–π –ø–∞–ø–∫–µ
# –≠—Ç–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç SQLite –∏ data/features_*.pkl
# –î–ª—è —Ä–∞–±–æ—Ç—ã —ç—Ç–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞ –Ω—É–∂–Ω–æ, —á—Ç–æ–±—ã data_binance/{symbol}/{tf}.csv —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–∏.
# –ò compute_features –±—ã–ª –¥–æ—Å—Ç—É–ø–µ–Ω –∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω.

# –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è compute_features, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω –æ—Ç–¥–µ–ª—å–Ω–æ
def compute_features_stub(df_input):
    logging.warning("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ó–ê–ì–õ–£–®–ö–ê –¥–ª—è compute_features. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã!")
    # –ü—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–ª–æ–Ω–æ–∫, —á—Ç–æ–±—ã –∫–æ–¥ –Ω–µ –ø–∞–¥–∞–ª
    df_input['rsi_stub'] = 50
    df_input['delta_stub'] = 0.01
    df_input['vol_stub'] = 0.02
    # –í–∞–∂–Ω–æ: –º–æ–¥–µ–ª–∏ –æ–±—É—á–∞–ª–∏—Å—å –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    # –≠—Ç–∞ –∑–∞–≥–ª—É—à–∫–∞ –Ω–µ —Å–æ–∑–¥–∞—Å—Ç –∏—Ö, –ø–æ—ç—Ç–æ–º—É predict —É–ø–∞–¥–µ—Ç, –µ—Å–ª–∏ –º–æ–¥–µ–ª–∏ –æ–∂–∏–¥–∞—é—Ç –¥—Ä—É–≥–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.
    # –ß—Ç–æ–±—ã —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–ª–æ, –Ω—É–∂–Ω–æ –ª–∏–±–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å X –∏–∑ features_*.pkl, –ª–∏–±–æ –∏–º–µ—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π compute_features.
    return df_input.iloc[-1:]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è


def predict_one_tf(symbol_arg, tf_arg):  # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω—ã –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    logging.info(f"–ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è {symbol_arg} –Ω–∞ {tf_arg}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–µ–π
    model_clf_path = f"{MODEL_DIR_MULTI}/{tf_arg}_clf_class.pkl"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º _clf_class
    model_delta_path = f"{MODEL_DIR_MULTI}/{tf_arg}_reg_delta.pkl"
    model_vol_path = f"{MODEL_DIR_MULTI}/{tf_arg}_reg_vol.pkl"

    if not all(os.path.exists(p) for p in [model_clf_path, model_delta_path, model_vol_path]):
        logging.error(f"–û–¥–Ω–∞ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è {tf_arg} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–ø—É—Å–∫.")
        return None

    model_clf = joblib.load(model_clf_path)
    model_delta = joblib.load(model_delta_path)
    model_vol = joblib.load(model_vol_path)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (—ç—Ç–æ—Ç –ø—É—Ç—å –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞)
    # path_csv = f"{DATA_DIR_MULTI}/{symbol_arg}/{tf_arg}.csv"
    # if not os.path.exists(path_csv):
    #     logging.error(f"CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path_csv}. –ü—Ä–æ–ø—É—Å–∫ {tf_arg} –¥–ª—è {symbol_arg}.")
    #     return None
    # df_raw = pd.read_csv(path_csv)
    # df_raw['timestamp'] = pd.to_datetime(df_raw['timestamp'], unit='ms') # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —Ç–∞–∫–æ–π —Ñ–æ—Ä–º–∞—Ç
    # df_raw.set_index('timestamp', inplace=True)

    # –í–º–µ—Å—Ç–æ —á—Ç–µ–Ω–∏—è CSV –∏ compute_features, –ø–æ–ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –≥–æ—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ data/features_TF.pkl
    features_pkl_path = f"data/features_{tf_arg}.pkl"
    if not os.path.exists(features_pkl_path):
        logging.error(f"–§–∞–π–ª –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ {features_pkl_path} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–ø—É—Å–∫ {tf_arg} –¥–ª—è {symbol_arg}.")
        return None

    try:
        df_all_features = pd.read_pickle(features_pkl_path)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {features_pkl_path}: {e}")
        return None

    df_sym_features = df_all_features[df_all_features['symbol'] == symbol_arg].sort_values('timestamp')
    if df_sym_features.empty:
        logging.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö/–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {symbol_arg} –≤ {features_pkl_path}. –ü—Ä–æ–ø—É—Å–∫ {tf_arg}.")
        return None

    last_row_features = df_sym_features.iloc[-1:].copy()

    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –æ–±—É—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å
    features_list_path = f"models/{tf_arg}_features.txt"
    if not os.path.exists(features_list_path):
        logging.error(f"–§–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ 'models/{tf_arg}_features.txt' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–ø—É—Å–∫.")
        return None
    try:
        with open(features_list_path, "r", encoding="utf-8") as f:
            feature_cols_model = [line.strip() for line in f if line.strip()]
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Å–æ —Å–ø–∏—Å–∫–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
        return None

    if not feature_cols_model:
        logging.error("–°–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞ –ø—É—Å—Ç.")
        return None

    missing_cols = [col for col in feature_cols_model if col not in last_row_features.columns]
    if missing_cols:
        logging.error(f"–í –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol_arg} {tf_arg} –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏: {missing_cols}")
        return None

    X_predict = last_row_features[feature_cols_model]
    if X_predict.isnull().values.any():
        logging.warning(f"NaN –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –¥–ª—è {symbol_arg} {tf_arg}. –†–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–º.")
        # X_predict = X_predict.fillna(0) # –ü—Ä–æ—Å—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

    # df_with_features = compute_features_stub(df_raw) # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É –∏–ª–∏ —Ä–µ–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
    # df_with_features.dropna(inplace=True) # –£–¥–∞–ª–µ–Ω–∏–µ NaN –ø–æ—Å–ª–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    # if df_with_features.empty:
    #     logging.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ compute_features –¥–ª—è {symbol_arg} {tf_arg}.")
    #     return None
    # last_features = df_with_features.iloc[[-1]] # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏

    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –º–æ–¥–µ–ª–∏ –æ–∂–∏–¥–∞—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Å compute_features_stub –∏–ª–∏ —Ä–µ–∞–ª—å–Ω–æ–π
    # –í–∞–∂–Ω–æ: –µ—Å–ª–∏ –º–æ–¥–µ–ª–∏ –æ–±—É—á–∞–ª–∏—Å—å –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –∏–∑ preprocess_features.py, —Ç–æ X_predict –¥–æ–ª–∂–µ–Ω –∏—Ö —Å–æ–¥–µ—Ä–∂–∞—Ç—å.
    try:
        proba_all = model_clf.predict_proba(X_predict)[0]
        # TARGET_CLASS_NAMES_MULTI = ['STRONG DOWN', 'DOWN', 'NEUTRAL', 'UP', 'STRONG UP']
        # prob_up = proba_all[TARGET_CLASS_NAMES_MULTI.index('UP')] + proba_all[TARGET_CLASS_NAMES_MULTI.index('STRONG UP')]
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã, –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ, –Ω–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–≤–µ—Ä–Ω–æ –¥–ª—è clf_class
        prob_up = proba_all[3] + proba_all[4] if len(proba_all) == 5 else proba_all[1]

        delta = model_delta.predict(X_predict)[0]
        vol = model_vol.predict(X_predict)[0]
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è {symbol_arg} {tf_arg}: {e}")
        # logging.debug(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {X_predict.columns.tolist()}")
        return None

    momentum = delta / vol if vol > 1e-9 else 0  # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å

    # –õ–æ–≥–∏–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞, –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
    signal_text = "LONG" if prob_up > 0.7 and delta > 0.002 else \
        "SHORT" if prob_up < 0.3 and delta < -0.002 else "NEUTRAL"
    # –ü–æ—Ä–æ–≥–∏ (0.7, 0.3, 0.002) —Å—Ç–æ–∏—Ç —Å–¥–µ–ª–∞—Ç—å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º–∏ –∏–ª–∏ –æ–±–æ—Å–Ω–æ–≤–∞—Ç—å

    return {
        'timeframe': tf_arg,
        'prob_up_pct': round(prob_up * 100, 2),  # prob_up —ç—Ç–æ —É–∂–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        'delta_pct': round(delta * 100, 2),  # delta —ç—Ç–æ —É–∂–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤ –¥–æ–ª—è—Ö
        'volatility_pct': round(vol * 100, 2),  # vol —ç—Ç–æ —É–∂–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤ –¥–æ–ª—è—Ö
        'momentum': round(momentum, 2),
        'signal': signal_text
    }


def summarize_results(results_list):  # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–æ
    if not results_list:
        return "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è."

    long_count = sum(1 for r in results_list if r and r['signal'].startswith('LONG'))
    short_count = sum(1 for r in results_list if r and r['signal'].startswith('SHORT'))

    if long_count >= 3:  # –ü–æ—Ä–æ–≥ –¥–ª—è –æ–±—â–µ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
        return 'üìà  –ò—Ç–æ–≥–æ–≤—ã–π —Ç—Ä–µ–Ω–¥: –í–í–ï–†–•'
    elif short_count >= 3:
        return 'üìâ  –ò—Ç–æ–≥–æ–≤—ã–π —Ç—Ä–µ–Ω–¥: –í–ù–ò–ó'
    else:
        return '‚öñÔ∏è  –ò—Ç–æ–≥–æ–≤—ã–π —Ç—Ä–µ–Ω–¥: –ù–ï–ô–¢–†–ê–õ–¨–ù–û'


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–ú—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º–æ–≤—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞.")
    parser.add_argument("--symbol", type=str, required=True, help="–°–∏–º–≤–æ–ª –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, BTCUSDT)")
    args = parser.parse_args()
    symbol_main = args.symbol.upper()

    print(f"\n--- –ú—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º-–ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è {symbol_main} ---")
    all_results = []

    try:
        for tf_main in TIMEFRAMES_MULTI:
            try:
                result_one = predict_one_tf(symbol_main, tf_main)
                if result_one:
                    all_results.append(result_one)
                    print(f"  {result_one['timeframe']:>4s} | {result_one['signal']:<7s} | "
                          f"P(Up): {result_one['prob_up_pct']:>6.2f}% | "
                          f"Œî: {result_one['delta_pct']:>6.2f}% | "
                          f"œÉ: {result_one['volatility_pct']:>6.2f}% | "
                          f"Mom: {result_one['momentum']:>5.2f}")
            except Exception as e_inner:  # –õ–æ–≤–∏–º –æ—à–∏–±–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ –¢–§, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞—Ç—å –≤–µ—Å—å —Ü–∏–∫–ª
                logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {tf_main} –¥–ª—è {symbol_main}: {e_inner}")

        print("\n" + summarize_results(all_results))

    except KeyboardInterrupt:
        print("\n[MultiFrame] üõë –ü—Ä–æ–≥–Ω–æ–∑ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C).")
        sys.exit(130)
    except Exception as e_outer:
        logging.error(f"[MultiFrame] üí• –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e_outer}", exc_info=True)
        sys.exit(1)

    print("--- –ú—É–ª—å—Ç–∏—Ñ—Ä–µ–π–º-–ø—Ä–æ–≥–Ω–æ–∑ –∑–∞–≤–µ—Ä—à—ë–Ω ---")