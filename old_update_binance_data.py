import requests
import sqlite3
import time
from datetime import datetime, timezone
import os
import argparse
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
import sys  # –î–ª—è sys.exit –ø—Ä–∏ Ctrl+C

# –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –¥–∞–Ω–Ω—ã—Ö (update_log.txt) –∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
os.makedirs('data', exist_ok=True)
os.makedirs('database', exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s ‚Äî %(message)s',
    handlers=[
        logging.FileHandler("data/update_log.txt", encoding='utf-8'),  # –õ–æ–≥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –æ—Å—Ç–∞–µ—Ç—Å—è –≤ data
        logging.StreamHandler()
    ]
)

CORE_SYMBOLS = [

    'ETHUSDT', 'SOLUSDT', 'BNBUSDT', 'BCHUSDT', 'LTCUSDT',
    'BTCUSDT', 'ADAUSDT', 'AVAXUSDT', 'DOTUSDT', 'XRPUSDT',
    'MATICUSDT', 'LINKUSDT', 'NEARUSDT', 'ATOMUSDT', 'TRXUSDT'
]

TIMEFRAMES = {

    '5m': '5m',
    '15m': '15m',
    '30m': '30m',
    '1h': '1h',  
    '4h': '4h',
    '1d': '1d'
}

DB_PATH = 'database/market_data.db'  # –ò–ó–ú–ï–ù–ï–ù–û
BINANCE_URL = 'https://api.binance.com/api/v3/klines'
MAX_CANDLES_PER_SYMBOL = 100000
DEFAULT_START_DATE_MS = int(
    datetime(2017, 8, 17, tzinfo=timezone.utc).timestamp() * 1000)  # Binance launch date for many pairs


def get_valid_symbols():
    url = 'https://api.binance.com/api/v3/exchangeInfo'
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        symbols = {s['symbol'] for s in data['symbols'] if s['quoteAsset'] == 'USDT' and s['status'] == 'TRADING'}
        logging.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(symbols)} –∞–∫—Ç–∏–≤–Ω—ã—Ö USDT —Å–∏–º–≤–æ–ª–æ–≤ —Å Binance.")
        return symbols
    except requests.exceptions.RequestException as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤: {e}")
        return set()
    except Exception as e:
        logging.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤: {e}")
        return set()


def get_tf_ms(tf_key):
    mult = {'m': 60, 'h': 3600, 'd': 86400}
    num_str = ''.join(filter(str.isdigit, tf_key))
    if not num_str:
        logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ –∏–∑ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞: {tf_key}")
        return 0
    num = int(num_str)
    unit = ''.join(filter(str.isalpha, tf_key))
    if unit not in mult:
        logging.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –µ–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤ —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ: {tf_key}")
        return 0
    return num * mult[unit] * 1000


def init_db():
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    for tf_val in TIMEFRAMES:
        cursor.execute(f'''
            CREATE TABLE IF NOT EXISTS candles_{tf_val} (
                symbol TEXT,
                timestamp INTEGER,
                open REAL,
                high REAL,
                low REAL,
                close REAL,
                volume REAL,
                PRIMARY KEY (symbol, timestamp)
            )
        ''')
    conn.commit()
    conn.close()
    logging.info(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö '{DB_PATH}' –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞/–ø—Ä–æ–≤–µ—Ä–µ–Ω–∞.")


def fetch_klines(symbol, interval_str, start_time=None, retries=3, delay=5):
    params = {
        'symbol': symbol,
        'interval': interval_str,
        'limit': 1000  # Binance API limit per request
    }
    if start_time:
        params['startTime'] = start_time

    for attempt in range(retries):
        try:
            # logging.debug(f"–ó–∞–ø—Ä–æ—Å: {BINANCE_URL} —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ {params}")
            response = requests.get(BINANCE_URL, params=params, timeout=15)  # –£–≤–µ–ª–∏—á–∏–ª —Ç–∞–π–º–∞—É—Ç

            if response.status_code == 429 or \
                    (response.status_code == 418 and "Too many requests" in response.text):
                ban_duration = 60
                try:
                    # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –≤—Ä–µ–º—è –±–∞–Ω–∞ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ Retry-After
                    retry_after = int(response.headers.get("Retry-After", ban_duration))
                    ban_duration = max(retry_after, ban_duration)  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ–µ –∏–∑ –¥–≤—É—Ö
                except (ValueError, TypeError):
                    pass  # –ò—Å–ø–æ–ª—å–∑—É–µ–º ban_duration –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                logging.warning(
                    f"[{symbol}-{interval_str}] –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (HTTP {response.status_code}) ‚Äî –ø–∞—É–∑–∞ {ban_duration} —Å–µ–∫—É–Ω–¥")
                time.sleep(ban_duration)
                continue  # –ü–æ–≤—Ç–æ—Ä—è–µ–º —Ç–æ—Ç –∂–µ –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ –ø–∞—É–∑—ã

            response.raise_for_status()  # –í—ã–∑–æ–≤–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è 4xx/5xx –æ—à–∏–±–æ–∫, –∫—Ä–æ–º–µ 429/418
            return response.json()

        except requests.exceptions.HTTPError as http_err:
            logging.warning(
                f"[{symbol}-{interval_str}] HTTP –æ—à–∏–±–∫–∞: {http_err} - {response.text if response else 'No response object'}")
        except requests.exceptions.RequestException as e:  # ConnectionError, Timeout, etc.
            logging.warning(f"[{symbol}-{interval_str}] –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")

        if attempt < retries - 1:
            current_delay = delay * (attempt + 1)
            logging.info(
                f"[{symbol}-{interval_str}] –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {current_delay} —Å–µ–∫. ({attempt + 2}/{retries})")
            time.sleep(current_delay)
        else:
            logging.error(f"[{symbol}-{interval_str}] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ {retries} –ø–æ–ø—ã—Ç–æ–∫.")
    return []


def insert_klines(conn, tf_key, symbol, klines):
    cursor = conn.cursor()
    count = 0
    start_ts_val = None
    end_ts_val = None

    if klines:
        start_ts_val = int(klines[0][0])
        end_ts_val = int(klines[-1][0])

        for k in klines:
            try:
                cursor.execute(f'''
                    INSERT OR IGNORE INTO candles_{tf_key}
                    (symbol, timestamp, open, high, low, close, volume)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (symbol, int(k[0]), float(k[1]), float(k[2]), float(k[3]), float(k[4]), float(k[5])))
                if cursor.rowcount > 0:
                    count += 1
            except sqlite3.Error as e:  # –ë–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è SQLite
                logging.error(
                    f"–û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏ SQLite –¥–ª—è {symbol} –≤ {datetime.fromtimestamp(int(k[0]) / 1000, timezone.utc)}: {e}")
            except Exception as e:
                logging.error(
                    f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏ –¥–ª—è {symbol} –≤ {datetime.fromtimestamp(int(k[0]) / 1000, timezone.utc)}: {e}")
    conn.commit()
    return count, start_ts_val, end_ts_val


def get_last_timestamp(conn, tf_key, symbol):
    cursor = conn.cursor()
    try:
        cursor.execute(f"SELECT MAX(timestamp) FROM candles_{tf_key} WHERE symbol = ?", (symbol,))
        row = cursor.fetchone()
        return row[0] if row and row[0] else None
    except sqlite3.Error as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è MAX(timestamp) –¥–ª—è {symbol} [{tf_key}]: {e}")
        return None


def process_symbol_for_tf(symbol, tf_key, interval_str, step_ms, db_path_local, pbar_instance=None):
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –≤ –∫–∞–∂–¥–æ–º –ø–æ—Ç–æ–∫–µ
    # –°–æ–∑–¥–∞–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ç–æ–∫–∞
    conn_local = sqlite3.connect(db_path_local, timeout=60)
    downloaded_for_symbol = 0

    try:
        last_ts = get_last_timestamp(conn_local, tf_key, symbol)
        next_ts = (last_ts + step_ms) if last_ts else DEFAULT_START_DATE_MS

        # logging.info(f"–î–ª—è {symbol} [{tf_key}]: last_ts={last_ts}, next_ts={datetime.fromtimestamp(next_ts/1000, timezone.utc)}")

        while downloaded_for_symbol < MAX_CANDLES_PER_SYMBOL:
            if next_ts >= int(datetime.now(timezone.utc).timestamp() * 1000):  # –ù–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –±—É–¥—É—â–µ–≥–æ
                logging.info(f"{symbol} [{tf_key}] –¥–æ—Å—Ç–∏–≥–Ω—É—Ç—ã —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ.")
                break

            klines = fetch_klines(symbol, interval_str, next_ts)
            if not klines:
                # logging.info(f"{symbol} [{tf_key}] ‚Äî Binance –Ω–µ –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã–µ –¥–ª—è {datetime.fromtimestamp(next_ts / 1000, timezone.utc)} –∏–ª–∏ API limit.")
                break  # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ –¥–ª—è —ç—Ç–æ–≥–æ —Å–∏–º–≤–æ–ª–∞

            rows_inserted, _, _ = insert_klines(conn_local, tf_key, symbol, klines)
            downloaded_for_symbol += rows_inserted

            if pbar_instance and rows_inserted > 0:
                pbar_instance.update(rows_inserted)
            # elif pbar_instance and not rows_inserted and klines: # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –¥–∞–∂–µ –µ—Å–ª–∏ —Å–≤–µ—á–∏ —É–∂–µ –±—ã–ª–∏
            #      pbar_instance.update(len(klines))

            if len(klines) < 1000:  # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –º–µ–Ω—å—à–µ, —á–µ–º –∑–∞–ø—Ä–∞—à–∏–≤–∞–ª–∏, –∑–Ω–∞—á–∏—Ç, —ç—Ç–æ –∫–æ–Ω–µ—Ü –∏—Å—Ç–æ—Ä–∏–∏
                logging.info(f"{symbol} [{tf_key}] –ø–æ–ª—É—á–µ–Ω–æ {len(klines)} —Å–≤–µ—á–µ–π, –≤–µ—Ä–æ—è—Ç–Ω–æ, –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –∫–æ–Ω–µ—Ü –∏—Å—Ç–æ—Ä–∏–∏.")
                break

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å timestamp –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–≤–µ—á–∏
            if not klines[-1] or not str(klines[-1][0]).isdigit():
                logging.error(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π timestamp –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–≤–µ—á–µ –¥–ª—è {symbol} [{tf_key}]: {klines[-1]}")
                break

            next_ts = int(klines[-1][0]) + step_ms
            time.sleep(0.2)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞

        if downloaded_for_symbol > 0:
            logging.info(f"{symbol} [{tf_key}] ‚Äî –ó–∞–≥—Ä—É–∂–µ–Ω–æ {downloaded_for_symbol} –Ω–æ–≤—ã—Ö —Å–≤–µ—á–µ–π.")
        return downloaded_for_symbol
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ {symbol} [{tf_key}] –≤ –ø–æ—Ç–æ–∫–µ: {e}", exc_info=True)
        return 0  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º 0 –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    finally:
        conn_local.close()


def update_timeframe_parallel(tf_key):
    logging.info(f"[Old Update] ‚è≥  –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞: {tf_key}")
    if tf_key not in TIMEFRAMES:
        logging.error(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º: {tf_key}")
        return

    init_db()  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ë–î –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —Ä–∞–±–æ—Ç—ã —Å —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–º

    step_ms = get_tf_ms(tf_key)
    if step_ms == 0:
        return
    interval_str = TIMEFRAMES[tf_key]

    valid_binance_symbols = get_valid_symbols()
    if not valid_binance_symbols:
        logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–∞–ª–∏–¥–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã Binance. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ.")
        return

    active_symbols = [s for s in CORE_SYMBOLS if s in valid_binance_symbols]
    if not active_symbols:
        logging.info(f"–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ CORE_SYMBOLS –¥–ª—è {tf_key}.")
        return

    logging.info(f"–ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(active_symbols)} —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è {tf_key}: {', '.join(active_symbols[:5])}...")

    total_downloaded_for_tf = 0
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º ThreadPoolExecutor –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
    # max_workers=5 —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å API Binance –∏ –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã
    with ThreadPoolExecutor(max_workers=5) as executor, \
            tqdm(total=len(active_symbols) * MAX_CANDLES_PER_SYMBOL,  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª—è tqdm
                 desc=f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ {tf_key}", unit=" —Å–≤–µ—á–µ–π", mininterval=1.0) as pbar:

        futures = {executor.submit(process_symbol_for_tf, symbol, tf_key, interval_str, step_ms, DB_PATH, pbar): symbol
                   for symbol in active_symbols}

        for future in as_completed(futures):
            symbol = futures[future]
            try:
                downloaded_count = future.result()
                total_downloaded_for_tf += downloaded_count
                # pbar.set_postfix_str(f"{symbol} done") # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º —Å–∏–º–≤–æ–ª–µ
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ –¥–ª—è —Å–∏–º–≤–æ–ª–∞ {symbol} [{tf_key}]: {e}")

    logging.info(
        f"[Old Update] ‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {tf_key} –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í—Å–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {total_downloaded_for_tf} —Å–≤–µ—á–µ–π.")


def update_single_symbol_tf(symbol_to_update, tf_key_to_update):
    logging.info(f"[Old Update] ‚è≥ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞/—Ç–∞–π–º—Ñ—Ä–µ–π–º–∞: {symbol_to_update} [{tf_key_to_update}]")
    if tf_key_to_update not in TIMEFRAMES:
        logging.error(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º: {tf_key_to_update}")
        return

    symbol_to_update = symbol_to_update.upper()
    valid_binance_symbols = get_valid_symbols()
    if not valid_binance_symbols:
        logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–∞–ª–∏–¥–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ –ø—Ä–µ—Ä–≤–∞–Ω–æ.")
        return
    if symbol_to_update not in valid_binance_symbols:
        logging.error(f"–°–∏–º–≤–æ–ª {symbol_to_update} –Ω–µ —Ç–æ—Ä–≥—É–µ—Ç—Å—è –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–µ–Ω –Ω–∞ Binance (USDT).")
        return

    init_db()
    step_ms = get_tf_ms(tf_key_to_update)
    if step_ms == 0: return
    interval_str = TIMEFRAMES[tf_key_to_update]

    # –î–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ –Ω–µ—Ç —Å–º—ã—Å–ª–∞ –≤ ThreadPoolExecutor, –¥–µ–ª–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º tqdm –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–≤–µ—á–µ–π –¥–ª—è —ç—Ç–æ–≥–æ –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
    with tqdm(total=MAX_CANDLES_PER_SYMBOL, desc=f"–ó–∞–≥—Ä—É–∑–∫–∞ {symbol_to_update} [{tf_key_to_update}]", unit=" —Å–≤–µ—á–µ–π",
              mininterval=1.0) as pbar_single:
        downloaded_count = process_symbol_for_tf(symbol_to_update, tf_key_to_update, interval_str, step_ms, DB_PATH,
                                                 pbar_single)

    logging.info(
        f"[Old Update] ‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ {symbol_to_update} [{tf_key_to_update}] –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {downloaded_count} —Å–≤–µ—á–µ–π.")


def update_all_tf_sequentially():
    logging.info("[Old Update] ‚è≥ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤...")
    init_db()
    # –ù–µ—Ç —Å–º—ã—Å–ª–∞ –ø–æ–ª—É—á–∞—Ç—å valid_binance_symbols –∑–¥–µ—Å—å, —Ç–∞–∫ –∫–∞–∫ update_timeframe_parallel —Å–¥–µ–ª–∞–µ—Ç —ç—Ç–æ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ TF
    for tf_key_loop in TIMEFRAMES.keys():
        # –í–º–µ—Å—Ç–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–∏ –∑–¥–µ—Å—å, –≤—ã–∑—ã–≤–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¢–§
        update_timeframe_parallel(tf_key_loop)
    logging.info("[Old Update] ‚úÖ –ü–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="–ó–∞–≥—Ä—É–∑—á–∏–∫ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö Binance Klines.")
    parser.add_argument('--symbol', type=str, help='–°–∏–º–≤–æ–ª –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä: BTCUSDT)')
    parser.add_argument('--tf', type=str, choices=TIMEFRAMES.keys(), help='–¢–∞–π–º—Ñ—Ä–µ–π–º (–Ω–∞–ø—Ä–∏–º–µ—Ä: 15m)')
    parser.add_argument('--all', action='store_true',
                        help='–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤—Å–µ—Ö CORE_SYMBOLS –∏ –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –ø–æ —Å–∏–º–≤–æ–ª–∞–º –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ –¢–§)')
    parser.add_argument('--sequential-all-tf', action='store_true',
                        help='–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è –∫–∞–∂–¥—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (–Ω–æ —Å–∏–º–≤–æ–ª—ã –≤–Ω—É—Ç—Ä–∏ –¢–§ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)')

    args = parser.parse_args()
    print(f"–ó–∞–ø—É—Å–∫ old_update_binance_data.py —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏: {args}")

    try:
        if args.all:
            logging.info("–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (–≤—Å–µ CORE_SYMBOLS, –≤—Å–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã).")
            # update_all_tf_sequentially() # –°—Ç–∞—Ä—ã–π –≤–∞—Ä–∏–∞–Ω—Ç - —Ç–µ–ø–µ—Ä—å update_timeframe_parallel –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–∏–º–≤–æ–ª—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            for tf_key_main in TIMEFRAMES.keys():
                update_timeframe_parallel(tf_key_main)


        elif args.symbol and args.tf:
            logging.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ {args.symbol} –∏ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {args.tf}")
            update_single_symbol_tf(args.symbol, args.tf)

        elif args.tf:  # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Ç–æ–ª—å–∫–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º, –æ–±–Ω–æ–≤–ª—è–µ–º –≤—Å–µ CORE_SYMBOLS –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            logging.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Å–µ—Ö CORE_SYMBOLS –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º—É {args.tf}")
            update_timeframe_parallel(args.tf)

        elif args.sequential_all_tf:  # –û—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–ª–∞–≥ –¥–ª—è —ç—Ç–æ–π –ª–æ–≥–∏–∫–∏
            logging.info(
                "–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –ø–æ –¢–§, –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –ø–æ —Å–∏–º–≤–æ–ª–∞–º –≤–Ω—É—Ç—Ä–∏ –¢–§)")
            update_all_tf_sequentially()

        elif args.symbol:
            logging.warning(f"–£–∫–∞–∑–∞–Ω —Å–∏–º–≤–æ–ª '{args.symbol}', –Ω–æ –Ω–µ —É–∫–∞–∑–∞–Ω —Ç–∞–π–º—Ñ—Ä–µ–π–º. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --tf.")
            logging.info(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã: {', '.join(TIMEFRAMES.keys())}")

        else:
            parser.print_help()
            logging.warning(
                "–ù–µ —É–∫–∞–∑–∞–Ω—ã –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --all, –∏–ª–∏ --symbol/--tf, –∏–ª–∏ --tf, –∏–ª–∏ --help.")

    except KeyboardInterrupt:
        print("\n[Old Update] üõë –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C).")
        sys.exit(130)
    except Exception as e:
        logging.error(f"[Old Update] üí• –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        sys.exit(1)
    print("–†–∞–±–æ—Ç–∞ —Å–∫—Ä–∏–ø—Ç–∞ old_update_binance_data.py –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")