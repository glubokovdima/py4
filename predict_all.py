import pandas as pd
import joblib
import os
from datetime import datetime
from tabulate import tabulate
import argparse
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler
import numpy as np
import sys  # –î–ª—è Ctrl+C
import logging  # –î–ª—è –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è


# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —ç—Ç–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞ (–º–æ–∂–Ω–æ –≤—ã–≤–æ–¥–∏—Ç—å –≤ —Ñ–∞–π–ª –∏–ª–∏ —Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Å–æ–ª—å)
logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s [PredictAll] - %(message)s',
                    stream=sys.stdout)

# –°–ª–æ–≤–∞—Ä—å –≥—Ä—É–ø–ø: —Å–∏–º–≤–æ–ª—ã —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω—ã –ø–æ–¥ –∏–º–µ–Ω–µ–º (–∫–ª—é—á–æ–º)
# >>> –î–û–ë–ê–í–õ–ï–ù–û/–û–ë–ù–û–í–õ–ï–ù–û —Å–æ–≥–ª–∞—Å–Ω–æ –ø–∞—Ç—á—É
GROUP_MODELS = {
    "top8": [
        "BTCUSDT", "ETHUSDT", "BNBUSDT", "SOLUSDT",
        "XRPUSDT", "ADAUSDT", "LINKUSDT", "AVAXUSDT"
    ],
    "meme": [
        "PEPEUSDT", "DOGEUSDT", "FLOKIUSDT", "WIFUSDT", "SHIBUSDT"
    ],
    # –î–æ–±–∞–≤—å—Ç–µ —Å—é–¥–∞ –¥—Ä—É–≥–∏–µ –≥—Ä—É–ø–ø—ã –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    "defi": [
        # –ü—Ä–∏–º–µ—Ä: "UNIUSDT", "AAVEUSDT", ...
    ]
}

def load_model_with_fallback(symbol, tf, model_type):
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å:
    1. –ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å: models/BTCUSDT_15m_clf_class.pkl
    2. –ì—Ä—É–ø–ø–æ–≤—É—é –º–æ–¥–µ–ª—å: models/top8_15m_clf_class.pkl (–µ—Å–ª–∏ symbol –≤—Ö–æ–¥–∏—Ç –≤ –≥—Ä—É–ø–ø—É)
    3. –û–±—â—É—é –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º—É: models/15m_clf_class.pkl
    """
    # 1. –ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
    symbol_model_path = f"models/{symbol}_{tf}_{model_type}.pkl"
    if os.path.exists(symbol_model_path):
        # print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è {symbol}: {model_type}") # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª print, –ø–µ—Ä–µ–∫–ª—é—á—É –Ω–∞ logging
        logging.debug(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è {symbol}: {model_type}")
        try:
            return joblib.load(symbol_model_path)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ {symbol_model_path}: {e}")
            # Fallback to next option

    # 2. –ì—Ä—É–ø–ø–æ–≤–∞—è –º–æ–¥–µ–ª—å
    for group_name, symbol_list in GROUP_MODELS.items():
        if symbol in symbol_list:
            group_model_path = f"models/{group_name}_{tf}_{model_type}.pkl"
            if os.path.exists(group_model_path):
                # print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≥—Ä—É–ø–ø–æ–≤–∞—è –º–æ–¥–µ–ª—å ({group_name}) –¥–ª—è {symbol}: {model_type}") # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª print, –ø–µ—Ä–µ–∫–ª—é—á—É –Ω–∞ logging
                logging.debug(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≥—Ä—É–ø–ø–æ–≤–∞—è –º–æ–¥–µ–ª—å ({group_name}) –¥–ª—è {symbol}: {model_type}")
                try:
                    return joblib.load(group_model_path)
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≥—Ä—É–ø–ø–æ–≤–æ–π –º–æ–¥–µ–ª–∏ {group_model_path}: {e}")
                    # Fallback to next option
                # Found group model, no need to check other groups for this symbol
                break # Exit the group loop

    # 3. –û–±—â–∞—è –º–æ–¥–µ–ª—å
    default_model_path = f"models/{tf}_{model_type}.pkl"
    if os.path.exists(default_model_path):
        # print(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–±—â–∞—è –º–æ–¥–µ–ª—å –ø–æ TF: {model_type} ‚Üí {default_model_path}") # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª print, –ø–µ—Ä–µ–∫–ª—é—á—É –Ω–∞ logging
        logging.debug(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–±—â–∞—è –º–æ–¥–µ–ª—å –ø–æ TF: {model_type} ‚Üí {default_model_path}")
        try:
            return joblib.load(default_model_path)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ–±—â–µ–π –º–æ–¥–µ–ª–∏ {default_model_path}: {e}")
            return None

    # print(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∏ –¥–ª—è —Å–∏–º–≤–æ–ª–∞ {symbol}, –Ω–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã, –Ω–∏ –æ–±—â–∞—è: {model_type}") # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª print, –ø–µ—Ä–µ–∫–ª—é—á—É –Ω–∞ logging
    logging.warning(f"‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∏ –¥–ª—è —Å–∏–º–≤–æ–ª–∞ {symbol}, –Ω–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã, –Ω–∏ –æ–±—â–∞—è: {model_type} –Ω–∞ {tf}")
    return None

# –£–¥–∞–ª–∏–ª —Å—Ç–∞—Ä—É—é –¥—É–±–ª–∏—Ä—É—é—â—É—é—Å—è —Ñ—É–Ω–∫—Ü–∏—é load_model (–∫–æ—Ç–æ—Ä–∞—è load_model(tf, model_type)),
# —Ç–∞–∫ –∫–∞–∫ load_model_with_fallback —Ç–µ–ø–µ—Ä—å –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –≤–∫–ª—é—á–∞–µ—Ç –ª–æ–≥–∏–∫—É fallback.
# –ï—Å–ª–∏ —ç—Ç–∞ —Å—Ç–∞—Ä–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å –≥–¥–µ-—Ç–æ –µ—â–µ —Å –¥—Ä—É–≥–∏–º–∏ –ø—É—Ç—è–º–∏, –≤–æ–∑–º–æ–∂–Ω–æ, –µ–µ –Ω—É–∂–Ω–æ
# –æ—Å—Ç–∞–≤–∏—Ç—å –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å, –Ω–æ –¥–ª—è —Ç–µ–∫—É—â–µ–π –∑–∞–¥–∞—á–∏ predict_all_tf –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ load_model_with_fallback.
# –°—É–¥—è –ø–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º—É –∫–æ–¥—É, —Å—Ç–∞—Ä–∞—è load_model –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤–Ω—É—Ç—Ä–∏ predict_all_tf
# –∏ –µ–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–ø–µ—Ä—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–∫—Ä—ã—Ç–∞ load_model_with_fallback.

TIMEFRAMES = ['5m', '15m', '30m', '1h', '4h', '1d']  # –û—Å–Ω–æ–≤–Ω—ã–µ –¢–§ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
# FEATURES_PATH_TEMPLATE = 'data/features_{tf}.pkl' # –°—Ç–∞—Ä—ã–π —à–∞–±–ª–æ–Ω
# –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —à–∞–±–ª–æ–Ω –ø—É—Ç–∏, —á—Ç–æ–±—ã –æ–Ω —É—á–∏—Ç—ã–≤–∞–ª —Å—É—Ñ—Ñ–∏–∫—Å (all, group, symbol)
# –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ features_path –±—É–¥–µ—Ç –≤–Ω—É—Ç—Ä–∏ predict_all_tf
# MODEL_PATH_TEMPLATE = 'models/{tf}_{model_type}.pkl' # –£–¥–∞–ª–∏–ª, —Ç–∞–∫ –∫–∞–∫ —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è load_model_with_fallback –ø—É—Ç—è–º–∏

LOG_DIR_PREDICT = 'logs'
# –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è, —á—Ç–æ–±—ã –æ–Ω–∏ –≤–∫–ª—é—á–∞–ª–∏ —Å—É—Ñ—Ñ–∏–∫—Å —Ñ–∏–ª—å—Ç—Ä–∞
# –≠—Ç–æ –Ω—É–∂–Ω–æ, —á—Ç–æ–±—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤ –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–ª–∏ –¥—Ä—É–≥ –¥—Ä—É–≥–∞
# FILES_SUFFIX will be determined inside predict_all_tf based on the filter
# LATEST_PREDICTIONS_FILE = os.path.join(LOG_DIR_PREDICT, 'latest_predictions.csv') # –°—Ç–∞—Ä—ã–π –ø—É—Ç—å
# TRADE_PLAN_FILE = os.path.join(LOG_DIR_PREDICT, 'trade_plan.csv') # –°—Ç–∞—Ä—ã–π –ø—É—Ç—å


# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ª–æ–≥–æ–≤/—Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
os.makedirs(LOG_DIR_PREDICT, exist_ok=True)

TARGET_CLASS_NAMES = ['STRONG DOWN', 'DOWN', 'NEUTRAL', 'UP', 'STRONG UP']


def compute_final_delta(delta_model, delta_history, sigma_history):
    if pd.isna(delta_history) or pd.isna(sigma_history):
        return round(delta_model, 5)
    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ sigma_history –Ω–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–∞ –≤–æ –∏–∑–±–µ–∂–∞–Ω–∏–µ –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å –∏–ª–∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –≤–µ—Å–æ–≤
    if sigma_history < 1e-9: # –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —Å—á–∏—Ç–∞–µ–º –µ–≥–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω—É–ª–µ–º
         sigma_history = 1e-9 # –ó–∞–º–µ–Ω—è–µ–º –Ω–∞ –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–æ–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ
         # –ú–æ–∂–Ω–æ —Ç–∞–∫–∂–µ —Ä–µ—à–∏—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å history, –µ—Å–ª–∏ sigma_history –±–ª–∏–∑–∫–∞ –∫ –Ω—É–ª—é, —Ç.–∫. —ç—Ç–æ –∏–¥–µ–∞–ª—å–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è
         # return round(delta_model, 5) # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –µ—Å–ª–∏ sigma_history ~ 0, —Ç–æ history –∏–¥–µ–∞–ª—å–Ω–∞, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º model

    # –°—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞ –≤–µ—Å–æ–≤ - –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å
    # if sigma_history < 0.005:
    #     w1, w2 = 0.4, 0.6
    # elif sigma_history > 0.02:
    #     w1, w2 = 0.8, 0.2
    # else:
    #     alpha = (sigma_history - 0.005) / (0.02 - 0.005)
    #     w1 = 0.4 + alpha * (0.8 - 0.4)
    #     w2 = 1.0 - w1

    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≤–µ—Å–æ–≤, –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ –æ–±—Ä–∞—Ç–Ω–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–∏–≥–º—ã –∏—Å—Ç–æ—Ä–∏–∏
    # –ß–µ–º –º–µ–Ω—å—à–µ —Å–∏–≥–º–∞ –∏—Å—Ç–æ—Ä–∏–∏, —Ç–µ–º –±–æ–ª—å—à–∏–π –≤–µ—Å —É –∏—Å—Ç–æ—Ä–∏–∏
    # –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏–≥–º—É –∫–∞–∫ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å "—à—É–º–∞" –∏–ª–∏ "–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏" –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
    # –ü—Ä–∏–º–µ—Ä: –≤–µ—Å –∏—Å—Ç–æ—Ä–∏–∏ = 1 / sigma_history, –≤–µ—Å –º–æ–¥–µ–ª–∏ = –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤: w_hist = (1/sigma_history) / ((1/sigma_history) + C), w_model = C / ((1/sigma_history) + C)
    # –ì–¥–µ C - –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞, —Ä–µ–≥—É–ª–∏—Ä—É—é—â–∞—è –±–∞–∑–æ–≤—ã–π "–¥–æ–≤–µ—Ä–∏–µ" –∫ –º–æ–¥–µ–ª–∏
    # –ò–ª–∏ –ø—Ä–æ—Å—Ç–æ –ª–∏–Ω–µ–π–Ω–æ: w_hist = max_weight - (sigma_history - min_sigma) / (max_sigma - min_sigma) * (max_weight - min_weight)
    # –ì–¥–µ min_sigma, max_sigma, min_weight, max_weight - –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.

    # –í–µ—Ä–Ω–µ–º—Å—è –∫ –ø—Ä–æ—Å—Ç–æ–π –ª–∏–Ω–µ–π–Ω–æ–π –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏ –≤–µ—Å–æ–≤ –∏–∑ –ø—Ä–∏–º–µ—Ä–∞
    min_sigma = 0.005
    max_sigma = 0.020
    weight_hist_at_min_sigma = 0.6 # –í–µ—Å –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–∏ –æ—á–µ–Ω—å –Ω–∏–∑–∫–æ–π —Å–∏–≥–º–µ
    weight_hist_at_max_sigma = 0.2 # –í–µ—Å –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π —Å–∏–≥–º–µ

    if sigma_history <= min_sigma:
        w_hist = weight_hist_at_min_sigma
    elif sigma_history >= max_sigma:
        w_hist = weight_hist_at_max_sigma
    else:
        # –õ–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –≤–µ—Å–∞ –∏—Å—Ç–æ—Ä–∏–∏ –º–µ–∂–¥—É weight_hist_at_min_sigma –∏ weight_hist_at_max_sigma
        # –ø–æ –º–µ—Ä–µ —Ä–æ—Å—Ç–∞ sigma_history –æ—Ç min_sigma –¥–æ max_sigma
        alpha = (sigma_history - min_sigma) / (max_sigma - min_sigma)
        w_hist = weight_hist_at_min_sigma - alpha * (weight_hist_at_min_sigma - weight_hist_at_max_sigma)

    w_model = 1.0 - w_hist

    return round(w_model * delta_model + w_hist * delta_history, 5)


def get_signal_strength(delta_final, confidence, sigma_history):
    if pd.isna(sigma_history):
        sigma_history = float('inf')

    # –ù–µ–º–Ω–æ–≥–æ —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–ª –ª–æ–≥–∏–∫—É —Å–∏–ª—ã —Å–∏–≥–Ω–∞–ª–∞, —á—Ç–æ–±—ã –æ–Ω–∞ –ª—É—á—à–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º confidence –∏ sigma
    # –≠—Ç–æ –º–æ–µ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–µ, –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–æ –∂–µ–ª–∞–Ω–∏—é
    # –ü–æ—Ä–æ–≥–∏ –¥–ª—è delta_final –∏ confidence, –∞ —Ç–∞–∫–∂–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –∏—Å—Ç–æ—Ä–∏–∏ (–æ–±—Ä–∞—Ç–Ω–∞—è –∫ sigma)
    # –°–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª: –±–æ–ª—å—à–∞—è delta_final, –≤—ã—Å–æ–∫–∞—è confidence, –Ω–∏–∑–∫–∞—è sigma_history (–Ω–∞–¥–µ–∂–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è)
    # –£–º–µ—Ä–µ–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª: —Å—Ä–µ–¥–Ω—è—è delta_final, —Å—Ä–µ–¥–Ω—è—è confidence, —Å—Ä–µ–¥–Ω—è—è sigma_history
    # –°–ª–∞–±—ã–π —Å–∏–≥–Ω–∞–ª: –º–∞–ª–µ–Ω—å–∫–∞—è delta_final, –Ω–∏–∑–∫–∞—è confidence, –≤—ã—Å–æ–∫–∞—è sigma_history (–Ω–µ–Ω–∞–¥–µ–∂–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è)

    delta_threshold_strong = 0.025 # 2.5%
    delta_threshold_moderate = 0.010 # 1.0%

    conf_threshold_strong = 0.15 # > conf_score - next_conf_score
    conf_threshold_moderate = 0.05

    sigma_threshold_reliable = 0.010 # –ò—Å—Ç–æ—Ä–∏—è –Ω–∞–¥–µ–∂–Ω–∞, –µ—Å–ª–∏ —Å–∏–≥–º–∞ < 1%
    sigma_threshold_unreliable = 0.020 # –ò—Å—Ç–æ—Ä–∏—è –Ω–µ–Ω–∞–¥–µ–∂–Ω–∞, –µ—Å–ª–∏ —Å–∏–≥–º–∞ > 2%


    abs_delta = abs(delta_final)

    if abs_delta > delta_threshold_strong and confidence > conf_threshold_strong:
        # –°–∏–ª—å–Ω—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç, —Ç–µ–ø–µ—Ä—å —É—Ç–æ—á–Ω–∏–º –ø–æ –∏—Å—Ç–æ—Ä–∏–∏
        if sigma_history < sigma_threshold_reliable:
            return "üü¢ –°–∏–ª—å–Ω—ã–π"
        elif sigma_history < sigma_threshold_unreliable:
             # –£–º–µ—Ä–µ–Ω–Ω–æ –Ω–∞–¥–µ–∂–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è —Å–Ω–∏–∂–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
             return "üü° –£–º–µ—Ä–µ–Ω–Ω—ã–π"
        else:
             # –ù–µ–Ω–∞–¥–µ–∂–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è —Å–∏–ª—å–Ω–æ —Å–Ω–∏–∂–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
             return "‚ö™ –°–ª–∞–±—ã–π" # –ò–ª–∏ –¥–∞–∂–µ "–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π"?

    elif abs_delta > delta_threshold_moderate and confidence > conf_threshold_moderate:
        # –£–º–µ—Ä–µ–Ω–Ω—ã–π –∫–∞–Ω–¥–∏–¥–∞—Ç, —É—Ç–æ—á–Ω–∏–º –ø–æ –∏—Å—Ç–æ—Ä–∏–∏
        if sigma_history < sigma_threshold_reliable:
             # –£–º–µ—Ä–µ–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª + –Ω–∞–¥–µ–∂–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è = –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–≤—ã—à–µ–Ω –¥–æ –£–º–µ—Ä–µ–Ω–Ω–æ–≥–æ
             return "üü° –£–º–µ—Ä–µ–Ω–Ω—ã–π" # –ò–ª–∏ –¥–∞–∂–µ "–°–∏–ª—å–Ω—ã–π"? –†–µ—à–∏–º –æ—Å—Ç–∞–≤–∏—Ç—å –£–º–µ—Ä–µ–Ω–Ω—ã–º
        elif sigma_history < sigma_threshold_unreliable:
             # –£–º–µ—Ä–µ–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª + —É–º–µ—Ä–µ–Ω–Ω–æ –Ω–∞–¥–µ–∂–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è = –æ—Å—Ç–∞–µ—Ç—Å—è –£–º–µ—Ä–µ–Ω–Ω—ã–º
             return "üü° –£–º–µ—Ä–µ–Ω–Ω—ã–π"
        else:
             # –£–º–µ—Ä–µ–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª + –Ω–µ–Ω–∞–¥–µ–∂–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è = –ø–æ–Ω–∏–∂–∞–µ—Ç—Å—è –¥–æ –°–ª–∞–±–æ–≥–æ
             return "‚ö™ –°–ª–∞–±—ã–π"

    else:
        # –°–ª–∞–±—ã–π —Å–∏–≥–Ω–∞–ª –ø–æ –¥–µ–ª—å—Ç–µ –∏–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        return "‚ö™ –°–ª–∞–±—ã–π"

    # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –∏–∑ –ø—Ä–∏–º–µ—Ä–∞:
    # if abs(delta_final) > 0.02 and confidence > 0.5 and sigma_history < 0.015: # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–µ —É—Å–ª–æ–≤–∏—è –¥–ª—è –°–∏–ª—å–Ω–æ–≥–æ
    #     return "üü¢ –°–∏–ª—å–Ω—ã–π"
    # elif abs(delta_final) > 0.01 and confidence > 0.2 and sigma_history < 0.025: # –£–º–µ—Ä–µ–Ω–Ω—ã–π
    #     return "üü° –£–º–µ—Ä–µ–Ω–Ω—ã–π"
    # else: # –°–ª–∞–±—ã–π –∏–ª–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π
    #     return "‚ö™ –°–ª–∞–±—ã–π"


def is_conflict(delta_model, delta_history):
    if pd.isna(delta_history) or pd.isna(delta_model):
        return False
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–Ω—Ñ–ª–∏–∫—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–µ–ª—å—Ç–∞ –∏—Å—Ç–æ—Ä–∏–∏ –Ω–µ –±–ª–∏–∑–∫–∞ –∫ –Ω—É–ª—é
    if abs(delta_history) < 0.005: # –ü–æ—Ä–æ–≥ –¥–ª—è "–±–ª–∏–∑–∫–æ –∫ –Ω—É–ª—é", –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å
        return False
    return (delta_model > 0 and delta_history < 0) or \
        (delta_model < 0 and delta_history > 0)


# –£–¥–∞–ª–∏–ª —Å—Ç–∞—Ä—É—é —Ñ—É–Ω–∫—Ü–∏—é load_model, –µ–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–ø–µ—Ä—å –≤ load_model_with_fallback.


def get_confidence_hint(score):
    if score > 0.20:
        return "–û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
    elif score > 0.10:
        return "–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
    elif score > 0.05:
        return "–£–º–µ—Ä–µ–Ω–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å"
    elif score > 0.02: # –ú–æ–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ—Ä–æ–≥, –Ω–∏–∂–µ –∫–æ—Ç–æ—Ä–æ–≥–æ —Å–∏–≥–Ω–∞–ª—ã –Ω–µ —Ç–æ—Ä–≥—É—é—Ç—Å—è
         return "–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –±—É–¥—å—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã"
    else:
        return "–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å"


def calculate_trade_levels(entry, direction, atr_value, rr=2.0):
    # atr_value –∑–¥–µ—Å—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç—Å—è –∫–∞–∫ –±–∞–∑–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –¥–≤–∏–∂–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∏–ª–∏ ATR)
    # SL —Å—Ç–∞–≤–∏–º –Ω–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏ atr_value, TP –Ω–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–∏ atr_value * rr
    if pd.isna(atr_value) or atr_value <= 1e-9:
        return np.nan, np.nan
    if direction == 'long':
        sl = entry - atr_value
        tp = entry + atr_value * rr
    elif direction == 'short':
        sl = entry + atr_value
        tp = entry - atr_value * rr
    else:
        return np.nan, np.nan
    # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ —Ä–∞–∑—É–º–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π, –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ü–µ–Ω—ã –∞–∫—Ç–∏–≤–∞
    # –î–ª—è –∫—Ä–∏–ø—Ç—ã 6 –∑–Ω–∞–∫–æ–≤ –æ–±—ã—á–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –Ω–æ –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –¥–ª—è –æ—á–µ–Ω—å –¥–µ—à–µ–≤—ã—Ö –º–æ–Ω–µ—Ç
    # –¢–∞–∫–∂–µ –Ω—É–∂–Ω–æ —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ SL/TP –Ω–µ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ –¥–ª—è –æ—á–µ–Ω—å –¥–µ—à–µ–≤—ã—Ö –º–æ–Ω–µ—Ç –ø—Ä–∏ —àort
    sl = round(max(0, sl), 6) if direction == 'short' else round(sl, 6)
    tp = round(max(0, tp), 6) if direction == 'short' else round(tp, 6) # TP —Ç–æ–∂–µ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º

    return sl, tp


def similarity_analysis(X_live_df, X_hist_df, deltas_hist_series, top_n=15):
    # X_live_df - –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ DataFrame, X_hist_df - –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π DataFrame –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    # deltas_hist_series - —Å–µ—Ä–∏—è –¥–µ–ª—å—Ç –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ DataFrame

    if X_hist_df.empty or len(X_hist_df) < top_n:
        return np.nan, np.nan, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏"

    # –í–∞–∂–Ω–æ: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –∏ –≤ X_live, –∏ –≤ X_hist
    # X_live_df –ø—Ä–∏—Ö–æ–¥–∏—Ç —Å—é–¥–∞ —É–∂–µ —Å –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ feature_cols_from_file
    # X_hist_df - —ç—Ç–æ hist_for_sim_features, –∫–æ—Ç–æ—Ä–∞—è —Ç–æ–∂–µ –æ—Ç–æ–±—Ä–∞–Ω–∞ –ø–æ feature_cols_from_file
    # –¢–∞–∫ —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∏ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å. –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π.
    if not X_live_df.columns.equals(X_hist_df.columns):
         logging.error("–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –º–µ–∂–¥—É X_live_df –∏ X_hist_df –ø–µ—Ä–µ–¥ –∞–Ω–∞–ª–∏–∑–æ–º —Å—Ö–æ–∂–µ—Å—Ç–∏!")
         # –ú–æ–∂–Ω–æ –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –Ω–∞–π—Ç–∏ –æ–±—â–∏–µ, –Ω–æ –ª—É—á—à–µ, —á—Ç–æ–±—ã –æ–Ω–∏ —Å–æ–≤–ø–∞–¥–∞–ª–∏ –Ω–∞ —ç—Ç–∞–ø–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏
         common_cols = X_live_df.columns.intersection(X_hist_df.columns)
         if len(common_cols) == 0:
              return np.nan, np.nan, "–ù–µ—Ç –æ–±—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏"
         logging.warning(f"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–±—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(common_cols)}) –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏.")
         X_live_df_common = X_live_df[common_cols]
         X_hist_df_common = X_hist_df[common_cols]
    else:
         X_live_df_common = X_live_df
         X_hist_df_common = X_hist_df


    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ X_hist_df_common –∏ deltas_hist_series –∏–º–µ—é—Ç —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã
    # –∏ —É–¥–∞–ª–∏–º —Å—Ç—Ä–æ–∫–∏ —Å NaN –∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–µ—Ä–µ–¥ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –∞–Ω–∞–ª–∏–∑–æ–º —Å—Ö–æ–∂–µ—Å—Ç–∏
    hist_df_aligned = X_hist_df_common.copy()
    # –ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ deltas_hist_series –∏–º–µ–µ—Ç —Ç–æ—Ç –∂–µ –∏–Ω–¥–µ–∫—Å, —á—Ç–æ –∏ X_hist_df_common
    if not deltas_hist_series.index.equals(hist_df_aligned.index):
         # –ï—Å–ª–∏ –∏–Ω–¥–µ–∫—Å—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç, –ø–æ–ø—Ä–æ–±—É–µ–º –≤—ã—Ä–æ–≤–Ω—è—Ç—å –ø–æ –∏–Ω–¥–µ–∫—Å—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
         try:
              hist_deltas_aligned = deltas_hist_series.reindex(hist_df_aligned.index).copy()
              logging.debug("–ò–Ω–¥–µ–∫—Å—ã deltas_hist_series –≤—ã—Ä–æ–≤–Ω–µ–Ω—ã –ø–æ X_hist_df_common.")
         except Exception as e:
              logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–∏ –∏–Ω–¥–µ–∫—Å–æ–≤ deltas_hist_series –ø–æ X_hist_df_common: {e}")
              return np.nan, np.nan, "–û—à–∏–±–∫–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ö–æ–∂–µ—Å—Ç–∏"
    else:
        hist_deltas_aligned = deltas_hist_series.copy()


    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –µ—Å—Ç—å NaN –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –ò–õ–ò –≥–¥–µ –µ—Å—Ç—å NaN –≤ –¥–µ–ª—å—Ç–∞—Ö –∏—Å—Ç–æ—Ä–∏–∏
    # –°–æ–∑–¥–∞–µ–º –±—É–ª–µ–≤—ã –º–∞—Å–∫–∏ –¥–ª—è NaN –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –∏ –¥–µ–ª—å—Ç–∞—Ö
    nan_in_features = hist_df_aligned.isnull().any(axis=1)
    nan_in_deltas = hist_deltas_aligned.isnull()

    # –ò–Ω–¥–µ–∫—Å—ã —Å—Ç—Ä–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï —Å–æ–¥–µ—Ä–∂–∞—Ç NaN –Ω–∏ –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö, –Ω–∏ –≤ –¥–µ–ª—å—Ç–∞—Ö
    valid_indices = hist_df_aligned.index[~(nan_in_features | nan_in_deltas)]

    hist_df_aligned_clean = hist_df_aligned.loc[valid_indices]
    hist_deltas_aligned_clean = hist_deltas_aligned.loc[valid_indices]

    if len(hist_df_aligned_clean) < top_n:
         return np.nan, np.nan, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å—Ç—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö ({len(hist_df_aligned_clean)} < {top_n}) –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏"

    scaler = StandardScaler()
    try:
        X_hist_scaled = scaler.fit_transform(hist_df_aligned_clean)
        # X_live_df_common - —ç—Ç–æ –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞, –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –µ–µ —Ç–µ–º –∂–µ —Å–∫–µ–π–ª–µ—Ä–æ–º
        x_live_scaled = scaler.transform(X_live_df_common)

    except ValueError as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏ –≤ similarity_analysis: {e}")
        return np.nan, np.nan, "–û—à–∏–±–∫–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
    except Exception as e:
         logging.error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏ –≤ similarity_analysis: {e}", exc_info=True)
         return np.nan, np.nan, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"


    sims = cosine_similarity(X_hist_scaled, x_live_scaled).flatten()

    # Indices of the top N similar historical points in the *cleaned and scaled* history data
    # Handle case where top_n might be larger than available data after cleaning
    actual_top_n = min(top_n, len(sims))
    if actual_top_n <= 0:
         return np.nan, np.nan, "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ–ø-N –ø–æ—Å–ª–µ —á–∏—Å—Ç–∫–∏ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è"

    top_indices_in_cleaned_hist = sims.argsort()[-actual_top_n:][::-1]

    # Get the original indices from the cleaned data index
    original_top_indices = hist_df_aligned_clean.iloc[top_indices_in_cleaned_hist].index

    if len(original_top_indices) == 0:
        # –≠—Ç–æ —É—Å–ª–æ–≤–∏–µ, –ø–æ –∏–¥–µ–µ, –Ω–µ –¥–æ–ª–∂–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è, –µ—Å–ª–∏ actual_top_n > 0, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        return np.nan, np.nan, "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ö–æ–∂–∏—Ö —Å–∏—Ç—É–∞—Ü–∏–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"

    # Get the deltas for these original indices from the cleaned deltas series
    similar_deltas = hist_deltas_aligned_clean.loc[original_top_indices]

    # Calculate mean and std of these deltas
    avg_delta = similar_deltas.mean()
    std_delta = similar_deltas.std()

    # Ensure std_delta is not NaN if there's only one point (std is 0)
    if len(similar_deltas) == 1:
        std_delta = 0.0

    hint = (
        "–í—ã—Å–æ–∫–∏–π —Ä–∞–∑–±—Ä–æ—Å" if pd.notna(std_delta) and std_delta > 0.02 else
        "–£–º–µ—Ä–µ–Ω–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ" if pd.notna(std_delta) and std_delta > 0.01 else
        "–°—Ç–∞–±–∏–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω" if pd.notna(std_delta) else
        "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–±—Ä–æ—Å"
    )
    if pd.isna(avg_delta) or pd.isna(std_delta):
        hint = "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å—Ö–æ–∂–µ—Å—Ç–∏"

    return avg_delta, std_delta, hint


# >>> –ò–ó–ú–ï–ù–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã symbol_filter –∏ group_filter
def predict_all_tf(save_output_flag, symbol_filter=None, group_filter=None):
    # ----- –ù–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å–∏–º–≤–æ–ª—É –∏–ª–∏ –≥—Ä—É–ø–ø–µ -----
    # >>> –î–û–ë–ê–í–õ–ï–ù–û —Å–æ–≥–ª–∞—Å–Ω–æ –ø–∞—Ç—á—É
    target_syms = None
    files_suffix = "all" # –°—É—Ñ—Ñ–∏–∫—Å –¥–ª—è —Ñ–∞–π–ª–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if symbol_filter:
        target_syms = [symbol_filter.upper()] # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –≤–µ—Ä—Ö–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        logging.info(f"üõ†Ô∏è –§–∏–ª—å—Ç—Ä –ø–æ —Å–∏–º–≤–æ–ª—É: {target_syms[0]}")
        files_suffix = target_syms[0]
    elif group_filter:
        group_key = group_filter.lower() # –ü—Ä–∏–≤–æ–¥–∏–º –∫–ª—é—á –≥—Ä—É–ø–ø—ã –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        if group_key not in GROUP_MODELS:
            # –≠—Ç–æ—Ç —Å–ª—É—á–∞–π –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –≤ __main__ –ø–µ—Ä–µ–¥ –≤—ã–∑—ã–≤–æ–º, –Ω–æ –æ—Å—Ç–∞–≤–∏–º –ø—Ä–æ–≤–µ—Ä–∫—É
            logging.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –≥—Ä—É–ø–ø–∞ —Å–∏–º–≤–æ–ª–æ–≤: '{group_filter}'. –î–æ—Å—Ç—É–ø–Ω—ã–µ –≥—Ä—É–ø–ø—ã: {list(GROUP_MODELS.keys())}")
            return # –í—ã—Ö–æ–¥–∏–º –∏–∑ —Ñ—É–Ω–∫—Ü–∏–∏, –µ—Å–ª–∏ –≥—Ä—É–ø–ø–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
        target_syms = GROUP_MODELS[group_key]
        logging.info(f"üõ†Ô∏è –§–∏–ª—å—Ç—Ä –ø–æ –≥—Ä—É–ø–ø–µ: '{group_filter}' ({len(target_syms)} —Å–∏–º–≤–æ–ª–æ–≤)")
        files_suffix = group_key
    else:
        logging.info("üõ†Ô∏è –ë–µ–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –ø–æ —Å–∏–º–≤–æ–ª—É/–≥—Ä—É–ø–ø–µ (–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö).")
        files_suffix = "all" # –Ø–≤–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—É—Ñ—Ñ–∏–∫—Å "all"

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å —É—á—ë—Ç–æ–º —Å—É—Ñ—Ñ–∏–∫—Å–∞
    LATEST_PREDICTIONS_FILE = os.path.join(LOG_DIR_PREDICT, f'latest_predictions_{files_suffix}.csv')
    TRADE_PLAN_FILE = os.path.join(LOG_DIR_PREDICT, f'trade_plan_{files_suffix}.csv')


    logging.info(f"üöÄ  –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ (—Ñ–∏–ª—å—Ç—Ä: {files_suffix})...")
    all_predictions_data = []
    trade_plan = []

    for tf in TIMEFRAMES:
        logging.info(f"\n--- –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞: {tf} ---")

        # >>> –ò–ó–ú–ï–ù–ï–ù–û —Å–æ–≥–ª–∞—Å–Ω–æ –ø–∞—Ç—á—É: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å fallback
        # 1) —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –≥—Ä—É–ø–ø–æ–≤–æ–π/—Å–∏–º–≤–æ–ª—å–Ω—ã–π —Ñ–∞–π–ª
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º files_suffix, –∫–æ—Ç–æ—Ä—ã–π –±—ã–ª –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –≤—ã—à–µ
        group_path   = f"data/features_{files_suffix}_{tf}.pkl"
        # 2) –∑–∞—Ç–µ–º –ø—Ä–æ–±—É–µ–º –æ–±—â–∏–π —Ñ–∞–π–ª
        generic_path = f"data/features_{tf}.pkl"

        features_path = None
        if os.path.exists(group_path):
            features_path = group_path
            logging.debug(f"–ò—Å–ø–æ–ª—å–∑—É—é —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {group_path}")
        elif os.path.exists(generic_path):
            features_path = generic_path
            logging.info(f"üõ†Ô∏è –ò—Å–ø–æ–ª—å–∑—É—é –æ–±—â–∏–π —Ñ–∞–π–ª –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {generic_path}")
        else:
            logging.warning(f"‚ö†Ô∏è –ù–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–∞—è ({group_path}), –Ω–∏ –æ–±—â–∞—è ({generic_path}) –≤–µ—Ä—Å–∏—è —Ñ–∞–π–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–ø—É—Å–∫ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {tf}.")
            continue

        try:
            # >>> –ò–ó–ú–ï–ù–ï–ù–û —Å–æ–≥–ª–∞—Å–Ω–æ –ø–∞—Ç—á—É: —É–±–∏—Ä–∞–µ–º engine=...
            # –ß–∏—Ç–∞–µ–º pickle —Ñ–∞–π–ª
            df = pd.read_pickle(features_path)
        except Exception as e:
            logging.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ {features_path}: {e}. –ü—Ä–æ–ø—É—Å–∫ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {tf}.")
            continue

        if df.empty:
            logging.warning(f"‚ö†Ô∏è –§–∞–π–ª –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—É—Å—Ç: {features_path}. –ü—Ä–æ–ø—É—Å–∫ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {tf}.")
            continue

        # –°–∏–º–≤–æ–ª—ã –≤ df —É–∂–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã preprocess_features, –µ—Å–ª–∏ —Ñ–∞–π–ª —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º –±—ã–ª –Ω–∞–π–¥–µ–Ω.
        # –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω generic_path, —Ç–æ df —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ —Å–∏–º–≤–æ–ª—ã, –∏ –Ω–∞–º –Ω—É–∂–Ω–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –µ–≥–æ.
        # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —Å–∏–º–≤–æ–ª—ã –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º df —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç target_syms (–µ—Å–ª–∏ –æ–Ω –∑–∞–¥–∞–Ω)
        available_symbols_in_data_before_filter = df['symbol'].unique().tolist()

        if target_syms is not None:
            # –ï—Å–ª–∏ –º—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ –æ–±—â–∏–π —Ñ–∞–π–ª (generic_path), —Ç–æ df –µ—â–µ –Ω–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω.
            # –ï—Å–ª–∏ –º—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª (group_path), —Ç–æ df —É–∂–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω preprocess_features.
            # –í –ª—é–±–æ–º —Å–ª—É—á–∞–µ, –ø—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –Ω–∞ df, —á—Ç–æ–±—ã –±—ã—Ç—å —É–≤–µ—Ä–µ–Ω–Ω—ã–º–∏.
            before_filter_count = len(df)
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∏–ª–∏ generic_path –ò–õ–ò –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–∏–º–≤–æ–ª—ã,
            # –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ target_syms (–ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏).
            # –°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± - –ø—Ä–æ—Å—Ç–æ –≤—Å–µ–≥–¥–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å df –ø–æ target_syms, –µ—Å–ª–∏ target_syms –Ω–µ None.
            # –≠—Ç–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ, –¥–∞–∂–µ –µ—Å–ª–∏ df —É–∂–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω.
            df = df[df['symbol'].isin(target_syms)].copy() # –ò—Å–ø–æ–ª—å–∑—É–µ–º .copy() –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è SettingWithCopyWarning
            after_filter_count = len(df)

            symbols_in_file_but_not_in_filter = [sym for sym in available_symbols_in_data_before_filter if sym not in target_syms]
            symbols_in_filter_but_not_in_file_after_load = [sym for sym in target_syms if sym not in available_symbols_in_data_before_filter]


            if symbols_in_file_but_not_in_filter:
                 logging.warning(f"‚ö†Ô∏è –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(symbols_in_file_but_not_in_filter)} –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ {features_path}.")

            if symbols_in_filter_but_not_in_file_after_load:
                 logging.warning(f"‚ö†Ô∏è –°–∏–º–≤–æ–ª—ã –∏–∑ —Ñ–∏–ª—å—Ç—Ä–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ({features_path}): {symbols_in_filter_but_not_in_file_after_load}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Ö.")


            if df.empty:
                 logging.info(f"ü§∑ –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —Å–∏–º–≤–æ–ª–∞–º/–≥—Ä—É–ø–ø–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –Ω–∞ {tf}. –ü—Ä–æ–ø—É—Å–∫ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {tf}.")
                 continue # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Ç–∞–π–º—Ñ—Ä–µ–π–º—É

            logging.info(f"–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è DataFrame: {before_filter_count} ‚Üí {after_filter_count} —Å—Ç—Ä–æ–∫ –¥–ª—è TF {tf}.")


        # >>> –ö–û–ù–ï–¶ –ë–õ–û–ö–ê –§–ò–õ–¨–¢–†–ê–¶–ò–ò DATAFRAME (–º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ)

        features_list_path = f"models/{files_suffix}_{tf}_features_selected.txt"
        if not os.path.exists(features_list_path):
            logging.error(
                f"‚ùå –§–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ '{features_list_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –¥–ª—è {tf}. –ü—Ä–æ–ø—É—Å–∫.")
            continue
        try:
            with open(features_list_path, "r", encoding="utf-8") as f:
                feature_cols_from_file = [line.strip() for line in f if line.strip()]
            if not feature_cols_from_file:
                logging.error(f"‚ùå –§–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ '{features_list_path}' –ø—É—Å—Ç. –ü—Ä–æ–ø—É—Å–∫ {tf}.")
                continue
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Å–æ —Å–ø–∏—Å–∫–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ '{features_list_path}': {e}. –ü—Ä–æ–ø—É—Å–∫ {tf}.")
            continue

        # Model loading is now per-symbol, so it's moved inside the symbol loop.
        # The old loading location and logging for TP-hit classes per TF is removed from here.

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ *–æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö* –∏–ª–∏ *–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö* –¥–∞–Ω–Ω—ã—Ö
        # –¢–µ–ø–µ—Ä—å df —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ç–µ —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω—ã –¥–ª—è —ç—Ç–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞.
        available_symbols_in_data = df['symbol'].unique()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∏–µ —Å–∏–º–≤–æ–ª—ã –º—ã –±—É–¥–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≤ —ç—Ç–æ–º TF
        # –≠—Ç–æ—Ç —Å–ø–∏—Å–æ–∫ —É–∂–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º —Ñ–∞–π–ª–æ–º –∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π) —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
        symbols_to_process_this_tf = available_symbols_in_data.tolist()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤ —Å–ø–∏—Å–∫–µ symbol_list (–µ—Å–ª–∏ –æ–Ω –±—ã–ª –∑–∞–¥–∞–Ω) –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Å–∏–º–≤–æ–ª,
        # –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ç–µ–∫—É—â–µ–º df.
        # –≠—Ç–æ —É–∂–µ –Ω–µ —Å—Ç—Ä–æ–≥–∞—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å, —Ç.–∫. –º—ã –∏—Ç–µ—Ä–∏—Ä—É–µ–º—Å—è –ø–æ symbols_to_process_this_tf,
        # –∫–æ—Ç–æ—Ä—ã–π –±–µ—Ä–µ—Ç—Å—è –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ df, –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω (–∏–ª–∏ –Ω–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω).
        # –û—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if not symbols_to_process_this_tf:
             # –≠—Ç–æ—Ç –ª–æ–≥ —É–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–∫—Ä—ã—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –≤—ã—à–µ, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
             logging.info(f"ü§∑ –ù–µ—Ç —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞ {tf} –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ DataFrame –ø–æ—Å–ª–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.")
             continue # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Ç–∞–π–º—Ñ—Ä–µ–π–º—É


        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–∏–º–≤–æ–ª—ã –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–≥–æ –≤—ã–≤–æ–¥–∞
        symbols_to_process_this_tf.sort()

        for symbol in symbols_to_process_this_tf:

            df_sym = df[df['symbol'] == symbol].sort_values('timestamp').copy()
            # –ü—É—Å—Ç–æ–π df_sym –Ω–µ –¥–æ–ª–∂–µ–Ω –≤–æ–∑–Ω–∏–∫–∞—Ç—å —Ç—É—Ç, —Ç.–∫. —Å–∏–º–≤–æ–ª –≤–∑—è—Ç –∏–∑ available_symbols_in_data,
            # –Ω–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –ø–æ–≤—Ä–µ–¥–∏—Ç.
            if df_sym.empty:
                logging.warning(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–æ –ø—É—Å—Ç–æ–π DataFrame –¥–ª—è {symbol} –Ω–∞ {tf}. –ü—Ä–æ–ø—É—Å–∫.")
                continue

            logging.info(f"--- –û–±—Ä–∞–±–æ—Ç–∫–∞ {symbol} –Ω–∞ {tf} ---")

            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ –∏ –¢–§
            # load_model_with_fallback —É–∂–µ —Ä–µ–∞–ª–∏–∑—É–µ—Ç –ª–æ–≥–∏–∫—É –∑–∞–≥—Ä—É–∑–∫–∏ –≥—Ä—É–ø–ø–æ–≤—ã—Ö/–æ–±—â–∏—Ö –º–æ–¥–µ–ª–µ–π
            model_class = load_model_with_fallback(symbol, tf, "clf_class")
            model_delta = load_model_with_fallback(symbol, tf, "reg_delta")
            model_vol = load_model_with_fallback(symbol, tf, "reg_vol")
            model_tp_hit = load_model_with_fallback(symbol, tf, "clf_tp_hit")

            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ TP-hit –º–æ–¥–µ–ª–∏ (–ø–µ—Ä–µ–º–µ—â–µ–Ω–æ —Å—é–¥–∞)
            if model_tp_hit:
                logging.debug(f"–ö–ª–∞—Å—Å—ã TP-hit –º–æ–¥–µ–ª–∏ ({symbol}, {tf}): {getattr(model_tp_hit, 'classes_', 'N/A')}")

            if not all([model_class, model_delta, model_vol]):  # model_tp_hit is optional
                logging.warning(
                    f"‚ö†Ô∏è –û–¥–Ω–∞ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è {symbol} –Ω–∞ {tf} –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –ü—Ä–æ–ø—É—Å–∫ —Å–∏–º–≤–æ–ª–∞ {symbol} –Ω–∞ —ç—Ç–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ.")
                continue  # Skip this symbol for this tf

            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –∏ –æ—Å—Ç–∞–ª—å–Ω–æ–µ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤ df_sym –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å—Ç—Ä–æ–∫ (–º–∏–Ω–∏–º—É–º 1 –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞, –ø–ª—é—Å –∏—Å—Ç–æ—Ä–∏—è –¥–ª—è —Å—Ö–æ–∂–µ—Å—Ç–∏)
            if len(df_sym) < 2: # –ú–∏–Ω–∏–º—É–º 2 —Å—Ç—Ä–æ–∫–∏ –Ω—É–∂–Ω–æ: 1 –¥–ª—è X_live, 1 –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ (—Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞)
                 logging.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö ({len(df_sym)} —Å—Ç—Ä–æ–∫) –¥–ª—è {symbol} {tf}. –ü—Ä–æ–ø—É—Å–∫.")
                 continue

            row_df = df_sym.iloc[-1:].copy()
            hist_df_full = df_sym.iloc[:-1].copy()

            if 'close' not in row_df.columns or 'timestamp' not in row_df.columns:
                logging.warning(f"‚ö†Ô∏è –í –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol} {tf} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç 'close' –∏–ª–∏ 'timestamp'. –ü—Ä–æ–ø—É—Å–∫.")
                continue

            # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ feature_cols_from_file –Ω–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ row_df
            missing_cols_in_df_for_symbol = [col for col in feature_cols_from_file if col not in row_df.columns]
            if missing_cols_in_df_for_symbol:
                logging.error(
                    f"‚ùå –í DataFrame –¥–ª—è {symbol} –Ω–∞ {tf} –∏–∑ {features_path} –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã {missing_cols_in_df_for_symbol}, "
                    f"–Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ (—Å–æ–≥–ª–∞—Å–Ω–æ {features_list_path}). –ü—Ä–æ–ø—É—Å–∫ —Å–∏–º–≤–æ–ª–∞ {symbol} –Ω–∞ —ç—Ç–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ."
                )
                continue

            X_live = row_df[feature_cols_from_file]
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –≤ X_live —É–∂–µ –¥–µ–ª–∞–µ—Ç—Å—è –Ω–∏–∂–µ, –Ω–æ –º–æ–∂–Ω–æ —É—Å–∏–ª–∏—Ç—å —Ç—É—Ç
            # if X_live.isnull().values.any():
            #     nan_features = X_live.columns[X_live.isnull().any()].tolist()
            #     logging.warning(f"‚ö†Ô∏è –í X_live –¥–ª—è {symbol} {tf} –µ—Å—Ç—å NaN –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö: {nan_features}. –ü—Ä–æ–ø—É—Å–∫ —Å–∏–º–≤–æ–ª–∞ {symbol} –Ω–∞ —ç—Ç–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ.")
            #     continue


            # –ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å –∏—Å—Ç–æ—Ä–∏–µ–π
            avg_delta_similar, std_delta_similar, similarity_hint = np.nan, np.nan, "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏"
            if 'delta' not in hist_df_full.columns:
                logging.debug(f"–°—Ç–æ–ª–±–µ—Ü 'delta' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö hist_df_full –¥–ª—è {symbol} {tf}. –ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏ –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
                similarity_hint = "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–æ–ª–±–µ—Ü 'delta' –≤ –∏—Å—Ç–æ—Ä–∏–∏"
            else:
                 # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ò —Å—Ç–æ–ª–±—Ü–∞ 'delta' –≤ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                required_hist_cols = feature_cols_from_file + ['delta']
                missing_hist_features_and_delta = [col for col in required_hist_cols if col not in hist_df_full.columns]

                if missing_hist_features_and_delta:
                    logging.debug(f"–í hist_df_full –¥–ª—è {symbol} {tf} –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã {missing_hist_features_and_delta} –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏.")
                    similarity_hint = "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"
                else:
                    hist_for_sim_features = hist_df_full[feature_cols_from_file].copy()
                    hist_for_sim_deltas = hist_df_full['delta'].copy()

                    # –ß–∏—Å—Ç–∫–∞ –æ—Ç NaN –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ sufficient data –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤–Ω—É—Ç—Ä–∏ similarity_analysis
                    avg_delta_similar, std_delta_similar, similarity_hint = similarity_analysis(
                        X_live, hist_for_sim_features, hist_for_sim_deltas, top_n=15) # top_n=15


            # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN –≤ X_live –µ—â–µ —Ä–∞–∑ –ø–µ—Ä–µ–¥ –ø–æ–¥–∞—á–µ–π –≤ –º–æ–¥–µ–ª—å
            if X_live.isnull().values.any():
                 nan_features = X_live.columns[X_live.isnull().any()].tolist()
                 logging.warning(f"‚ö†Ô∏è –í X_live –¥–ª—è {symbol} {tf} –µ—Å—Ç—å NaN –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö: {nan_features}. –ü—Ä–æ–ø—É—Å–∫ —Å–∏–º–≤–æ–ª–∞ {symbol} –Ω–∞ —ç—Ç–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ.")
                 continue # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç–æ—Ç —Å–∏–º–≤–æ–ª/–¢–§

            try:
                proba_raw = model_class.predict_proba(X_live)[0]
            except Exception as e:
                logging.error(
                    f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ model_class.predict_proba –¥–ª—è {symbol} {tf} —Å X_live shape {X_live.shape}: {e}. –ü—Ä–æ–ø—É—Å–∫ —Å–∏–º–≤–æ–ª–∞.")
                continue

            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ proba_raw —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∫–ª–∞—Å—Å–æ–≤ –º–æ–¥–µ–ª–∏
            model_classes = getattr(model_class, 'classes_', None)
            if model_classes is None or len(proba_raw) != len(model_classes):
                 logging.error(f"‚ùå –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π ({len(proba_raw)}) –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–ª–∞—Å—Å–∞–º –º–æ–¥–µ–ª–∏ ({len(model_classes) if model_classes is not None else 'N/A'}) –¥–ª—è {symbol} {tf}. –ü—Ä–æ–ø—É—Å–∫.")
                 continue

            # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Å –∏–º–µ–Ω–∞–º–∏ –∫–ª–∞—Å—Å–æ–≤ –º–æ–¥–µ–ª–∏
            proba_dict_model_order = {model_classes[i]: proba_raw[i] for i in range(len(proba_raw))}

            # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∞—Å—Å—ã –∏–∑ –º–æ–¥–µ–ª–∏)
            pred_class_label = model_classes[proba_raw.argmax()]
            signal = pred_class_label # –°–∏–≥–Ω–∞–ª —Ç–µ–ø–µ—Ä—å –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –∫–ª–∞—Å—Å–∞ –º–æ–¥–µ–ª–∏

            # –†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –ª—É—á—à–µ–π –∏ –≤—Ç–æ—Ä–æ–π –ª—É—á—à–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
            if len(proba_raw) < 2:
                confidence = float(proba_raw.max()) if len(proba_raw) == 1 else 0.0
            else:
                sorted_probas = np.sort(proba_raw)
                confidence = float(sorted_probas[-1] - sorted_probas[-2])

            hint = get_confidence_hint(confidence)

            try:
                predicted_delta = model_delta.predict(X_live)[0]
            except Exception as e:
                 logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ model_delta.predict –¥–ª—è {symbol} {tf}: {e}. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é predicted_delta –≤ NaN.")
                 predicted_delta = np.nan

            try:
                predicted_volatility = model_vol.predict(X_live)[0]
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞ –∏ –Ω–µ –±–ª–∏–∑–∫–∞ –∫ –Ω—É–ª—é
                if pd.notna(predicted_volatility) and predicted_volatility < 1e-9:
                    logging.warning(f"‚ö†Ô∏è –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –æ—á–µ–Ω—å –±–ª–∏–∑–∫–∞ –∫ –Ω—É–ª—é ({predicted_volatility:.6f}) –¥–ª—è {symbol} {tf}. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ 0.")
                    predicted_volatility = 0.0
                elif pd.notna(predicted_volatility) and predicted_volatility < 0:
                     logging.warning(f"‚ö†Ô∏è –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞ ({predicted_volatility:.6f}) –¥–ª—è {symbol} {tf}. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ 0.")
                     predicted_volatility = 0.0

            except Exception as e:
                 logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ model_vol.predict –¥–ª—è {symbol} {tf}: {e}. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é predicted_volatility –≤ NaN.")
                 predicted_volatility = np.nan


            # TP-hit probability
            tp_hit_proba = np.nan
            if model_tp_hit:
                try:
                    tp_hit_proba_all_classes = model_tp_hit.predict_proba(X_live)[0]
                    model_tp_classes = getattr(model_tp_hit, 'classes_', None)

                    # –ò—â–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ '1' (—É—Å–ø–µ—Ö TP)
                    if model_tp_classes is not None and 1 in model_tp_classes:
                        try:
                            class_1_idx = list(model_tp_classes).index(1)
                            tp_hit_proba = tp_hit_proba_all_classes[class_1_idx]
                        except ValueError:
                            # –≠—Ç–æ–≥–æ –Ω–µ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–∏–∑–æ–π—Ç–∏, –µ—Å–ª–∏ 1 –≤ model_tp_classes, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
                            logging.error(f"‚ùå –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞: –∫–ª–∞—Å—Å '1' –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –∏–Ω–¥–µ–∫—Å—É, —Ö–æ—Ç—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ model_tp_hit.classes_ ({model_tp_classes}) –¥–ª—è {symbol} {tf}. TP Hit% –±—É–¥–µ—Ç NaN.")
                            tp_hit_proba = np.nan # –û—Å—Ç–∞–µ—Ç—Å—è NaN
                    elif len(tp_hit_proba_all_classes) > 1:
                         # Fallback: –ï—Å–ª–∏ classes_ –Ω–µ—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç 1, –Ω–æ predict_proba –≤–µ—Ä–Ω—É–ª >1 –∑–Ω–∞—á–µ–Ω–∏–µ,
                         # –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –±–∏–Ω–∞—Ä–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –∏ –∫–ª–∞—Å—Å 1 –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø–æ –∏–Ω–¥–µ–∫—Å—É 1
                         logging.warning(f"‚ö†Ô∏è –ö–ª–∞—Å—Å '1' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ model_tp_hit.classes_ ({model_tp_classes if model_tp_classes is not None else 'N/A'}) –¥–ª—è {symbol} {tf}. –ò—Å–ø–æ–ª—å–∑—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ –∏–Ω–¥–µ–∫—Å—É 1.")
                         if len(tp_hit_proba_all_classes) > 1:
                            tp_hit_proba = tp_hit_proba_all_classes[1] # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –∏–Ω–¥–µ–∫—Å 1 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–ª–∞—Å—Å—É 1
                         else:
                             logging.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –≤ predict_proba TP-hit –º–æ–¥–µ–ª–∏ ({len(tp_hit_proba_all_classes)}) –¥–ª—è {symbol} {tf}. TP Hit% –±—É–¥–µ—Ç NaN.")
                             tp_hit_proba = np.nan
                    else:
                         logging.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å TP-hit –¥–ª—è {symbol} {tf} –Ω–µ –∏–º–µ–µ—Ç –∫–ª–∞—Å—Å–∞ '1' –∏ predict_proba –≤–µ—Ä–Ω—É–ª–∞ {len(tp_hit_proba_all_classes)} –∑–Ω–∞—á–µ–Ω–∏–π. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å tp_hit_proba.")
                         # tp_hit_proba –æ—Å—Ç–∞–µ—Ç—Å—è np.nan

                except Exception as e:
                    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ model_tp_hit.predict_proba –¥–ª—è {symbol} {tf}: {e}. TP Hit% –±—É–¥–µ—Ç NaN.")
                    # tp_hit_proba –æ—Å—Ç–∞–µ—Ç—Å—è np.nan


            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–º—É —Å–∏–≥–Ω–∞–ª—É
            direction = 'long' if signal in ['UP', 'STRONG UP'] else 'short' if signal in ['DOWN',
                                                                                           'STRONG DOWN'] else 'none'
            ts_obj = pd.to_datetime(row_df['timestamp'].values[0])
            ts_str_log = ts_obj.strftime('%Y-%m-%d %H:%M:%S')
            ts_str_display = ts_obj.strftime('%Y-%m-%d %H:%M')

            entry_price = float(row_df['close'].values[0])

            # –†–∞—Å—á–µ—Ç SL/TP —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
            sl, tp = calculate_trade_levels(entry_price, direction, predicted_volatility)

            # –†–∞—Å—á–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –¥–µ–ª—å—Ç—ã –∏ —Å–∏–ª—ã —Å–∏–≥–Ω–∞–ª–∞
            delta_final = compute_final_delta(predicted_delta, avg_delta_similar, std_delta_similar)
            signal_strength_val = get_signal_strength(delta_final, confidence, std_delta_similar)
            conflict_flag = is_conflict(predicted_delta, avg_delta_similar)

            # –°–æ–±–∏—Ä–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ –ø–æ—Ä—è–¥–∫–µ TARGET_CLASS_NAMES –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –≤—ã–≤–æ–¥–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            # –ï—Å–ª–∏ –∫–∞–∫–∏–µ-—Ç–æ –∫–ª–∞—Å—Å—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –º–æ–¥–µ–ª–∏, –∏—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –±—É–¥–µ—Ç 0
            proba_dict_ordered = {cls_name: proba_dict_model_order.get(cls_name, 0.0) for cls_name in TARGET_CLASS_NAMES}


            prediction_entry = {
                'symbol': symbol, 'tf': tf, 'timestamp_obj': ts_obj,
                'timestamp_str_log': ts_str_log, 'timestamp_str_display': ts_str_display,
                'signal': signal, 'confidence_score': confidence, 'confidence_hint': hint,
                # 'proba_dict': proba_dict_model_order, # –ò—Å–ø–æ–ª—å–∑—É–µ–º proba_dict_ordered –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –≤—ã–≤–æ–¥–∞
                'proba_dict': proba_dict_ordered,
                'predicted_delta': predicted_delta,
                'predicted_volatility': predicted_volatility, 'entry': entry_price,
                'sl': sl, 'tp': tp, 'direction': direction,
                'avg_delta_similar': avg_delta_similar, 'std_delta_similar': std_delta_similar,
                'similarity_hint': similarity_hint,
                'delta_final': delta_final, 'signal_strength': signal_strength_val, 'conflict': conflict_flag,
                'tp_hit_proba': tp_hit_proba,
                'error': None # –ü–æ–ª–µ –¥–ª—è –±—É–¥—É—â–∏—Ö –æ—à–∏–±–æ–∫ –ø–æ —Å–∏–º–≤–æ–ª—É/–¢–§
            }
            all_predictions_data.append(prediction_entry)

            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –ø–ª–∞–Ω–∞
            # –£—Å–ª–æ–≤–∏–µ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Ç–æ—Ä–≥–æ–≤—ã–π –ø–ª–∞–Ω: –Ω–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞,
            # –∏ TP-hit –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ª–∏–±–æ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞, –ª–∏–±–æ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞.
            TRADE_PLAN_CONFIDENCE_THRESHOLD = 0.08 # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø–ª–∞–Ω–∞
            TRADE_PLAN_TP_HIT_THRESHOLD = 0.55 # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è TP Hit% –¥–ª—è –ø–ª–∞–Ω–∞ (–µ—Å–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞)

            if direction != 'none' and confidence >= TRADE_PLAN_CONFIDENCE_THRESHOLD:
                 if pd.isna(prediction_entry['tp_hit_proba']) or prediction_entry['tp_hit_proba'] >= TRADE_PLAN_TP_HIT_THRESHOLD:
                     rr_value = np.nan # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∫ NaN
                     if pd.notna(sl) and pd.notna(tp):
                         # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ SL –Ω–µ —Ä–∞–≤–µ–Ω Entry (—Å —É—á–µ—Ç–æ–º –æ–∫—Ä—É–≥–ª–µ–Ω–∏—è –∏–ª–∏ –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–æ–π —Ä–∞–∑–Ω–∏—Ü—ã)
                         if abs(entry_price - sl) > 1e-9:
                             try:
                                rr_value = round(abs(tp - entry_price) / abs(entry_price - sl), 2)
                             except ZeroDivisionError:
                                 logging.warning(f"‚ö†Ô∏è –î–µ–ª–µ–Ω–∏–µ –Ω–∞ –Ω–æ–ª—å –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ RR –¥–ª—è {symbol} {tf} (Entry={entry_price}, SL={sl}).")
                                 rr_value = np.nan
                         else:
                             logging.warning(f"‚ö†Ô∏è SL –æ—á–µ–Ω—å –±–ª–∏–∑–∫–æ –∫ —Ü–µ–Ω–µ –≤—Ö–æ–¥–∞ –¥–ª—è {symbol} {tf} (Entry={entry_price}, SL={sl}). –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å RR.")


                     trade_plan.append({
                         'symbol': symbol, 'tf': tf, 'entry': entry_price, 'direction': direction,
                         'sl': sl, 'tp': tp, 'rr': rr_value,
                         'confidence': confidence, 'signal': signal, 'timestamp': ts_str_log, 'hint': hint,
                         'tp_hit_proba': tp_hit_proba
                     })
                 else:
                     tp_hit_display = f"{prediction_entry['tp_hit_proba']:.1%}" if pd.notna(prediction_entry['tp_hit_proba']) else "N/A"
                     logging.debug(f"–ü—Ä–æ–ø—É—Å–∫ {symbol} {tf} –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –ø–ª–∞–Ω–∞: TP Hit ({tp_hit_display}) –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞ {TRADE_PLAN_TP_HIT_THRESHOLD:.1%}.")
            else:
                 logging.debug(f"–ü—Ä–æ–ø—É—Å–∫ {symbol} {tf} –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –ø–ª–∞–Ω–∞: –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ {direction} –∏–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ({confidence:.3f}) –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞ {TRADE_PLAN_CONFIDENCE_THRESHOLD:.3f}.")


    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if save_output_flag and all_predictions_data:
        logging.info("üíæ  –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        df_out_list = []
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º TARGET_CLASS_NAMES –∫–∞–∫ –±–∞–∑–æ–≤—ã–π –ø–æ—Ä—è–¥–æ–∫ –¥–ª—è –∫–æ–ª–æ–Ω–æ–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        proba_dict_keys_order = TARGET_CLASS_NAMES

        for r_item in all_predictions_data:
            item = {
                'symbol': r_item['symbol'], 'tf': r_item['tf'],
                'timestamp': r_item['timestamp_obj'].strftime('%Y-%m-%d %H:%M:%S'),
                'signal': r_item['signal'], 'confidence_score': r_item['confidence_score'],
                'tp_hit_proba': r_item['tp_hit_proba'],
                'predicted_delta': r_item['predicted_delta'],
                'predicted_volatility': r_item['predicted_volatility'],
                'avg_delta_similar': r_item['avg_delta_similar'],
                'std_delta_similar': r_item['std_delta_similar'],
                'delta_final': r_item['delta_final'],
                'entry': r_item['entry'], 'sl': r_item['sl'], 'tp': r_item['tp'],
                'direction': r_item['direction'],
                'signal_strength': r_item['signal_strength'], 'conflict': r_item['conflict'],
                'confidence_hint': r_item['confidence_hint'],
                'similarity_hint': r_item['similarity_hint'],
            }
            # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª—é—á–∏ –∏–∑ proba_dict_ordered,
            # –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å TARGET_CLASS_NAMES
            item.update(r_item['proba_dict'])

            df_out_list.append(item)

        df_out = pd.DataFrame(df_out_list)

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –∑–∞—Ç–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤, –∑–∞—Ç–µ–º –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –ø–æ—è–≤–∏—Ç—å—Å—è
        csv_columns_order = [
            'symbol', 'tf', 'timestamp', 'signal', 'confidence_score', 'tp_hit_proba',
            'predicted_delta', 'avg_delta_similar', 'std_delta_similar', 'delta_final',
            'predicted_volatility', 'entry', 'sl', 'tp', 'direction',
            'signal_strength', 'conflict', 'confidence_hint', 'similarity_hint'
        ]
        csv_columns_order.extend(proba_dict_keys_order) # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–∏ —Ç–∏–ø–∞ 'STRONG DOWN', 'DOWN' –∏ —Ç.–¥.

        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ df_out –≤–∫–ª—é—á–µ–Ω—ã, –¥–∞–∂–µ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç –≤ csv_columns_order
        final_csv_columns = [col for col in csv_columns_order if col in df_out.columns]
        for col in df_out.columns:
            if col not in final_csv_columns:
                final_csv_columns.append(col)

        if not df_out.empty:
            try:
                # –ü–µ—Ä–µ—É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
                df_out = df_out[final_csv_columns]
                df_out.to_csv(LATEST_PREDICTIONS_FILE, index=False, float_format='%.6f')
                logging.info(f"üìÑ  –°–∏–≥–Ω–∞–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {LATEST_PREDICTIONS_FILE}")
            except Exception as e:
                logging.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å {LATEST_PREDICTIONS_FILE}: {e}")
        else:
            logging.info(f"ü§∑ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ {LATEST_PREDICTIONS_FILE}.")

        if trade_plan:
            df_trade_plan = pd.DataFrame(trade_plan)
            trade_plan_cols_order = [
                'symbol', 'tf', 'timestamp', 'direction', 'signal', 'confidence', 'tp_hit_proba',
                'entry', 'sl', 'tp', 'rr', 'hint'
            ]
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ df_trade_plan –≤–∫–ª—é—á–µ–Ω—ã
            final_trade_plan_cols = [col for col in trade_plan_cols_order if col in df_trade_plan.columns]
            for col in df_trade_plan.columns:
                if col not in final_trade_plan_cols:
                    final_trade_plan_cols.append(col)

            if not df_trade_plan.empty:
                try:
                    # –ü–µ—Ä–µ—É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
                    df_trade_plan = df_trade_plan[final_trade_plan_cols]
                    df_trade_plan.to_csv(TRADE_PLAN_FILE, index=False, float_format='%.6f')
                    logging.info(f"üìà  –¢–æ—Ä–≥–æ–≤—ã–π –ø–ª–∞–Ω —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {TRADE_PLAN_FILE}")
                except Exception as e:
                    logging.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å {TRADE_PLAN_FILE}: {e}")
            else:
                logging.info(f"ü§∑ –¢–æ—Ä–≥–æ–≤—ã–π –ø–ª–∞–Ω –ø—É—Å—Ç, —Ñ–∞–π–ª {TRADE_PLAN_FILE} –Ω–µ —Å–æ–∑–¥–∞–Ω.")
        else:
            logging.info("ü§∑ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–≥–æ –ø–ª–∞–Ω–∞.")

    # –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
    if all_predictions_data:
        headers_tabulate = ["TF", "Timestamp", "–°–∏–≥–Ω–∞–ª", "Conf.", "ŒîModel", "ŒîHist", "œÉHist", "ŒîFinal", "–ö–æ–Ω—Ñ?", "–°–∏–ª–∞",
                            "TP Hit%"]
        grouped_by_symbol = {}
        for row_data_item in all_predictions_data:
            grouped_by_symbol.setdefault(row_data_item['symbol'], []).append(row_data_item)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–∏–º–≤–æ–ª—ã –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ –∞–ª—Ñ–∞–≤–∏—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        sorted_symbols_for_display = sorted(grouped_by_symbol.keys())

        for symbol_key in sorted_symbols_for_display:
            rows_list = grouped_by_symbol[symbol_key]
            try:
                # Sort by TIMEFRAMES order, then by confidence score descending
                sorted_rows = sorted(rows_list,
                                     key=lambda r_item_sort: (TIMEFRAMES.index(r_item_sort['tf'])
                                                              if r_item_sort['tf'] in TIMEFRAMES else float('inf'),
                                                              # Handle TFs not in TIMEFRAMES gracefully
                                                              -r_item_sort['confidence_score']))
            except ValueError:
                logging.warning(
                    f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –¥–ª—è {symbol_key}, –≤–æ–∑–º–æ–∂–Ω–æ TF –Ω–µ –≤ —Å–ø–∏—Å–∫–µ TIMEFRAMES. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ç–æ–ª—å–∫–æ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏.")
                sorted_rows = sorted(rows_list, key=lambda r_item_sort: (-r_item_sort['confidence_score']))

            table_data_tabulate = []
            for r_tab in sorted_rows:
                table_data_tabulate.append([
                    r_tab['tf'],
                    r_tab['timestamp_str_display'],
                    r_tab['signal'],
                    f"{r_tab['confidence_score']:.3f}",
                    f"{r_tab['predicted_delta']:.2%}" if pd.notna(r_tab['predicted_delta']) else "N/A",
                    f"{r_tab['avg_delta_similar']:.2%}" if pd.notna(r_tab['avg_delta_similar']) else "N/A",
                    f"{r_tab['std_delta_similar']:.2%}" if pd.notna(r_tab['std_delta_similar']) else "N/A",
                    f"{r_tab['delta_final']:.2%}" if pd.notna(r_tab['delta_final']) else "N/A",
                    "‚ùó" if r_tab['conflict'] else " ",
                    r_tab['signal_strength'].replace(" –°–∏–ª—å–Ω—ã–π", "üü¢").replace(" –£–º–µ—Ä–µ–Ω–Ω—ã–π", "üü°").replace(" –°–ª–∞–±—ã–π",
                                                                                                         "‚ö™"),
                    f"{r_tab['tp_hit_proba']:.1%}" if pd.notna(r_tab['tp_hit_proba']) else "N/A"
                ])
            print(f"\nüìä  –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ —Å–∏–º–≤–æ–ª—É: {symbol_key}")
            try:
                print(tabulate(table_data_tabulate, headers=headers_tabulate, tablefmt="pretty", stralign="right",
                               numalign="right"))
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–≤–æ–¥–µ —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è {symbol_key}: {e}")
                # –ü–æ–ø—Ä–æ–±—É–µ–º –≤—ã–≤–µ—Å—Ç–∏ –ø—Ä–æ—Å—Ç–æ –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ tabulate –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
                print("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É. –î–∞–Ω–Ω—ã–µ:")
                for row in table_data_tabulate:
                    print(row)


    logging.info("‚úÖ  –ü—Ä–æ—Ü–µ—Å—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –∑–∞–≤–µ—Ä—à—ë–Ω.")


if __name__ == '__main__':
    # >>> –ò–ó–ú–ï–ù–ï–ù–û: –ù–æ–≤—ã–π –ø–∞—Ä—Å–µ—Ä –∏ –ª–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∏–∑ –ø–∞—Ç—á–∞
    parser = argparse.ArgumentParser(description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.")
    parser.add_argument('--save',         action='store_true', help="–°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –≤ CSV —Ñ–∞–π–ª—ã.")
    # –û–±–Ω–æ–≤–ª—è–µ–º help —Ç–µ–∫—Å—Ç —Å–æ–≥–ª–∞—Å–Ω–æ –ø–∞—Ç—á—É
    parser.add_argument('--symbol',       type=str, help="–û–¥–∏–Ω —Å–∏–º–≤–æ–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, –Ω–∞–ø—Ä. BTCUSDT (–∏–ª–∏ –≥—Ä—É–ø–ø–∞, –µ—Å–ª–∏ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å top8/meme/defi)")
    parser.add_argument('--symbol-group', type=str, help="–ì—Ä—É–ø–ø–∞ —Å–∏–º–≤–æ–ª–æ–≤, –Ω–∞–ø—Ä. top8 –∏–ª–∏ meme (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω --symbol, —Å–æ–≤–ø–∞–¥–∞—é—â–∏–π —Å –≥—Ä—É–ø–ø–æ–π)") # –û–±–Ω–æ–≤–ª—è–µ–º help –¥–ª—è —è—Å–Ω–æ—Å—Ç–∏
    args = parser.parse_args()

    # –†–∞–∑–≤–æ–¥–∏–º –≤ symbol_filter vs group_filter —Å–æ–≥–ª–∞—Å–Ω–æ –ª–æ–≥–∏–∫–µ –ø–∞—Ç—á–∞
    symbol_filter = None
    group_filter  = None

    if args.symbol and args.symbol_group:
        logging.error("‚ùå –ù–µ–ª—å–∑—è —É–∫–∞–∑—ã–≤–∞—Ç—å –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ --symbol –∏ --symbol-group.")
        sys.exit(1)
    elif args.symbol_group:
        group_filter = args.symbol_group.lower() # –í—Å–µ–≥–¥–∞ –ø—Ä–∏–≤–æ–¥–∏–º –≥—Ä—É–ø–ø—É –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –≥—Ä—É–ø–ø—ã —Ç–µ–ø–µ—Ä—å –∑–¥–µ—Å—å, –ø–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º predict_all_tf
        if group_filter not in GROUP_MODELS:
             logging.error(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –≥—Ä—É–ø–ø–∞ —Å–∏–º–≤–æ–ª–æ–≤: '{args.symbol_group}'. –î–æ—Å—Ç—É–ø–Ω—ã–µ –≥—Ä—É–ø–ø—ã: {list(GROUP_MODELS.keys())}")
             sys.exit(1)

    elif args.symbol:
        # –µ—Å–ª–∏ –≤ --symbol –ø–µ—Ä–µ–¥–∞–Ω–æ –∏–º—è –∏–∑–≤–µ—Å—Ç–Ω–æ–π –≥—Ä—É–ø–ø—ã (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ä–µ–≥–∏—Å—Ç—Ä–∞) ‚Äî —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ group_filter
        symbol_lower = args.symbol.lower()
        if symbol_lower in GROUP_MODELS:
            group_filter = symbol_lower
            logging.info(f"Interpreting --symbol '{args.symbol}' as group '{group_filter}'.")
        else:
            symbol_filter = args.symbol.upper() # –í—Å–µ–≥–¥–∞ –ø—Ä–∏–≤–æ–¥–∏–º —Å–∏–º–≤–æ–ª –∫ –≤–µ—Ä—Ö–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É


    try:
        predict_all_tf(
            args.save,
            symbol_filter=symbol_filter,
            group_filter=group_filter
        )
    except KeyboardInterrupt:
        print("\n[PredictAll] üõë –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C).")
        sys.exit(130)
    except Exception as e:
        logging.error(f"[PredictAll] üí• –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        sys.exit(1)