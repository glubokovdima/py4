import pandas as pd
import joblib
import os
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from datetime import datetime
import argparse
import matplotlib.pyplot as plt
import numpy as np
import sys  # –î–ª—è Ctrl+C
import logging  # –î–ª—è –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s [Backtest] - %(message)s',
                    stream=sys.stdout)

TIMEFRAMES_CHOICES = ['5m', '15m', '30m', '1h', '4h', '1d']  # –î–æ—Å—Ç—É–ø–Ω—ã–µ –¢–§ –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞
FEATURES_PATH_TEMPLATE = 'data/features_{tf}.pkl'
MODEL_PATH_TEMPLATE = 'models/{tf}_{model_type}.pkl'
OUTPUT_DIR_BACKTEST = 'logs'  # –ò—Å–ø–æ–ª—å–∑—É–µ–º LOGS_DIR –∏–ª–∏ —Å–≤–æ—é –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É
OUTPUT_CSV_PATH_TEMPLATE = os.path.join(OUTPUT_DIR_BACKTEST, 'backtest_results_{tf}.csv')
OUTPUT_PLOT_PATH_TEMPLATE = os.path.join(OUTPUT_DIR_BACKTEST, 'backtest_accuracy_{tf}.png')
OUTPUT_CONF_MATRIX_PATH_TEMPLATE = os.path.join(OUTPUT_DIR_BACKTEST, 'backtest_conf_matrix_{tf}.png')

TARGET_CLASS_NAMES = ['STRONG DOWN', 'DOWN', 'NEUTRAL', 'UP', 'STRONG UP']

os.makedirs(OUTPUT_DIR_BACKTEST, exist_ok=True)


def load_model_backtest(tf, model_type):  # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–æ
    path = MODEL_PATH_TEMPLATE.format(tf=tf, model_type=model_type)
    if os.path.exists(path):
        try:
            # logging.debug(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {path}")
            return joblib.load(path)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {path}: {e}")
            return None
    logging.warning(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {path}")
    return None


def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues, tf_suffix=''):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        # logging.info("–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")
    # else:
    # logging.info('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫, –±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏')
    # print(cm) # –í—ã–≤–æ–¥ –º–∞—Ç—Ä–∏—Ü—ã –≤ –∫–æ–Ω—Å–æ–ª—å

    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title + f' ({tf_suffix})')
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in np.ndindex(cm.shape):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

    plot_path = OUTPUT_CONF_MATRIX_PATH_TEMPLATE.format(tf=tf_suffix)
    try:
        plt.savefig(plot_path)
        logging.info(f"–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {plot_path}")
    except Exception as e:
        logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫ {plot_path}: {e}")
    plt.close()


def plot_daily_accuracy(df_result_plot, tf_plot):  # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω—ã –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    if df_result_plot.empty or 'timestamp' not in df_result_plot.columns:
        logging.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ —Å—Ç–æ–ª–±—Ü–∞ 'timestamp' –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ Accuracy –ø–æ –¥–Ω—è–º –¥–ª—è {tf_plot}.")
        return

    df_result_plot['timestamp'] = pd.to_datetime(df_result_plot['timestamp'])
    df_result_plot['date'] = df_result_plot['timestamp'].dt.date

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –∏ —Å—á–∏—Ç–∞–µ–º accuracy –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–Ω—è
    daily_accuracy_data = []
    for date_val, group in df_result_plot.groupby('date'):
        if not group.empty:
            acc = (group['true_label_idx'] == group['pred_label_idx']).sum() / len(group)
            daily_accuracy_data.append({'date': date_val, 'accuracy': acc, 'samples': len(group)})

    if not daily_accuracy_data:
        logging.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ –¥–Ω—è–º –¥–ª—è {tf_plot}.")
        return

    accuracy_by_day_df = pd.DataFrame(daily_accuracy_data)
    accuracy_by_day_df = accuracy_by_day_df.sort_values('date')

    plt.figure(figsize=(12, 6))
    plt.plot(accuracy_by_day_df['date'], accuracy_by_day_df['accuracy'], marker='o', linestyle='-',
             label='Daily Accuracy')

    # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
    if len(accuracy_by_day_df) >= 7:
        accuracy_by_day_df['accuracy_ma_7'] = accuracy_by_day_df['accuracy'].rolling(window=7, min_periods=1).mean()
        plt.plot(accuracy_by_day_df['date'], accuracy_by_day_df['accuracy_ma_7'], linestyle='--',
                 label='7-day MA Accuracy')

    plt.title(f'Accuracy –ø–æ –¥–Ω—è–º ‚Äî {tf_plot}')
    plt.xlabel('–î–∞—Ç–∞')
    plt.ylabel('Accuracy')
    plt.xticks(rotation=45)
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.tight_layout()

    plot_path_val = OUTPUT_PLOT_PATH_TEMPLATE.format(tf=tf_plot)
    try:
        plt.savefig(plot_path_val)
        logging.info(f"–ì—Ä–∞—Ñ–∏–∫ Accuracy –ø–æ –¥–Ω—è–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {plot_path_val}")
    except Exception as e:
        logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ Accuracy {plot_path_val}: {e}")
    plt.close()


def run_backtest(tf_backtest):  # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–æ
    logging.info(f"üöÄ  –ó–∞–ø—É—Å–∫ –±—ç–∫—Ç–µ—Å—Ç–∞ –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞: {tf_backtest}")
    features_file_path = FEATURES_PATH_TEMPLATE.format(tf=tf_backtest)
    if not os.path.exists(features_file_path):
        logging.error(f"–ù–µ—Ç —Ñ–∞–π–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ {features_file_path} –¥–ª—è {tf_backtest}. –ë—ç–∫—Ç–µ—Å—Ç –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
        return pd.DataFrame()

    try:
        df = pd.read_pickle(features_file_path)
    except Exception as e:
        logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ {features_file_path}: {e}. –ü—Ä–æ–ø—É—Å–∫ {tf_backtest}.")
        return pd.DataFrame()

    if df.empty:
        logging.warning(f"–ü—É—Å—Ç–æ–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {tf_backtest}. –ë—ç–∫—Ç–µ—Å—Ç –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
        return pd.DataFrame()

    model_class = load_model_backtest(tf_backtest, 'clf_class')
    if not model_class:
        logging.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å clf_class –¥–ª—è {tf_backtest}. –ë—ç–∫—Ç–µ—Å—Ç –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
        return pd.DataFrame()

    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –æ–±—É—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å
    features_list_path = f"models/{tf_backtest}_features.txt"
    if not os.path.exists(features_list_path):
        logging.error(
            f"–§–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ 'models/{tf_backtest}_features.txt' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ë—ç–∫—Ç–µ—Å—Ç –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω –¥–ª—è {tf_backtest}.")
        return pd.DataFrame()
    try:
        with open(features_list_path, "r", encoding="utf-8") as f:
            feature_cols_from_file = [line.strip() for line in f if line.strip()]
        if not feature_cols_from_file:
            logging.error(f"–§–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ 'models/{tf_backtest}_features.txt' –ø—É—Å—Ç. –ë—ç–∫—Ç–µ—Å—Ç –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
            return pd.DataFrame()
    except Exception as e:
        logging.error(
            f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Å–æ —Å–ø–∏—Å–∫–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ 'models/{tf_backtest}_features.txt': {e}. –ë—ç–∫—Ç–µ—Å—Ç –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
        return pd.DataFrame()

    # logging.debug(f"–î–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞ {tf_backtest} –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏: {feature_cols_from_file}")

    missing_cols_in_df = [col for col in feature_cols_from_file if col not in df.columns]
    if missing_cols_in_df:
        logging.error(
            f"–í DataFrame –∏–∑ {features_file_path} –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã {missing_cols_in_df}, "
            f"–Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ {tf_backtest} (—Å–æ–≥–ª–∞—Å–Ω–æ {features_list_path}). –ë—ç–∫—Ç–µ—Å—Ç –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω."
        )
        return pd.DataFrame()

    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ü–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ –µ—Å—Ç—å
    if 'target_class' not in df.columns:
        logging.error(f"–¶–µ–ª–µ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ 'target_class' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ {features_file_path}. –ë—ç–∫—Ç–µ—Å—Ç –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
        return pd.DataFrame()

    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –∏–ª–∏ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    df_cleaned = df.dropna(subset=feature_cols_from_file + ['target_class']).copy()
    if df_cleaned.empty:
        logging.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ NaN –¥–ª—è {tf_backtest}. –ë—ç–∫—Ç–µ—Å—Ç –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
        return pd.DataFrame()

    X_test_data = df_cleaned[feature_cols_from_file]
    # y_true_named - —ç—Ç–æ –∏–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤ ('UP', 'NEUTRAL', etc.)
    y_true_named = df_cleaned['target_class']

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –º–µ—Ç—Ä–∏–∫ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞ –∏–º–µ–Ω –∫–ª–∞—Å—Å–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å—ã
    class_to_idx = {name: i for i, name in enumerate(TARGET_CLASS_NAMES)}
    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Å–µ y_true_named –µ—Å—Ç—å –≤ TARGET_CLASS_NAMES
    y_true_named = y_true_named[y_true_named.isin(TARGET_CLASS_NAMES)]
    if y_true_named.empty:
        logging.error(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ TARGET_CLASS_NAMES –≤ y_true –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è {tf_backtest}.")
        return pd.DataFrame()

    # –û–±–Ω–æ–≤–ª—è–µ–º X_test_data, —á—Ç–æ–±—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º y_true_named
    X_test_data = X_test_data.loc[y_true_named.index]
    if X_test_data.empty:
        logging.error(f"X_test_data –ø—É—Å—Ç –ø–æ—Å–ª–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è —Å y_true_named –¥–ª—è {tf_backtest}.")
        return pd.DataFrame()

    y_true_indices = y_true_named.map(class_to_idx)

    try:
        probas = model_class.predict_proba(X_test_data)
        y_pred_indices = probas.argmax(axis=1)  # –ò–Ω–¥–µ–∫—Å—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ predict_proba –∏–ª–∏ argmax –¥–ª—è {tf_backtest}: {e}")
        return pd.DataFrame()

    # –†–∞—Å—á–µ—Ç confidence (—Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É —Ç–æ–ø-1 –∏ —Ç–æ–ø-2 –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏)
    if probas.shape[1] < 2:  # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–ª–∞—Å—Å
        confidence_scores = probas.max(axis=1)
    else:
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ —É–±—ã–≤–∞–Ω–∏—é –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
        sorted_probas_desc = -np.sort(-probas, axis=1)  # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é
        confidence_scores = sorted_probas_desc[:, 0] - sorted_probas_desc[:, 1]

    df_result_out = pd.DataFrame({
        'timestamp': df_cleaned.loc[y_true_named.index, 'timestamp'],  # –ë–µ—Ä–µ–º timestamp –æ—Ç –≤—ã—Ä–æ–≤–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        'symbol': df_cleaned.loc[y_true_named.index, 'symbol'],
        'true_label_idx': y_true_indices,
        'pred_label_idx': y_pred_indices,
        'confidence_score': confidence_scores
    })
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
    idx_to_class = {i: name for name, i in class_to_idx.items()}
    df_result_out['true_label_text'] = df_result_out['true_label_idx'].map(idx_to_class)
    df_result_out['pred_label_text'] = df_result_out['pred_label_idx'].map(idx_to_class)

    logging.info(f"\n--- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç—á—ë—Ç ({tf_backtest}) ---")
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º y_true_indices –∏ y_pred_indices –¥–ª—è classification_report
    # target_names –¥–æ–ª–∂–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –ø–æ—Ä—è–¥–∫—É –∏–Ω–¥–µ–∫—Å–æ–≤ 0, 1, 2...
    report = classification_report(y_true_indices, y_pred_indices, target_names=TARGET_CLASS_NAMES, zero_division=0)
    print(report)

    # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
    cm = confusion_matrix(y_true_indices, y_pred_indices, labels=list(range(len(TARGET_CLASS_NAMES))))
    plot_confusion_matrix(cm, classes=TARGET_CLASS_NAMES, title='–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫', tf_suffix=tf_backtest)
    plot_confusion_matrix(cm, classes=TARGET_CLASS_NAMES, normalize=True, title='–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫',
                          tf_suffix=tf_backtest)

    return df_result_out


def analyze_confidence_backtest(df_result_conf, tf_conf):  # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω—ã –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    if df_result_conf.empty:
        logging.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è {tf_conf}.")
        return

    logging.info(f"\n--- –ê–Ω–∞–ª–∏–∑ –ø–æ confidence_score ({tf_conf}) ---")
    bins = [0, 0.05, 0.1, 0.2, 0.4, 1.01]  # –î–æ–±–∞–≤–ª–µ–Ω –±–∏–Ω 0.4-1.0, 1.01 –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è 1.0
    labels = ["<0.05", "0.05-0.1", "0.1-0.2", "0.2-0.4", ">0.4"]
    df_result_conf['conf_group'] = pd.cut(df_result_conf['confidence_score'], bins=bins, labels=labels,
                                          right=False)  # right=False: [0, 0.05)

    results_table = []
    for label_val in labels:
        group_df = df_result_conf[df_result_conf['conf_group'] == label_val]
        if group_df.empty:
            results_table.append((label_val, np.nan, 0, 0))  # –î–æ–±–∞–≤–ª—è–µ–º count –∏ correct_preds
            continue

        correct_preds = (group_df['true_label_idx'] == group_df['pred_label_idx']).sum()
        total_in_group = len(group_df)
        acc = correct_preds / total_in_group if total_in_group > 0 else 0
        results_table.append((label_val, acc, total_in_group, correct_preds))

    print(f"{'–î–∏–∞–ø–∞–∑–æ–Ω Conf.':<15} | {'Accuracy':<9} | {'Samples':<9} | {'Correct':<9}")
    print("-" * 50)
    for label_print, acc_print, n_print, correct_print in results_table:
        acc_str = f"{acc_print:.4f}" if not pd.isna(acc_print) else "N/A"
        print(f"{label_print:<15} | {acc_str:<9} | {n_print:<9} | {correct_print:<9}")


def main_backtest():
    parser = argparse.ArgumentParser(description="–ë—ç–∫—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏.")
    parser.add_argument('--tf', type=str, choices=TIMEFRAMES_CHOICES, required=True,
                        help=f"–¢–∞–π–º—Ñ—Ä–µ–π–º –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {', '.join(TIMEFRAMES_CHOICES)}")
    args = parser.parse_args()

    df_result_main = run_backtest(args.tf)

    if not df_result_main.empty:
        output_csv_file = OUTPUT_CSV_PATH_TEMPLATE.format(tf=args.tf)
        try:
            df_result_main.to_csv(output_csv_file, index=False)
            logging.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—ç–∫—Ç–µ—Å—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_csv_file}")
        except Exception as e:
            logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—ç–∫—Ç–µ—Å—Ç–∞ –≤ {output_csv_file}: {e}")

        plot_daily_accuracy(df_result_main, args.tf)
        analyze_confidence_backtest(df_result_main, args.tf)
    else:
        logging.warning(f"–ë—ç–∫—Ç–µ—Å—Ç –¥–ª—è {args.tf} –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –§–∞–π–ª—ã –∏ –≥—Ä–∞—Ñ–∏–∫–∏ –Ω–µ —Å–æ–∑–¥–∞–Ω—ã.")

    logging.info(f"‚úÖ  –ë—ç–∫—Ç–µ—Å—Ç –¥–ª—è {args.tf} –∑–∞–≤–µ—Ä—à—ë–Ω.")


if __name__ == '__main__':
    try:
        main_backtest()
    except KeyboardInterrupt:
        print("\n[Backtest] üõë –ë—ç–∫—Ç–µ—Å—Ç –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C).")
        sys.exit(130)
    except Exception as e:
        logging.error(f"[Backtest] üí• –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        sys.exit(1)