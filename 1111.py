лючевые выводы и проблемы:
Повторяющаяся ошибка калибровки: Это основная проблема, которую нужно решить. Модель clf_long не калибруется, и вы работаете с потенциально "сырыми" вероятностями.
Причина ошибки калибровки: Скорее всего, на валидационном наборе X_val_for_threshold_sel (который не проходил SMOTE), ваша некалиброванная модель предсказывает только один класс (вероятно, класс 0, так как класс 1 был минорным до SMOTE на обучающей выборке). Это приводит к тому, что predict_proba возвращает массив формы (n_samples, 1), и попытка взять [:, 1] вызывает ошибку.
SMOTE применяется к X_cv_pool_full: Финальная модель обучается на данных после SMOTE (если apply_smote_final истинно). Валидационный набор для порога/калибровки (X_val_for_threshold_sel) берется из оригинального X_cv_pool_full до SMOTE. Это правильный подход: калибровка и подбор порога должны выполняться на данных, которые не были искусственно изменены оверсемплингом.
Высокий F1 на валидации (0.8958 с порогом 0.17 для некалиброванной модели): Это очень хороший показатель, но его нужно воспринимать с осторожностью из-за провала калибровки.
Permutation Importance: volume_btc снова показывает отрицательную важность, его стоит исключить для clf_long на 30m/top15.
Рекомендации по исправлению ошибки калибровки:
Проверьте распределение классов в y_val_for_threshold:
Добавьте лог перед калибровкой:
logging.info(f"Данные для калибровки {model_log_prefix}: X_shape={X_val_for_threshold_sel.shape}, y_shape={y_val_for_threshold.shape}, y_classes={y_val_for_threshold.value_counts().to_dict()}")
if y_val_for_threshold.nunique() < 2:
    logging.warning(f"Пропуск калибровки: в y_val_for_threshold только один класс.")
    # ... пропустить калибровку ...
Use code with caution.
Python
Если там действительно только один класс, то калибровка невозможна. Это может означать, что ваш X_val_for_threshold слишком мал или очень специфичен.
Попробуйте method='sigmoid' для CalibratedClassifierCV:
Это более робастный метод, который может сработать, даже если isotonic падает.
calibrated_clf = CalibratedClassifierCV(final_model_uncalibrated, method='sigmoid', cv=None)
Use code with caution.
Python
Убедитесь, что final_model_uncalibrated обучена с eval_set имеющим два класса:
Если eval_set_for_final_fit (который является X_val_for_threshold_sel) имел только один класс во время final_model_uncalibrated.fit(), модель могла "специализироваться" на этом одном классе. Проверьте логику формирования eval_set_for_final_fit.
Если X_val_for_threshold_sel слишком мал или несбалансирован:
Рассмотрите возможность не выделять X_val_for_threshold_sel из X_cv_pool_full, а использовать для калибровки и подбора порога данные, полученные на out-of-fold предсказаниях TimeSeriesSplit внутри Optuna HPO. Это более сложный подход, но он использует все данные CV-пула для оценки.
Или, как крайняя мера, если валидационный набор для порога/калибровки систематически плох, можно попробовать подобрать порог и откалибровать на обучающей выборке после SMOTE (X_train_for_final_model_sel, y_train_for_final_model_target), но это приведет к оптимистичным оценкам и риску переобучения порога/калибровки. Это следует делать только для отладки, понимая последствия.
Приоритет сейчас – исправить ошибку калибровки. Попробуйте method='sigmoid' и проверьте данные в y_val_for_threshold.






