import sqlite3
import pandas as pd
import numpy as np
import ta
import os
import argparse
from tqdm import tqdm
import sys  # –î–ª—è Ctrl+C
import logging
from ta.volatility import BollingerBands  # üìä [2] –ò–º–ø–æ—Ä—Ç –¥–ª—è BollingerBands

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —ç—Ç–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞
logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s [Preprocess] - %(message)s',
                    stream=sys.stdout)

DB_PATH = 'database/market_data.db'
TARGET_SHIFT = 5
TP_THRESHOLD = 0.005


def load_candles_from_db(tf_key):
    logging.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Å–≤–µ—á–µ–π –∏–∑ candles_{tf_key}...")
    if not os.path.exists(DB_PATH):
        logging.error(f"–§–∞–π–ª –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö {DB_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return pd.DataFrame()

    conn = sqlite3.connect(DB_PATH)
    try:
        cursor = conn.cursor()
        cursor.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='candles_{tf_key}';")
        if cursor.fetchone() is None:
            logging.error(f"–¢–∞–±–ª–∏—Ü–∞ 'candles_{tf_key}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö {DB_PATH}.")
            return pd.DataFrame()

        df = pd.read_sql_query(f"SELECT * FROM candles_{tf_key}", conn)
        if df.empty:
            logging.warning(f"–¢–∞–±–ª–∏—Ü–∞ candles_{tf_key} –ø—É—Å—Ç–∞.")
            return pd.DataFrame()

        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df = df.sort_values(['symbol', 'timestamp']).reset_index(drop=True)
        logging.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å–≤–µ—á–µ–π –∏–∑ candles_{tf_key} –¥–ª—è {df['symbol'].nunique()} —Å–∏–º–≤–æ–ª–æ–≤.")
        return df
    except pd.io.sql.DatabaseError as e:
        logging.error(f"–û—à–∏–±–∫–∞ SQL –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ candles_{tf_key}: {e}")
        return pd.DataFrame()
    except Exception as e:
        logging.error(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å–≤–µ—á–µ–π –¥–ª—è {tf_key}: {e}")
        return pd.DataFrame()
    finally:
        conn.close()


def classify_delta_value(delta_val):
    if pd.isna(delta_val): return np.nan
    if delta_val > 0.002:
        return 'UP'
    elif delta_val < -0.002:
        return 'DOWN'
    else:
        return np.nan


def compute_ta_features(df_group):
    # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –ê–Ω–∞–ª–∏–∑–∞
    # RSI
    df_group['rsi'] = ta.momentum.RSIIndicator(close=df_group['close'], window=14).rsi()
    # EMA
    df_group['ema_20'] = ta.trend.EMAIndicator(close=df_group['close'], window=20).ema_indicator()
    df_group['ema_50'] = ta.trend.EMAIndicator(close=df_group['close'], window=50).ema_indicator()
    # MACD
    macd_indicator = ta.trend.MACD(close=df_group['close'], window_slow=26, window_fast=12, window_sign=9)
    df_group['macd'] = macd_indicator.macd()
    df_group['macd_signal'] = macd_indicator.macd_signal()
    df_group['macd_diff'] = macd_indicator.macd_diff()
    # OBV (On-Balance Volume)
    df_group['obv'] = ta.volume.OnBalanceVolumeIndicator(close=df_group['close'],
                                                         volume=df_group['volume']).on_balance_volume()
    # ATR (Average True Range)
    df_group['atr'] = ta.volatility.AverageTrueRange(high=df_group['high'], low=df_group['low'],
                                                     close=df_group['close'], window=14).average_true_range()

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ)
    df_group['volume_z'] = (df_group['volume'] - df_group['volume'].rolling(window=20, min_periods=1).mean()) / \
                           (df_group['volume'].rolling(window=20, min_periods=1).std().replace(0, np.nan))
    # üìâ [1] –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ volume_z
    df_group['volume_z'] = df_group['volume_z'].clip(-5, 5)

    df_group['candle_body_size'] = abs(df_group['close'] - df_group['open'])
    df_group['candle_hl_range'] = df_group['high'] - df_group['low']
    df_group['is_doji'] = ((df_group['candle_body_size'] / (df_group['candle_hl_range'] + 1e-9)) < 0.1).astype(int)

    if isinstance(df_group.index, pd.DatetimeIndex):
        df_group['hour'] = df_group.index.hour
        df_group['minute'] = df_group.index.minute
        df_group['dayofweek'] = df_group.index.dayofweek
        df_group['dayofmonth'] = df_group.index.day
        df_group['weekofyear'] = df_group.index.isocalendar().week.astype(int)
    else:
        for col in ['hour', 'dayofweek']:
            if col not in df_group.columns:
                df_group[col] = np.nan

    df_group['ema_20_slope'] = df_group['ema_20'].diff()
    df_group['ema_50_slope'] = df_group['ema_50'].diff()

    if 'rsi' in df_group.columns and len(df_group['rsi']) > 1:
        df_group['rsi_cross_50'] = ((df_group['rsi'] > 50) & (df_group['rsi'].shift(1) <= 50)).astype(int)
    else:
        df_group['rsi_cross_50'] = 0

    if all(col in df_group.columns for col in ['high', 'open', 'close', 'low']):
        wick_up = df_group['high'] - df_group[['open', 'close']].max(axis=1)
        wick_down = df_group[['open', 'close']].min(axis=1) - df_group['low']
        body = abs(df_group['close'] - df_group['open'])
        df_group['pin_bar'] = ((wick_up > (body * 2 + 1e-9)) | (wick_down > (body * 2 + 1e-9))).astype(int)
    else:
        df_group['pin_bar'] = 0

    # –ù–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    if 'ema_20' in df_group.columns and 'ema_50' in df_group.columns:
        df_group['ema_diff'] = df_group['ema_20'] - df_group['ema_50']
    else:
        df_group['ema_diff'] = np.nan

    if 'rsi' in df_group.columns:
        df_group['rsi_change_3'] = df_group['rsi'].diff(3)
    else:
        df_group['rsi_change_3'] = np.nan

    if 'volume' in df_group.columns:
        df_group['volume_mean'] = df_group['volume'].rolling(window=20).mean()
        df_group['volume_std'] = df_group['volume'].rolling(window=20).std()
        df_group['volume_spike'] = ((df_group['volume'] - df_group['volume_mean']) > 2 * df_group['volume_std']).astype(
            int)
    else:
        df_group['volume_mean'] = np.nan
        df_group['volume_std'] = np.nan
        df_group['volume_spike'] = 0

    if 'hour' in df_group.columns:
        df_group['hour_sin'] = np.sin(2 * np.pi * df_group['hour'] / 24)
    else:
        df_group['hour_sin'] = np.nan

    if 'dayofweek' in df_group.columns:
        df_group['dayofweek_sin'] = np.sin(2 * np.pi * df_group['dayofweek'] / 7)
    else:
        df_group['dayofweek_sin'] = np.nan

    # üìä [2] –î–æ–±–∞–≤–ª–µ–Ω–∏–µ bb_width (—à–∏—Ä–∏–Ω–∞ –ë–æ–ª–ª–∏–Ω–¥–∂–µ—Ä–∞)
    if 'close' in df_group.columns and len(df_group['close']) >= 20:  # BollingerBands —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
        try:
            bb = BollingerBands(close=df_group['close'], window=20, window_dev=2)
            df_group['bb_width'] = bb.bollinger_hband() - bb.bollinger_lband()
            # –¢–∞–∫–∂–µ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø–æ–ª–æ–∂–µ–Ω–∏—è —Ü–µ–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–æ–ª–æ—Å, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            # df_group['bb_pband'] = bb.bollinger_pband() # –ü—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ —Ü–µ–Ω—ã –≤–Ω—É—Ç—Ä–∏ –ø–æ–ª–æ—Å
            # df_group['bb_wband'] = bb.bollinger_wband() # –®–∏—Ä–∏–Ω–∞ –ø–æ–ª–æ—Å, –Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ —Å—Ä–µ–¥–Ω—é—é –ª–∏–Ω–∏—é
        except Exception as e:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å Bollinger Bands: {e}")
            df_group['bb_width'] = np.nan
    else:
        df_group['bb_width'] = np.nan

    return df_group


def compute_and_prepare_features(df_input, tf_name, btc_features_df):
    logging.info(f"–ù–∞—á–∞–ª–æ —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {df_input['symbol'].nunique()} —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ –¢–§ {tf_name}...")
    all_symbols_features = []

    for symbol_val in tqdm(df_input['symbol'].unique(), desc=f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {tf_name}", unit="symbol"):
        df_sym = df_input[df_input['symbol'] == symbol_val].copy()
        df_sym = df_sym.set_index('timestamp')

        if len(df_sym) < 100:
            logging.info(
                f"–°–∏–º–≤–æ–ª {symbol_val} –Ω–∞ –¢–§ {tf_name} –∏–º–µ–µ—Ç —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö ({len(df_sym)} < 100), –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è.")
            continue

        df_sym['log_return_1'] = np.log(df_sym['close'] / df_sym['close'].shift(1))
        df_sym['future_close'] = df_sym['close'].shift(-TARGET_SHIFT)
        df_sym['delta'] = (df_sym['future_close'] / df_sym['close']) - 1

        future_max_high = df_sym['high'].rolling(window=TARGET_SHIFT).max().shift(-TARGET_SHIFT + 1)
        future_min_low = df_sym['low'].rolling(window=TARGET_SHIFT).min().shift(-TARGET_SHIFT + 1)
        df_sym['volatility'] = (future_max_high - future_min_low) / df_sym['close']

        df_sym['target_up'] = (df_sym['delta'] > 0).astype(int)
        df_sym['target_class'] = df_sym['delta'].apply(classify_delta_value)

        df_sym['target_tp_hit'] = (df_sym['delta'] > TP_THRESHOLD).astype(int)

        df_sym = compute_ta_features(df_sym.copy())

        if btc_features_df is not None and not btc_features_df.empty:
            df_sym = df_sym.merge(btc_features_df, left_index=True, right_index=True, how='left', suffixes=('', '_btc'))
            btc_cols_to_ffill = [col for col in df_sym.columns if '_btc' in col]
            if btc_cols_to_ffill:
                df_sym[btc_cols_to_ffill] = df_sym[btc_cols_to_ffill].ffill()

        if 'atr' in df_sym.columns and 'volume' in df_sym.columns:
            condition_volume = df_sym['volume'] > df_sym['volume'].rolling(window=20).mean()
            condition_atr = df_sym['atr'] > df_sym['atr'].rolling(window=20).mean()
            df_sym_filtered = df_sym[condition_volume & condition_atr]

            if len(df_sym_filtered) < len(df_sym):
                logging.debug(
                    f"–î–ª—è {symbol_val} –Ω–∞ {tf_name} –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(df_sym) - len(df_sym_filtered)} —Å—Ç—Ä–æ–∫ –∏–∑-–∑–∞ —Ñ–ª—ç—Ç–∞/—Å–ª–∞–±—ã—Ö —É—á–∞—Å—Ç–∫–æ–≤.")
            df_sym = df_sym_filtered
        else:
            logging.warning(
                f"–ü—Ä–æ–ø—É—Å–∫ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ñ–ª—ç—Ç–∞ –¥–ª—è {symbol_val} –Ω–∞ {tf_name}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ 'atr' –∏–ª–∏ 'volume'.")

        if not df_sym.empty:
            df_sym['symbol'] = symbol_val
            all_symbols_features.append(df_sym)
        else:
            logging.info(
                f"–°–∏–º–≤–æ–ª {symbol_val} –Ω–∞ –¢–§ {tf_name} —Å—Ç–∞–ª –ø—É—Å—Ç—ã–º –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ñ–ª—ç—Ç–∞/—Å–ª–∞–±—ã—Ö —É—á–∞—Å—Ç–∫–æ–≤ –∏ –Ω–µ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω.")

    if not all_symbols_features:
        logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ –Ω–∞ –¢–§ {tf_name}.")
        return pd.DataFrame()

    full_features_df = pd.concat(all_symbols_features)

    cols_for_dropna = ['delta', 'volatility', 'target_class', 'rsi', 'target_tp_hit',
                       'ema_20_slope', 'ema_50_slope']
    # –ï—Å–ª–∏ 'bb_width' –∫—Ä–∏—Ç–∏—á–µ–Ω, –µ–≥–æ —Ç–æ–∂–µ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ cols_for_dropna,
    # –Ω–æ —ç—Ç–æ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ —É–¥–∞–ª–µ–Ω–∏—é —Å—Ç—Ä–æ–∫, –≥–¥–µ –æ–Ω –Ω–µ —Å–º–æ–≥ –±—ã—Ç—å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ –Ω–∞—á–∞–ª–µ –¥–∞—Ç–∞—Å–µ—Ç–∞).
    # cols_for_dropna.append('bb_width')

    len_before_dropna = len(full_features_df)
    full_features_df = full_features_df.dropna(subset=cols_for_dropna)
    len_after_dropna = len(full_features_df)
    logging.info(
        f"–£–¥–∞–ª–µ–Ω–æ {len_before_dropna - len_after_dropna} —Å—Ç—Ä–æ–∫ –∏–∑-–∑–∞ NaN –≤ –∫–ª—é—á–µ–≤—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö (–≤–∫–ª—é—á–∞—è target_class).")

    full_features_df = full_features_df.reset_index()
    logging.info(f"–†–∞—Å—á–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {tf_name} –∑–∞–≤–µ—Ä—à–µ–Ω. –ò—Ç–æ–≥–æ —Å—Ç—Ä–æ–∫: {len(full_features_df)}.")
    return full_features_df


def main_preprocess(tf_arg):
    logging.info(f"‚öôÔ∏è  –ù–∞—á–∞–ª–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞: {tf_arg}")

    df_all_candles = load_candles_from_db(tf_arg)
    if df_all_candles.empty:
        logging.error(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î –¥–ª—è {tf_arg}. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–µ—Ä–≤–∞–Ω–æ.")
        return

    btc_features_prepared = None
    if 'BTCUSDT' in df_all_candles['symbol'].unique():
        logging.info("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ BTCUSDT –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö –ø–∞—Ä–∞—Ö...")
        df_btc_raw = df_all_candles[df_all_candles['symbol'] == 'BTCUSDT'].copy()
        df_btc_raw = df_btc_raw.set_index('timestamp')

        if len(df_btc_raw) >= 50:
            df_btc_raw['log_return_1_btc'] = np.log(df_btc_raw['close'] / df_btc_raw['close'].shift(1))
            df_btc_raw['rsi_btc'] = ta.momentum.RSIIndicator(close=df_btc_raw['close'], window=14).rsi()
            df_btc_raw['volume_btc'] = df_btc_raw['volume']
            btc_features_prepared = df_btc_raw[['log_return_1_btc', 'rsi_btc', 'volume_btc']].shift(1)
            btc_features_prepared.dropna(inplace=True)
            logging.info(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ BTCUSDT –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã. –°—Ç—Ä–æ–∫: {len(btc_features_prepared)}")
        else:
            logging.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è BTCUSDT ({len(df_btc_raw)} —Å—Ç—Ä–æ–∫) –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.")
    else:
        logging.warning("–î–∞–Ω–Ω—ã–µ –ø–æ BTCUSDT –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Å–≤–µ—á–∞—Ö. –ü—Ä–∏–∑–Ω–∞–∫–∏ BTC –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –Ω–µ –±—É–¥—É—Ç.")

    df_to_process = df_all_candles

    if df_to_process.empty and btc_features_prepared is None:
        logging.error(
            f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –¢–§ {tf_arg} (–≤–æ–∑–º–æ–∂–Ω–æ, –±—ã–ª —Ç–æ–ª—å–∫–æ BTCUSDT —Å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö).")
        return

    df_final_features = compute_and_prepare_features(df_to_process, tf_arg, btc_features_prepared)

    if df_final_features.empty:
        logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {tf_arg}, —Ç–∞–∫ –∫–∞–∫ –∏—Ç–æ–≥–æ–≤—ã–π DataFrame –ø—É—Å—Ç.")
        return

    os.makedirs('data', exist_ok=True)
    output_pickle_path = f"data/features_{tf_arg}.pkl"
    output_sample_csv_path = f"data/sample_{tf_arg}.csv"

    try:
        df_final_features.to_pickle(output_pickle_path)
        logging.info(f"üíæ  –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_pickle_path}, —Ñ–æ—Ä–º–∞: {df_final_features.shape}")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è Pickle —Ñ–∞–π–ª–∞ {output_pickle_path}: {e}")

    try:
        sample_size = min(1000, len(df_final_features))
        if sample_size > 0:
            df_final_features.head(sample_size).to_csv(output_sample_csv_path, index=False)
            logging.info(f"üìÑ  –°—ç–º–ø–ª –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_sample_csv_path} ({sample_size} —Å—Ç—Ä–æ–∫)")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è CSV —Å—ç–º–ø–ª–∞ {output_sample_csv_path}: {e}")

    logging.info(f"‚úÖ  –ó–∞–≤–µ—Ä—à–µ–Ω–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞: {tf_arg}")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö —Å–≤–µ—á–µ–π –∏–∑ SQLite.")
    parser.add_argument('--tf', type=str, required=True, help='–¢–∞–π–º—Ñ—Ä–µ–π–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 5m, 15m)')
    args = parser.parse_args()

    try:
        main_preprocess(args.tf)
    except KeyboardInterrupt:
        print(f"\n[Preprocess] üõë –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {args.tf} –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C).")
        sys.exit(130)
    except Exception as e:
        logging.error(f"[Preprocess] üí• –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {args.tf}: {e}", exc_info=True)
        sys.exit(1)