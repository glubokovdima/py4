import pandas as pd
import numpy as np
import argparse
import os
from catboost import CatBoostClassifier, CatBoostRegressor, Pool, cv
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import classification_report, mean_absolute_error, accuracy_score
from sklearn.metrics import f1_score, precision_score, confusion_matrix
# ‚úÖ –ò–º–ø–æ—Ä—Ç –¥–ª—è ROC AUC
from sklearn.metrics import roc_auc_score
import joblib
import sys
import logging
from sklearn.metrics import average_precision_score
import random
import json  # Added for Change 3

SYMBOL_GROUPS = {
    "top8": [
        "BTCUSDT", "ETHUSDT", "BNBUSDT", "SOLUSDT",
        "XRPUSDT", "ADAUSDT", "LINKUSDT", "AVAXUSDT"
    ],
    "meme": [
        "DOGEUSDT", "PEPEUSDT", "FLOKIUSDT", "WIFUSDT", "SHIBUSDT"
    ]
}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s [TrainModel] - %(message)s',
                    stream=sys.stdout)

# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
os.makedirs("models", exist_ok=True)
os.makedirs("logs", exist_ok=True)

TARGET_CLASS_NAMES = ['DOWN', 'UP']  # For display purposes in reports
PREDICT_PROBA_THRESHOLD_CLASS = 0.55


def train_all_models(tf_train, symbol=None):  # Added symbol argument
    """
    –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª–∏ CatBoost –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ –∏/–∏–ª–∏ —Å–∏–º–≤–æ–ª–∞.

    Args:
        tf_train (str): –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, '1m', '5m').
        symbol (str, optional): –°–∏–º–≤–æ–ª, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ –æ–±—É—á–∞—é—Ç—Å—è –º–æ–¥–µ–ª–∏.
                                 –ï—Å–ª–∏ None, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è –≥—Ä—É–ø–ø–æ–≤–∞—è –º–æ–¥–µ–ª—å.
                                 Defaults to None.
    """
    # Define a prefix for filenames based on symbol and timeframe
    file_prefix = f"{symbol}_{tf_train}" if symbol else tf_train

    # Define a string for logging context
    log_context_str = f"—Ç–∞–π–º—Ñ—Ä–µ–π–º–∞: {tf_train}"
    if symbol:
        log_context_str += f", —Å–∏–º–≤–æ–ª–∞: {symbol}"

    logging.info(f"üöÄ  –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –¥–ª—è {log_context_str}")

    # Load features based on symbol
    if symbol:
        features_path = f"data/features_{symbol}_{tf_train}.pkl"
    else:
        features_path = f"data/features_{tf_train}.pkl"

    if not os.path.exists(features_path):
        logging.error(f"–§–∞–π–ª –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ {features_path} –Ω–µ –Ω–∞–π–¥–µ–Ω. –û–±—É—á–µ–Ω–∏–µ –¥–ª—è {log_context_str} –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.")
        return

    try:
        df = pd.read_pickle(features_path)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ {features_path}: {e}")
        return

    if df.empty:
        logging.error(f"–§–∞–π–ª –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ {features_path} –ø—É—Å—Ç. –û–±—É—á–µ–Ω–∏–µ –¥–ª—è {log_context_str} –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.")
        return

    required_cols_for_dropna = ['target_class', 'delta', 'volatility']
    target_tp_hit_col = 'target_tp_hit'

    train_tp_hit_model_flag = False
    use_stratified_cv_for_tp_hit = False

    if target_tp_hit_col in df.columns:
        logging.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ '{target_tp_hit_col}'. –ü–æ–ø—ã—Ç–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ TP-hit –¥–ª—è {log_context_str}.")
        if df[target_tp_hit_col].isnull().all() or df[target_tp_hit_col].nunique() < 2:
            logging.warning(
                f"–ö–æ–ª–æ–Ω–∫–∞ '{target_tp_hit_col}' —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ NaN –∏–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ. –ú–æ–¥–µ–ª—å TP-hit –ù–ï –±—É–¥–µ—Ç –æ–±—É—á–µ–Ω–∞ –¥–ª—è {log_context_str}.")
        elif df[target_tp_hit_col].value_counts().min() < 10:
            logging.warning(
                f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –æ–¥–Ω–æ–º –∏–∑ –∫–ª–∞—Å—Å–æ–≤ '{target_tp_hit_col}' ({df[target_tp_hit_col].value_counts().to_dict()}) –¥–ª—è {log_context_str}. "
                f"Stratified CV –¥–ª—è TP-hit –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–æ –∏–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –±—É–¥–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º."
            )
            train_tp_hit_model_flag = True
            use_stratified_cv_for_tp_hit = False
        else:
            train_tp_hit_model_flag = True
            use_stratified_cv_for_tp_hit = True
            logging.info(
                f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ '{target_tp_hit_col}' (–¥–æ –æ—á–∏—Å—Ç–∫–∏ NaN) –¥–ª—è {log_context_str}: {df[target_tp_hit_col].value_counts().to_dict()}")
        required_cols_for_dropna.append(target_tp_hit_col)
    else:
        logging.warning(
            f"–ö–æ–ª–æ–Ω–∫–∞ '{target_tp_hit_col}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {features_path}. "
            f"–ú–æ–¥–µ–ª—å TP-hit (clf_tp_hit) –ù–ï –±—É–¥–µ—Ç –æ–±—É—á–µ–Ω–∞ –¥–ª—è {log_context_str}."
        )

    df_cleaned = df.dropna(subset=required_cols_for_dropna).copy()
    if df_cleaned.empty:
        logging.error(
            f"DataFrame –ø—É—Å—Ç –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è NaN –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º {required_cols_for_dropna} –¥–ª—è {log_context_str}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.")
        return

    logging.info(f"–†–∞–∑–º–µ—Ä DataFrame –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ NaN –¥–ª—è {log_context_str}: {df_cleaned.shape}")
    if train_tp_hit_model_flag and target_tp_hit_col in df_cleaned.columns:
        logging.info(
            f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ '{target_tp_hit_col}' (–ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ NaN) –¥–ª—è {log_context_str}: {df_cleaned[target_tp_hit_col].value_counts().to_dict()}")
        if df_cleaned[target_tp_hit_col].nunique() < 2 or df_cleaned[
            target_tp_hit_col].value_counts().min() < 5:
            logging.warning(
                f"–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ NaN, –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–ª–∏ –∫–ª–∞—Å—Å–æ–≤ –≤ '{target_tp_hit_col}' ({df_cleaned[target_tp_hit_col].value_counts().to_dict()}) –¥–ª—è {log_context_str}. "
                f"Stratified CV –¥–ª—è TP-hit –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–æ."
            )
            use_stratified_cv_for_tp_hit = False

    excluded_cols_for_features = ['timestamp', 'symbol', 'target_class', 'delta', 'volatility', 'future_close']
    # Ensure 'symbol' column is excluded if it exists, especially if symbol is part of features_path name
    # but the actual features might still contain a 'symbol' column from data generation.
    if 'symbol' not in excluded_cols_for_features:
        excluded_cols_for_features.append('symbol')

    if train_tp_hit_model_flag and target_tp_hit_col in df_cleaned.columns:
        excluded_cols_for_features.append(target_tp_hit_col)

    potential_leak_cols = ['target_up']
    for col in potential_leak_cols:
        if col not in excluded_cols_for_features:
            excluded_cols_for_features.append(col)

    feature_cols_initial = [col for col in df_cleaned.columns if
                            col not in excluded_cols_for_features and df_cleaned[col].dtype in [np.int64, np.float64,
                                                                                                np.int32, np.float32,
                                                                                                bool]]
    feature_cols_initial = [col for col in feature_cols_initial if not pd.api.types.is_datetime64_any_dtype(
        df_cleaned[col]) and not pd.api.types.is_string_dtype(df_cleaned[col])]

    if not feature_cols_initial:
        logging.error(
            f"–ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Ü–µ–ª–µ–≤—ã—Ö –∏ —Å–ª—É–∂–µ–±–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è {log_context_str}.")
        return

    logging.info(
        f"–ù–∞—á–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ({log_context_str}): {len(feature_cols_initial)}. –ü–µ—Ä–≤—ã–µ 5: {feature_cols_initial[:5]}")

    X_all_data = df_cleaned[feature_cols_initial]
    y_class_all = df_cleaned['target_class']
    y_delta_all = df_cleaned['delta']
    y_vol_all = df_cleaned['volatility']
    y_tp_hit_all = df_cleaned[
        target_tp_hit_col] if train_tp_hit_model_flag and target_tp_hit_col in df_cleaned.columns else None

    if X_all_data.empty:
        logging.error(
            f"DataFrame X_all_data (–ø—Ä–∏–∑–Ω–∞–∫–∏) –ø—É—Å—Ç –¥–ª—è {log_context_str}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ feature_cols_initial –∏ –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
        return

    if len(X_all_data) < 20:
        logging.error(
            f"–°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö ({len(X_all_data)}) –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ train/test –¥–ª—è {log_context_str}. –û–±—É—á–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.")
        return

    try:
        # ‚úÖ 4. train_test_split —Å–æ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –∏ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ–º
        # Split data for classification, delta, and volatility models
        X_train_cv_pool, X_test_full, y_class_train_cv_pool, y_test_class, \
            y_delta_train_cv_pool, y_test_delta, y_vol_train_cv_pool, y_test_vol = train_test_split(
            X_all_data, y_class_all, y_delta_all, y_vol_all,
            test_size=0.15, random_state=42, shuffle=True, stratify=y_class_all
        )

        X_cv_pool = X_train_cv_pool
        y_class_cv_pool = y_class_train_cv_pool  # At this point, these are string labels

        X_train_full = X_train_cv_pool
        y_train_class = y_class_train_cv_pool  # At this point, these are string labels
        y_train_delta = y_delta_train_cv_pool
        y_train_vol = y_vol_train_cv_pool

        # Split data for TP-hit model if applicable
        if train_tp_hit_model_flag and y_tp_hit_all is not None:
            try:
                # Stratify TP-hit split if possible, else use the same split indices
                if use_stratified_cv_for_tp_hit and y_tp_hit_all.nunique() >= 2 and y_tp_hit_all.value_counts().min() >= 5:
                    # Perform a separate split for TP-hit if stratification is viable
                    # Note: This means TP-hit test set might be slightly different rows
                    # from class/delta/vol test sets, or we re-split the train/CV pool
                    # Let's stick to using the same train/test split indices for consistency
                    # and just locate the TP-hit targets based on those indices.
                    y_tp_hit_train_cv_pool = y_tp_hit_all.loc[X_train_cv_pool.index]
                    y_test_tp_hit = y_tp_hit_all.loc[X_test_full.index]
                    y_tp_hit_cv_pool = y_tp_hit_train_cv_pool # Use the same split for TP-hit CV pool
                    y_train_tp_hit = y_tp_hit_train_cv_pool # Use the same split for TP-hit train

                else:
                    # If stratification is not viable for TP-hit, just use indices from the main split
                    y_tp_hit_train_cv_pool = y_tp_hit_all.loc[X_train_cv_pool.index]
                    y_test_tp_hit = y_tp_hit_all.loc[X_test_full.index]
                    y_tp_hit_cv_pool = y_tp_hit_train_cv_pool
                    y_train_tp_hit = y_tp_hit_train_cv_pool
                    if use_stratified_cv_for_tp_hit: # Log if we intended to stratify but couldn't
                         logging.warning(f"Stratification for TP-hit split requested but not possible ({log_context_str}). Using non-stratified split indices.")
                         use_stratified_cv_for_tp_hit = False # Update flag

                if not y_train_tp_hit.empty:
                    logging.info(
                        f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ y_train_tp_hit ({log_context_str}): {y_train_tp_hit.value_counts().to_dict()}")
                if not y_test_tp_hit.empty:
                    logging.info(
                        f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ y_test_tp_hit ({log_context_str}): {y_test_tp_hit.value_counts().to_dict()}")
                if not y_tp_hit_cv_pool.empty:
                     logging.info(
                        f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ y_tp_hit_cv_pool ({log_context_str}): {y_tp_hit_cv_pool.value_counts().to_dict()}")


            except Exception as e:
                 logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–¥–µ–ª–µ–Ω–∏–∏ y_tp_hit –≤—ã–±–æ—Ä–æ–∫ –¥–ª—è {log_context_str}: {e}", exc_info=True)
                 y_train_tp_hit, y_test_tp_hit, y_tp_hit_cv_pool = None, None, None
                 train_tp_hit_model_flag = False # Disable TP-hit training if data extraction fails
        else:
            y_train_tp_hit, y_test_tp_hit, y_tp_hit_cv_pool = None, None, None
            train_tp_hit_model_flag = False


    except ValueError as e:
        logging.error(
            f"–û—à–∏–±–∫–∞ ValueError –ø—Ä–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {log_context_str}: {e}. –í–æ–∑–º–æ–∂–Ω–æ, —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏.")
        return
    except Exception as e:
        logging.error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {log_context_str}: {e}", exc_info=True)
        return

    logging.info(f"–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ target_class –≤ 0/1 (DOWN=0, UP=1) –¥–ª—è {log_context_str}...")
    label_mapping = {'DOWN': 0, 'UP': 1}

    # Apply mapping carefully, checking for empty series
    if not df_cleaned['target_class'].empty:
        y_class_all_mapped = df_cleaned['target_class'].map(label_mapping)
    else:
        y_class_all_mapped = pd.Series([], dtype=int) # Empty series if source is empty

    if not y_class_cv_pool.empty:
        y_class_cv_pool = y_class_cv_pool.map(label_mapping)
    else:
        y_class_cv_pool = pd.Series([], dtype=int)

    if not y_train_class.empty:
        y_train_class = y_train_class.map(label_mapping)
    else:
        y_train_class = pd.Series([], dtype=int)

    if not y_test_class.empty:
        y_test_class = y_test_class.map(label_mapping)
    else:
        y_test_class = pd.Series([], dtype=int)


    logging.info(
        f"–ü—Ä–∏–º–µ—Ä y_train_class –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è ({log_context_str}): {y_train_class.head().tolist() if not y_train_class.empty else '–ø—É—Å—Ç–æ'}")
    logging.info(
        f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ y_train_class –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è ({log_context_str}): {y_train_class.value_counts().to_dict() if not y_train_class.empty else '–ø—É—Å—Ç–æ'}")
    logging.info(
        f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ y_test_class –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è ({log_context_str}): {y_test_class.value_counts().to_dict() if not y_test_class.empty else '–ø—É—Å—Ç–æ'}")
    logging.info(
        f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ y_class_cv_pool –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è ({log_context_str}): {y_class_cv_pool.value_counts().to_dict() if not y_class_cv_pool.empty else '–ø—É—Å—Ç–æ'}")


    logging.info(f"–†–∞–∑–º–µ—Ä—ã –≤—ã–±–æ—Ä–æ–∫ ({log_context_str}): Train/CV Pool: {len(X_cv_pool)}, Test: {len(X_test_full)}")
    if X_cv_pool.empty or X_test_full.empty:
        logging.error(f"X_cv_pool (Train/CV) –∏–ª–∏ X_test_full –ø—É—Å—Ç—ã –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–ª—è {log_context_str}.")
        return

    logging.info(
        f"üöÄ –ù–∞—á–∞–ª–æ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Top 20) –¥–ª—è clf_class ({log_context_str}) –Ω–∞ –æ—Å–Ω–æ–≤–µ {len(X_cv_pool)} –æ–±—Ä–∞–∑—Ü–æ–≤...")
    top20_features = []
    if X_cv_pool.empty or y_class_cv_pool.empty:
        logging.warning(
            f"X_cv_pool –∏–ª–∏ y_class_cv_pool –ø—É—Å—Ç—ã –ø–µ—Ä–µ–¥ –æ—Ç–±–æ—Ä–æ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {log_context_str}. –û—Ç–±–æ—Ä –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.")
        top20_features = X_cv_pool.columns.tolist()
    elif len(X_cv_pool.columns) <= 20:
        logging.info(
            f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ({len(X_cv_pool.columns)}) –º–µ–Ω—å—à–µ –∏–ª–∏ —Ä–∞–≤–Ω–æ 20 –¥–ª—è {log_context_str}. –û—Ç–±–æ—Ä –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
        top20_features = X_cv_pool.columns.tolist()
    else:
        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
        min_samples_in_class = y_class_cv_pool.value_counts().min() if not y_class_cv_pool.empty else 0

        # Ensure enough samples for StratifiedKFold
        if min_samples_in_class < kf.get_n_splits() or y_class_cv_pool.nunique() < 2:
            logging.warning(
                f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –∫–ª–∞—Å—Å–µ y_class_cv_pool ({y_class_cv_pool.value_counts().to_dict() if not y_class_cv_pool.empty else '–ø—É—Å—Ç–æ'}) "
                f"–∏–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–ª–∞—Å—Å ({y_class_cv_pool.nunique() if not y_class_cv_pool.empty else 'N/A'}) "
                f"–¥–ª—è StratifiedKFold ({log_context_str}). –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è."
            )
            top20_features = X_cv_pool.columns.tolist()
        else:
            feature_importances_fi = np.zeros(X_cv_pool.shape[1])
            num_successful_folds = 0
            for fold, (train_idx, val_idx) in enumerate(kf.split(X_cv_pool, y_class_cv_pool)):
                logging.info(f"–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ({log_context_str}): —Ñ–æ–ª–¥ {fold + 1}/{kf.get_n_splits()}")
                X_fold_train, X_fold_val = X_cv_pool.iloc[train_idx], X_cv_pool.iloc[val_idx]
                y_fold_train, y_fold_val = y_class_cv_pool.iloc[train_idx], y_class_cv_pool.iloc[val_idx]

                if X_fold_val.empty or y_fold_val.empty:
                    logging.warning(
                        f"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –ø—É—Å—Ç –≤ —Ñ–æ–ª–¥–µ {fold + 1} ({log_context_str}). –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                    continue
                # Check if validation set has at least two classes for Logloss/Accuracy
                if y_fold_val.nunique() < 2:
                     logging.warning(
                        f"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –≤ —Ñ–æ–ª–¥–µ {fold + 1} –∏–º–µ–µ—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–ª–∞—Å—Å ({y_fold_val.nunique()}) –¥–ª—è {log_context_str}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                     continue

                clf_fi = CatBoostClassifier(
                    iterations=200, learning_rate=0.05,
                    early_stopping_rounds=25, verbose=False,
                    loss_function='Logloss', # Use Logloss for binary classification
                    eval_metric='Accuracy', # Or F1, depending on preference
                    task_type="GPU", devices='0', random_seed=42
                )
                try:
                     clf_fi.fit(X_fold_train, y_fold_train, eval_set=(X_fold_val, y_fold_val))
                     feature_importances_fi += clf_fi.get_feature_importance(type='FeatureImportance')
                     num_successful_folds += 1
                except Exception as e:
                     logging.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –≤ —Ñ–æ–ª–¥–µ {fold + 1} –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ({log_context_str}): {e}")


            if num_successful_folds > 0:
                fi_mean = pd.Series(feature_importances_fi / num_successful_folds,
                                    index=X_cv_pool.columns).sort_values(ascending=False)
                top20_features = fi_mean.head(20).index.tolist()
                logging.info(f"–¢–æ–ø-20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {log_context_str}: {top20_features}")
            else:
                logging.warning(
                    f"–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–æ–ª–¥–∞ –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ({log_context_str}). –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤—Å–µ.")
                top20_features = X_cv_pool.columns.tolist()

    # Ensure selected features are actually present in the dataframes
    feature_cols_final = [col for col in top20_features if col in X_train_full.columns]
    if not feature_cols_final:
        logging.error(f"–ü–æ—Å–ª–µ –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞, –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –≤ –¥–∞–Ω–Ω—ã—Ö ({log_context_str}). –û–±—É—á–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.")
        return

    X_train_sel = X_train_full[feature_cols_final]
    X_test_sel = X_test_full[feature_cols_final]
    X_cv_pool_sel = X_cv_pool[feature_cols_final]


    logging.info(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ –æ—Ç–±–æ—Ä–∞ ({log_context_str}): {len(feature_cols_final)}")

    try:
        # Use file_prefix for saving selected features
        features_list_path = f"models/{file_prefix}_features_selected.txt"
        with open(features_list_path, "w", encoding="utf-8") as f:
            f.write("\n".join(feature_cols_final))
        logging.info(f"–°–ø–∏—Å–æ–∫ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {features_list_path}")

        features_json_path = f"models/{file_prefix}_features_selected.json"
        try:
            with open(features_json_path, "w", encoding="utf-8") as f_json:
                json.dump(feature_cols_final, f_json, ensure_ascii=False, indent=2)
            logging.info(f"–°–ø–∏—Å–æ–∫ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {features_json_path}")
        except Exception as e_json:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ JSON ({log_context_str}): {e_json}")

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ({log_context_str}): {e}")


    logging.info(f"–†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è clf_class ({log_context_str}) –Ω–∞ –æ—Å–Ω–æ–≤–µ y_train_class (0/1)...")
    class_weights_dict_for_fit = {}
    if not y_train_class.empty:
        counts_class_in_train = y_train_class.value_counts().to_dict()
        total_class_in_train = sum(counts_class_in_train.values())
        # Calculate inverse frequency weights
        count_0 = counts_class_in_train.get(0, 0)
        if count_0 > 0:
            class_weights_dict_for_fit[0] = total_class_in_train / (2 * count_0) # /2 for balanced
        else:
            class_weights_dict_for_fit[0] = 1.0
            logging.warning(f"–ö–ª–∞—Å—Å 0 ('DOWN') –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ y_train_class ({log_context_str}). –í–µ—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ 1.0.")
        count_1 = counts_class_in_train.get(1, 0)
        if count_1 > 0:
            class_weights_dict_for_fit[1] = total_class_in_train / (2 * count_1) # /2 for balanced
        else:
            class_weights_dict_for_fit[1] = 1.0
            logging.warning(f"–ö–ª–∞—Å—Å 1 ('UP') –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ y_train_class ({log_context_str}). –í–µ—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ 1.0.")
        logging.info(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ y_train_class (0/1) ({log_context_str}): {counts_class_in_train}")
    else:
        logging.warning(
            f"y_train_class –ø—É—Å—Ç, –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã ({log_context_str}). –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤–µ—Å–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (1.0).")
        class_weights_dict_for_fit = {0: 1.0, 1: 1.0}

    logging.info(
        f"–í–µ—Å–∞ –¥–ª—è clf_class (CatBoost, –∫–ª—é—á–∏ 0/1, –¥–ª—è .fit()) ({log_context_str}): {class_weights_dict_for_fit}")

    # CatBoost CV expects class weights as a list [weight_for_class_0, weight_for_class_1]
    class_weights_list_for_cv = [
        class_weights_dict_for_fit.get(0, 1.0),
        class_weights_dict_for_fit.get(1, 1.0)
    ]
    logging.info(
        f"–í–µ—Å–∞ –¥–ª—è CV (—Å–ø–∏—Å–æ–∫ [–≤–µ—Å_–¥–ª—è_–∫–ª–∞—Å—Å–∞_0, –≤–µ—Å_–¥–ª—è_–∫–ª–∞—Å—Å–∞_1]) ({log_context_str}): {class_weights_list_for_cv}")


    clf_class_model = None
    num_unique_classes_clf = y_class_cv_pool.nunique() if not y_class_cv_pool.empty else 0
    if num_unique_classes_clf == 2:
        loss_func_clf = 'Logloss'
        eval_metric_clf = 'F1' # Using F1 as primary metric for imbalanced data
    elif num_unique_classes_clf == 1:
        logging.warning(
            f"–í y_class_cv_pool —Ç–æ–ª—å–∫–æ {num_unique_classes_clf} —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å ({log_context_str}). "
            f"–û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º –∏–ª–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω—ã–º. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Logloss/Accuracy."
        )
        loss_func_clf = 'Logloss'
        eval_metric_clf = 'Accuracy' # Fallback to Accuracy
    else:
        logging.error(
            f"–í y_class_cv_pool {num_unique_classes_clf} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ ({log_context_str}). "
            f"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Logloss/Accuracy –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."
        )
        loss_func_clf = 'Logloss'
        eval_metric_clf = 'Accuracy' # Fallback to Accuracy


    logging.info(f"\nüîÑ –ó–∞–ø—É—Å–∫ RandomSearch –¥–ª—è clf_class ({log_context_str})...")
    best_score_rs = -1 # Maximize F1 or Accuracy
    best_params_rs = None
    num_rs_trials = 10 # Number of Random Search trials

    default_cv_params_class = {
        'iterations': 700, 'learning_rate': 0.03, 'depth': 6,
        'loss_function': loss_func_clf, 'eval_metric': eval_metric_clf,
        'early_stopping_rounds': 50, 'random_seed': 42,
        'task_type': 'GPU', 'devices': '0', 'verbose': 0,
        # Use list for CV parameters
        'class_weights': class_weights_list_for_cv,
    }
    cv_params_class = default_cv_params_class.copy()
    best_iter_class_cv = cv_params_class['iterations']

    min_samples_for_cv = 5 # Minimum samples per class for Stratified KFold
    if not X_cv_pool_sel.empty and not y_class_cv_pool.empty and \
            y_class_cv_pool.nunique() >= 2 and \
            (y_class_cv_pool.value_counts().min() if not y_class_cv_pool.empty else 0) >= min_samples_for_cv:

        logging.info(f"–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ RandomSearch ({num_rs_trials} –ø–æ–ø—ã—Ç–æ–∫) –¥–ª—è clf_class ({log_context_str})...")
        # Define parameter grid for Random Search
        param_distributions = {
            'iterations': [300, 500, 700, 1000, 1500],
            'learning_rate': [0.01, 0.03, 0.05, 0.07, 0.1],
            'bagging_temperature': [random.uniform(0.1, 1.0) for _ in range(num_rs_trials * 2)], # More options
            'depth': [4, 5, 6, 7, 8, 9, 10],
            'l2_leaf_reg': [1, 3, 5, 7, 9, 11, 15, 20],
        }

        for i in range(num_rs_trials):
            logging.info(f"RandomSearch –¥–ª—è clf_class ({log_context_str}): –ø–æ–ø—ã—Ç–∫–∞ {i + 1}/{num_rs_trials}")
            trial_params = {
                'iterations': random.choice(param_distributions['iterations']),
                'learning_rate': random.choice(param_distributions['learning_rate']),
                'bagging_temperature': random.choice(param_distributions['bagging_temperature']),
                'depth': random.choice(param_distributions['depth']),
                'l2_leaf_reg': random.choice(param_distributions['l2_leaf_reg']),
                'loss_function': loss_func_clf,
                'eval_metric': eval_metric_clf,
                'early_stopping_rounds': 50,
                'random_seed': 42,
                'task_type': 'GPU', 'devices': '0',
                'verbose': 0, # Keep verbose low during search
                'class_weights': class_weights_list_for_cv, # Use list for CV
            }
            try:
                current_pool = Pool(
                    data=X_cv_pool_sel,
                    label=y_class_cv_pool.astype(np.int32).values,
                    feature_names=list(X_cv_pool_sel.columns),
                    cat_features=[] # Assuming no categorical features
                )
                # Use StratifiedKFold directly for CV
                stratified_kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

                cv_data = cv(current_pool, params=trial_params, folds=stratified_kf, plot=False)

                metric_key_rs = f'test-{eval_metric_clf}-mean'
                if metric_key_rs not in cv_data.columns:
                     logging.warning(f"–ú–µ—Ç—Ä–∏–∫–∞ '{eval_metric_clf}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö CV ({log_context_str}). –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: {list(cv_data.columns)}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–ø—ã—Ç–∫—É.")
                     continue

                # For metrics to maximize (Accuracy, F1, AUC), find max; for loss (Logloss), find min
                if eval_metric_clf in ['Logloss', 'RMSE', 'MultiClass']: # Add other loss functions if needed
                    current_score_rs = -cv_data[metric_key_rs].min() # Negate min for maximization
                    current_best_iter_rs = cv_data[metric_key_rs].idxmin() + 1
                else: # Assume metric to maximize (Accuracy, F1, AUC, etc.)
                    current_score_rs = cv_data[metric_key_rs].max()
                    current_best_iter_rs = cv_data[metric_key_rs].idxmax() + 1

                # Adjust iterations to be at least early_stopping_rounds + buffer
                min_iterations_needed = trial_params['early_stopping_rounds'] * 2 # Heuristic
                trial_params['iterations'] = max(int(current_best_iter_rs * 1.2), min_iterations_needed) # Add a buffer

                params_for_best_rs = trial_params.copy()
                # Use dict for final model fit
                params_for_best_rs['class_weights'] = class_weights_dict_for_fit

                logging.info(
                    f"  RandomSearch Trial {i + 1} ({log_context_str}): params={ {k: v for k, v in trial_params.items() if k in ['iterations', 'learning_rate', 'depth', 'l2_leaf_reg', 'bagging_temperature']} }, score ({eval_metric_clf})={current_score_rs:.4f} (raw_cv_score: {cv_data[metric_key_rs].iloc[-1]:.4f})")
                if current_score_rs > best_score_rs:
                    best_score_rs = current_score_rs
                    best_params_rs = params_for_best_rs
                    logging.info(
                        f"  üéâ New best RandomSearch score ({log_context_str}): {best_score_rs:.4f} with params: { {k: v for k, v in best_params_rs.items() if k in ['iterations', 'learning_rate', 'depth', 'l2_leaf_reg', 'bagging_temperature']} }")
            except Exception as e:
                params_causing_error = {k: v for k, v in trial_params.items()}
                logging.warning(
                    f"  –û—à–∏–±–∫–∞ –≤ RandomSearch trial {i + 1} ({log_context_str}) ({params_causing_error}): {e}")
                continue # Continue to the next trial

        if best_params_rs:
            cv_params_class = best_params_rs
            best_iter_class_cv = best_params_rs['iterations']
            logging.info(
                f"üéØ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è clf_class –æ—Ç RandomSearch ({log_context_str}): { {k: v for k, v in cv_params_class.items() if k in ['iterations', 'learning_rate', 'depth', 'l2_leaf_reg', 'bagging_temperature']} } —Å CV-score ({eval_metric_clf}): {best_score_rs:.4f}")
        else:
            logging.warning(f"RandomSearch –Ω–µ –Ω–∞—à–µ–ª –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è {log_context_str}, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ.")
            # Ensure default params use the dict for fit
            default_cv_params_class['class_weights'] = class_weights_dict_for_fit
            cv_params_class = default_cv_params_class.copy()

    else:
        logging.warning(
            f"RandomSearch –¥–ª—è clf_class –ø—Ä–æ–ø—É—â–µ–Ω –¥–ª—è {log_context_str}. –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –∫–ª–∞—Å—Å–æ–≤. X_cv_pool_sel empty: {X_cv_pool_sel.empty}, y_class_cv_pool empty: {y_class_cv_pool.empty}, unique classes: {y_class_cv_pool.nunique() if not y_class_cv_pool.empty else 'N/A'}, min class count: {(y_class_cv_pool.value_counts().min() if not y_class_cv_pool.empty and y_class_cv_pool.nunique() > 0 else 'N/A')}. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.")
        # Ensure default params use the dict for fit
        default_cv_params_class['class_weights'] = class_weights_dict_for_fit
        cv_params_class = default_cv_params_class.copy()


    logging.info(
        f"\nüöÄ –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ clf_class –¥–ª—è {log_context_str} —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: { {k: v for k, v in cv_params_class.items() if k in ['iterations', 'learning_rate', 'depth', 'l2_leaf_reg', 'bagging_temperature']} }")
    # Use parameters found by RS or default parameters
    clf_class_model = CatBoostClassifier(**cv_params_class)
    # Set verbose for the final training run
    clf_class_model.set_params(verbose=100)

    if not X_train_sel.empty and not y_train_class.empty:
        eval_set_class = (X_test_sel, y_test_class) if not X_test_sel.empty and not y_test_class.empty else None
        try:
            # Ensure y_train_class is integer type for CatBoost
            clf_class_model.fit(X_train_sel, y_train_class.astype(int), eval_set=eval_set_class, plot=False)
            logging.info(f"clf_class best_iteration ({log_context_str}): {clf_class_model.get_best_iteration()}")
            if clf_class_model.get_best_score() and eval_set_class:
                validation_scores = clf_class_model.get_best_score().get('validation',
                                                                         clf_class_model.get_best_score().get(
                                                                             'validation_0'))
                if validation_scores and eval_metric_clf in validation_scores:
                    logging.info(
                        f"clf_class validation_{eval_metric_clf} ({log_context_str}): {validation_scores[eval_metric_clf]:.4f}")
            if clf_class_model is not None and hasattr(clf_class_model, 'get_feature_importance'):
                importances = clf_class_model.get_feature_importance(type='FeatureImportance')
                feature_importance_df = pd.DataFrame({'feature': X_train_sel.columns, 'importance': importances})
                feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)
                logging.info(
                    f"\nüî• –¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è clf_class ({log_context_str}):\n{feature_importance_df.head(10).to_string(index=False)}")
                try:
                    # Use file_prefix for feature importance log
                    fi_path = f"logs/feature_importance_clf_class_{file_prefix}.csv"
                    feature_importance_df.to_csv(fi_path, index=False)
                    logging.info(f"üìÅ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è clf_class ({log_context_str}) —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {fi_path}")
                except Exception as e_fi_save:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ({log_context_str}): {e_fi_save}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ clf_class_model ({log_context_str}): {e}", exc_info=True)
            clf_class_model = None
    else:
        logging.error(f"–û–±—É—á–µ–Ω–∏–µ clf_class –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ ({log_context_str}): X_train_sel –∏–ª–∏ y_train_class –ø—É—Å—Ç—ã.")
        clf_class_model = None


    # --- Train Regression Models (Delta and Volatility) ---

    reg_delta_model = None
    logging.info(f"\n--- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è reg_delta ({log_context_str}) ---")
    if not y_train_delta.empty: logging.info(
        f"y_train_delta ({len(y_train_delta)}) ({log_context_str}): min={y_train_delta.min():.6f}, max={y_train_delta.max():.6f}, mean={y_train_delta.mean():.6f}, std={y_train_delta.std():.6f}")
    if not y_test_delta.empty: logging.info(
        f"y_test_delta ({len(y_test_delta)}) ({log_context_str}): min={y_test_delta.min():.6f}, max={y_test_delta.max():.6f}, mean={y_test_delta.mean():.6f}, std={y_test_delta.std():.6f}")
    logging.info(f"–û–±—É—á–µ–Ω–∏–µ reg_delta –¥–ª—è {log_context_str}...")
    reg_delta_model = CatBoostRegressor(
        iterations=500, learning_rate=0.03, depth=6,
        loss_function='RMSE', eval_metric='RMSE', custom_metric=['MAE'],
        min_data_in_leaf=10, task_type="GPU", devices='0',
        random_seed=42, verbose=100, early_stopping_rounds=50
    )
    if not X_train_sel.empty and not y_train_delta.empty:
        eval_set_delta = (X_test_sel, y_test_delta) if not X_test_sel.empty and not y_test_delta.empty else None
        try:
            reg_delta_model.fit(X_train_sel, y_train_delta, eval_set=eval_set_delta)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ reg_delta_model ({log_context_str}): {e}", exc_info=True)
            reg_delta_model = None
    else:
        logging.error(f"–û–±—É—á–µ–Ω–∏–µ reg_delta –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ ({log_context_str}). X_train_sel –∏–ª–∏ y_train_delta –ø—É—Å—Ç—ã.")
        reg_delta_model = None


    reg_vol_model = None
    logging.info(f"\n--- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è reg_vol ({log_context_str}) ---")
    if not y_train_vol.empty: logging.info(
        f"y_train_vol ({len(y_train_vol)}) ({log_context_str}): min={y_train_vol.min():.6f}, max={y_train_vol.max():.6f}, mean={y_train_vol.mean():.6f}, std={y_train_vol.std():.6f}")
    if not y_test_vol.empty: logging.info(
        f"y_test_vol ({len(y_test_vol)}) ({log_context_str}): min={y_test_vol.min():.6f}, max={y_test_vol.max():.6f}, mean={y_test_vol.mean():.6f}, std={y_test_vol.std():.6f}")
    logging.info(f"–û–±—É—á–µ–Ω–∏–µ reg_vol –¥–ª—è {log_context_str}...")
    reg_vol_model = CatBoostRegressor(
        iterations=500, learning_rate=0.03, depth=6,
        loss_function='RMSE', eval_metric='RMSE', custom_metric=['MAE'],
        min_data_in_leaf=10, task_type="GPU", devices='0',
        random_seed=42, verbose=100, early_stopping_rounds=50
    )
    if not X_train_sel.empty and not y_train_vol.empty:
        eval_set_vol = (X_test_sel, y_test_vol) if not X_test_sel.empty and not y_test_vol.empty else None
        try:
            reg_vol_model.fit(X_train_sel, y_train_vol, eval_set=eval_set_vol)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ reg_vol_model ({log_context_str}): {e}", exc_info=True)
            reg_vol_model = None
    else:
        logging.error(f"–û–±—É—á–µ–Ω–∏–µ reg_vol –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ ({log_context_str}). X_train_sel –∏–ª–∏ y_train_vol –ø—É—Å—Ç—ã.")
        reg_vol_model = None


    # --- Train TP-Hit Classifier ---

    clf_tp_hit_model = None
    if train_tp_hit_model_flag and y_tp_hit_cv_pool is not None and not y_tp_hit_cv_pool.empty \
        and y_test_tp_hit is not None and not y_test_tp_hit.empty:

        logging.info(f"\n–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –æ–±—É—á–µ–Ω–∏—é clf_tp_hit –¥–ª—è {log_context_str}...")

        # Ensure TP-hit targets are integer type
        y_train_tp_hit_int = y_train_tp_hit.astype(int)
        y_test_tp_hit_int = y_test_tp_hit.astype(int)
        y_tp_hit_cv_pool_int = y_tp_hit_cv_pool.astype(int)


        # Simple weight search using a small model
        best_f1 = -1
        best_weights = None
        weight_options = [1, 2, 5, 10, 15, 20, 30, 50] # Explore different weights for class 1

        logging.info(f"–ü–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –≤–µ—Å–æ–≤ –¥–ª—è clf_tp_hit –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ ({log_context_str})...")
        if X_test_sel.empty or y_test_tp_hit_int.empty:
             logging.warning(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø—É—Å—Ç–∞ –¥–ª—è TP-hit ({log_context_str}). –ü—Ä–æ–ø—É—Å–∫ –ø–æ–∏—Å–∫–∞ –≤–µ—Å–æ–≤.")
             # Fallback to a default weight if search is skipped
             class_weights_tp_hit_dict_for_fit = {0: 1, 1: 10}
        else:
            for w in weight_options:
                class_weights_tp_hit_dict_for_fit_tmp = {0: 1, 1: w}
                clf_tmp = CatBoostClassifier(
                    iterations=200, # Use fewer iterations for fast weight search
                    learning_rate=0.05,
                    depth=4,
                    loss_function='Logloss',
                    eval_metric='F1', # Evaluate on F1 for TP-hit
                    random_seed=42,
                    task_type="GPU",
                    verbose=0,
                    class_weights=class_weights_tp_hit_dict_for_fit_tmp
                )
                try:
                    # Fit on train set, evaluate on test set
                    clf_tmp.fit(X_train_sel, y_train_tp_hit_int)
                    y_pred_tmp = clf_tmp.predict(X_test_sel)
                    # Ensure predictions are in the expected format (flat list/array)
                    y_pred_tmp_flat = [item[0] if isinstance(item, (np.ndarray, list)) and len(item) == 1 else item
                                          for item in y_pred_tmp]

                    score = f1_score(y_test_tp_hit_int, y_pred_tmp_flat, zero_division=0, pos_label=1)

                    logging.info(f"[TP-hit] F1 = {score:.4f} –ø—Ä–∏ –≤–µ—Å–∞—Ö {class_weights_tp_hit_dict_for_fit_tmp}")
                    if score > best_f1:
                        best_f1 = score
                        best_weights = class_weights_tp_hit_dict_for_fit_tmp
                except Exception as e:
                    logging.warning(f"[TP-hit] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —Å –≤–µ—Å–∞–º–∏ {class_weights_tp_hit_dict_for_fit_tmp} ({log_context_str}): {e}")
                    continue

        # If no best weights found (e.g., due to errors or empty test set), set a default
        class_weights_tp_hit_dict_for_fit = best_weights if best_weights else {0: 1, 1: 10}

        class_weights_tp_hit_list_for_cv = [
            class_weights_tp_hit_dict_for_fit.get(0, 1.0),
            class_weights_tp_hit_dict_for_fit.get(1, 1.0)
        ]
        logging.info(f"–í–µ—Å–∞ –¥–ª—è clf_tp_hit (–¥–ª—è .fit()) ({log_context_str}): {class_weights_tp_hit_dict_for_fit}")
        logging.info(f"–í–µ—Å–∞ –¥–ª—è clf_tp_hit (–¥–ª—è CV) ({log_context_str}): {class_weights_tp_hit_list_for_cv}")


        counts_tp_hit_train = y_train_tp_hit_int.value_counts().to_dict() if not y_train_tp_hit_int.empty else {}
        logging.info(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ y_train_tp_hit (clf_tp_hit) ({log_context_str}): {counts_tp_hit_train}")


        best_iter_tp_hit = 500 # Default iterations
        # Check if CV is possible for TP-hit
        min_samples_for_tp_hit_cv = 5 # Minimum samples per class for Stratified KFold
        if use_stratified_cv_for_tp_hit and not X_cv_pool_sel.empty and not y_tp_hit_cv_pool_int.empty and \
                y_tp_hit_cv_pool_int.nunique() >= 2 and \
                (y_tp_hit_cv_pool_int.value_counts().min() if not y_tp_hit_cv_pool_int.empty else 0) >= min_samples_for_tp_hit_cv:

            logging.info(f"–ó–∞–ø—É—Å–∫ CV –¥–ª—è clf_tp_hit ({log_context_str})...")
            cv_params_tp_hit = {
                'iterations': 1000, # Max iterations for CV
                'learning_rate': 0.03,
                'depth': 4,
                'loss_function': 'Logloss',
                'eval_metric': 'F1', # Use F1 for CV evaluation
                'early_stopping_rounds': 50,
                'random_seed': 42,
                'task_type': 'GPU', 'devices': '0',
                'verbose': 0,
                'class_weights': class_weights_tp_hit_list_for_cv # Use list for CV
            }
            strat_cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
            try:
                pool_tp_hit_cv = Pool(
                    data=X_cv_pool_sel,
                    label=y_tp_hit_cv_pool_int.values,
                    feature_names=list(X_cv_pool_sel.columns)
                )
                cv_data_tp_hit = cv(pool_tp_hit_cv, params=cv_params_tp_hit, folds=strat_cv_folds, plot=False)
                metric_key_cv_tp_hit = f'test-{cv_params_tp_hit["eval_metric"]}-mean'

                if metric_key_cv_tp_hit in cv_data_tp_hit.columns:
                     # For F1, we maximize, so find idxmax
                    best_iter_tp_hit = cv_data_tp_hit[metric_key_cv_tp_hit].idxmax() + 1
                    # Add a buffer to the best iteration found
                    best_iter_tp_hit = max(best_iter_tp_hit, cv_params_tp_hit['early_stopping_rounds'] + 1) # Ensure at least early stopping rounds
                    best_iter_tp_hit = int(best_iter_tp_hit * 1.2) # Add 20% buffer

                    logging.info(
                        f"üîç CatBoostCV (TP-hit) ({log_context_str}): best_iterations = {best_iter_tp_hit}, val_score ({cv_params_tp_hit['eval_metric']}) = {cv_data_tp_hit[metric_key_cv_tp_hit].iloc[-1]:.4f}")
                else:
                    logging.warning(f"–ú–µ—Ç—Ä–∏–∫–∞ '{cv_params_tp_hit['eval_metric']}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö CV TP-hit ({log_context_str}). –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: {list(cv_data_tp_hit.columns)}. –ò—Ç–µ—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
                    best_iter_tp_hit = 500 # Fallback to default
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ CV –¥–ª—è clf_tp_hit ({log_context_str}): {e}. –ò—Ç–µ—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.", exc_info=True)
                best_iter_tp_hit = 500 # Fallback to default
        else:
            logging.info(f"CV –¥–ª—è clf_tp_hit –ø—Ä–æ–ø—É—â–µ–Ω ({log_context_str}). use_stratified_cv_for_tp_hit={use_stratified_cv_for_tp_hit}, X_cv_pool_sel empty={X_cv_pool_sel.empty}, y_tp_hit_cv_pool_int empty={y_tp_hit_cv_pool_int.empty}, unique classes={y_tp_hit_cv_pool_int.nunique() if not y_tp_hit_cv_pool_int.empty else 'N/A'}, min class count={(y_tp_hit_cv_pool_int.value_counts().min() if not y_tp_hit_cv_pool_int.empty and y_tp_hit_cv_pool_int.nunique() > 0 else 'N/A')}. –ò—Ç–µ—Ä–∞—Ü–∏–∏: {best_iter_tp_hit}")


        logging.info(f"–û–±—É—á–µ–Ω–∏–µ clf_tp_hit ({log_context_str}) —Å {best_iter_tp_hit} –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏...")
        # Use parameters found or default parameters
        clf_tp_hit_model = CatBoostClassifier(
            iterations=best_iter_tp_hit, learning_rate=0.03, depth=4,
            class_weights=class_weights_tp_hit_dict_for_fit, # Use dict for fit
            loss_function='Logloss', eval_metric='F1', random_state=42, verbose=100,
            task_type="GPU", devices='0', early_stopping_rounds=50
        )
        if not X_train_sel.empty and not y_train_tp_hit_int.empty:
            eval_set_tp_hit = (X_test_sel,
                               y_test_tp_hit_int) if not X_test_sel.empty and not y_test_tp_hit_int.empty else None
            try:
                clf_tp_hit_model.fit(X_train_sel, y_train_tp_hit_int, eval_set=eval_set_tp_hit)
                logging.info(f"clf_tp_hit best_iteration ({log_context_str}): {clf_tp_hit_model.get_best_iteration()}")
                if clf_tp_hit_model.get_best_score() and eval_set_tp_hit:
                    validation_scores_tp_hit = clf_tp_hit_model.get_best_score().get('validation',
                                                                             clf_tp_hit_model.get_best_score().get(
                                                                                 'validation_0'))
                    if validation_scores_tp_hit and 'F1' in validation_scores_tp_hit:
                        logging.info(
                            f"clf_tp_hit validation_F1 ({log_context_str}): {validation_scores_tp_hit['F1']:.4f}")

            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ clf_tp_hit_model ({log_context_str}): {e}", exc_info=True)
                clf_tp_hit_model = None
        else:
            logging.error(f"–û–±—É—á–µ–Ω–∏–µ clf_tp_hit –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ ({log_context_str}). X_train_sel –∏–ª–∏ y_train_tp_hit_int –ø—É—Å—Ç—ã.")
            clf_tp_hit_model = None

    elif train_tp_hit_model_flag:
        logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è clf_tp_hit ({log_context_str}). –ú–æ–¥–µ–ª—å –Ω–µ –±—É–¥–µ—Ç –æ–±—É—á–µ–Ω–∞.")
        clf_tp_hit_model = None # Explicitly set to None if training was attempted but failed


    # --- Save Models ---
    logging.info(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è {log_context_str}...")
    if clf_class_model:
         try:
            joblib.dump(clf_class_model, f"models/{file_prefix}_clf_class.pkl")
            logging.info(f"–ú–æ–¥–µ–ª—å clf_class —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/{file_prefix}_clf_class.pkl")
         except Exception as e:
             logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ clf_class ({log_context_str}): {e}")
    else:
         logging.warning(f"–ú–æ–¥–µ–ª—å clf_class –Ω–µ –æ–±—É—á–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–ª—è {log_context_str}.")

    if reg_delta_model:
         try:
            joblib.dump(reg_delta_model, f"models/{file_prefix}_reg_delta.pkl")
            logging.info(f"–ú–æ–¥–µ–ª—å reg_delta —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/{file_prefix}_reg_delta.pkl")
         except Exception as e:
             logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ reg_delta ({log_context_str}): {e}")
    else:
         logging.warning(f"–ú–æ–¥–µ–ª—å reg_delta –Ω–µ –æ–±—É—á–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–ª—è {log_context_str}.")

    if reg_vol_model:
         try:
            joblib.dump(reg_vol_model, f"models/{file_prefix}_reg_vol.pkl")
            logging.info(f"–ú–æ–¥–µ–ª—å reg_vol —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/{file_prefix}_reg_vol.pkl")
         except Exception as e:
             logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ reg_vol ({log_context_str}): {e}")
    else:
         logging.warning(f"–ú–æ–¥–µ–ª—å reg_vol –Ω–µ –æ–±—É—á–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–ª—è {log_context_str}.")


    if clf_tp_hit_model:
         try:
            joblib.dump(clf_tp_hit_model, f"models/{file_prefix}_clf_tp_hit.pkl")
            logging.info(f"–ú–æ–¥–µ–ª—å clf_tp_hit —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/{file_prefix}_clf_tp_hit.pkl")
         except Exception as e:
             logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ clf_tp_hit ({log_context_str}): {e}")
    else:
         logging.warning(f"–ú–æ–¥–µ–ª—å clf_tp_hit –Ω–µ –æ–±—É—á–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–ª—è {log_context_str}.")


    # --- Evaluate Metrics on Test Set ---
    if X_test_sel.empty:
        logging.warning(f"X_test_sel –ø—É—Å—Ç, –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è {log_context_str}.")
    else:
        metrics_output = f"\nüìä  –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ ({log_context_str}) —Å {len(feature_cols_final)} –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏:\n"

        # Metrics for clf_class
        report_class_str, acc_class_val = "N/A", "N/A"
        f1_class_val, precision_class_val = "N/A", "N/A"
        cm_df_str = "N/A"
        auc_class_val = "N/A"
        pr_auc_class_val = "N/A"

        if clf_class_model and not y_test_class.empty:
            try:
                # Ensure y_test_class is integer type for evaluation
                y_test_class_int = y_test_class.astype(int)

                proba_class_test = clf_class_model.predict_proba(X_test_sel)
                positive_class_label_int = 1 # 'UP' is mapped to 1
                model_classes_ = getattr(clf_class_model, 'classes_', [0, 1]) # Default to [0, 1] if not found
                try:
                    # Find the index corresponding to the positive class (1)
                    positive_class_idx = list(model_classes_).index(positive_class_label_int)
                except ValueError:
                    logging.warning(
                        f"–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å {positive_class_label_int} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ model.classes_ ({model_classes_}) –¥–ª—è {log_context_str}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–Ω–¥–µ–∫—Å 1 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π.")
                    positive_class_idx = 1 # Fallback index


                # Predict class based on threshold
                y_pred_class_flat = np.where(proba_class_test[:, positive_class_idx] > PREDICT_PROBA_THRESHOLD_CLASS,
                                             positive_class_label_int,
                                             1 - positive_class_label_int)

                # Ensure targets and predictions are flat for metrics
                y_test_class_flat = y_test_class_int.squeeze()
                y_pred_class_flat = pd.Series(y_pred_class_flat).squeeze()


                # Check unique values for reporting
                unique_labels_test_set = set(y_test_class_flat.unique()) if not y_test_class_flat.empty else set()
                unique_labels_pred_set = set(y_pred_class_flat.unique()) if not y_pred_class_flat.empty else set()
                all_present_labels_set = unique_labels_test_set | unique_labels_pred_set

                # Ensure target names align with labels [0, 1]
                report_labels_int = [0, 1]
                if not all_present_labels_set.issubset(set(report_labels_int)):
                     logging.warning(
                        f"–ú–µ—Ç–∫–∏ –≤ y_test/y_pred ({all_present_labels_set}) –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –æ–∂–∏–¥–∞–µ–º—ã—Ö –º–µ—Ç–∫–∞—Ö {set(report_labels_int)} –¥–ª—è {log_context_str}. Classification report may fail or be incomplete.")
                     # Try to use labels present in data if standard ones fail
                     report_labels_int = sorted(list(all_present_labels_set))
                     target_names_for_report = [TARGET_CLASS_NAMES[i] for i in report_labels_int if i in [0,1]]
                     if len(target_names_for_report) != len(report_labels_int):
                          target_names_for_report = [f'Class_{i}' for i in report_labels_int]
                else:
                    target_names_for_report = TARGET_CLASS_NAMES # Use standard names if labels are 0 and 1

                try:
                    report_class_str = classification_report(y_test_class_flat, y_pred_class_flat,
                                                             labels=report_labels_int,
                                                             target_names=target_names_for_report,
                                                             digits=4, zero_division=0)
                except Exception as e_report:
                    logging.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ classification_report –¥–ª—è clf_class ({log_context_str}): {e_report}. –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏.")
                    report_class_str = "Classification report failed."


                acc_class_val = accuracy_score(y_test_class_flat, y_pred_class_flat)
                # Calculate F1 and Precision for the positive class (1)
                f1_class_val = f1_score(y_test_class_flat, y_pred_class_flat, pos_label=positive_class_label_int,
                                        zero_division=0)
                precision_class_val = precision_score(y_test_class_flat, y_pred_class_flat,
                                                      pos_label=positive_class_label_int, zero_division=0)
                try:
                    # ROC AUC and PR AUC require probability scores
                    if len(np.unique(y_test_class_flat)) > 1:
                        y_score_probs = proba_class_test[:, positive_class_idx]
                        auc_class_val = roc_auc_score(y_test_class_flat, y_score_probs)
                        pr_auc_class_val = average_precision_score(y_test_class_flat, y_score_probs)
                    else:
                        logging.warning(
                            f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å ROC AUC/PR AUC –¥–ª—è {log_context_str}: –≤ y_test_class_flat —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–ª–∞—Å—Å ({np.unique(y_test_class_flat)}).")
                        auc_class_val = "N/A (–æ–¥–∏–Ω –∫–ª–∞—Å—Å –≤ y_true)"
                        pr_auc_class_val = "N/A (–æ–¥–∏–Ω –∫–ª–∞—Å—Å –≤ y_true)"
                except Exception as e_auc:
                    logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å ROC AUC/PR AUC –¥–ª—è {log_context_str}: {e_auc}")
                    auc_class_val = "N/A (–æ—à–∏–±–∫–∞)"
                    pr_auc_class_val = "N/A (–æ—à–∏–±–∫–∞)"

                # Calculate Confusion Matrix
                try:
                    cm = confusion_matrix(y_test_class_flat, y_pred_class_flat, labels=[0, 1]) # Always use [0, 1] for CM labels if possible
                    cm_df = pd.DataFrame(cm, index=[f"True_{l}" for l in TARGET_CLASS_NAMES],
                                         columns=[f"Pred_{l}" for l in TARGET_CLASS_NAMES])
                    logging.info(f"üß† Confusion Matrix (clf_class) –¥–ª—è {log_context_str}:\n{cm_df}")
                    cm_df_str = cm_df.to_string()
                except Exception as e_cm:
                     logging.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Confusion Matrix –¥–ª—è clf_class ({log_context_str}): {e_cm}")
                     cm_df_str = "N/A (–æ—à–∏–±–∫–∞)"


            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –º–µ—Ç—Ä–∏–∫ clf_class –¥–ª—è {log_context_str}: {e}", exc_info=True)
        else:
            logging.warning(
                f"–ú–µ—Ç—Ä–∏–∫–∏ clf_class –Ω–µ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –¥–ª—è {log_context_str} (–º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏–ª–∏ y_test_class –ø—É—Å—Ç).")

        metrics_output += f"--- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è (clf_class) [{eval_metric_clf}] (proba_threshold={PREDICT_PROBA_THRESHOLD_CLASS}) ---\n"
        metrics_output += report_class_str + "\n"
        metrics_output += f"   üéØ Accuracy (class): {acc_class_val:.4f}\n" if isinstance(acc_class_val,
                                                                                        float) else f"   üéØ Accuracy (class): {acc_class_val}\n"
        metrics_output += f"   üß† F1-score (UP/1): {f1_class_val:.4f}\n" if isinstance(f1_class_val,
                                                                                      float) else f"   üß† F1-score (UP/1): {f1_class_val}\n"
        metrics_output += f"   üéØ Precision (UP/1): {precision_class_val:.4f}\n" if isinstance(precision_class_val,
                                                                                              float) else f"   üéØ Precision (UP/1): {precision_class_val}\n"
        metrics_output += f"   üü¶ ROC AUC (UP/1): {auc_class_val:.4f}\n" if isinstance(auc_class_val,
                                                                                      float) else f"   üü¶ ROC AUC (UP/1): {auc_class_val}\n"
        metrics_output += f"   üî∂ PR AUC (UP/1): {pr_auc_class_val:.4f}\n" if isinstance(pr_auc_class_val,
                                                                                       float) else f"   üî∂ PR AUC (UP/1): {pr_auc_class_val}\n"
        metrics_output += f"   üß© Confusion Matrix (clf_class):\n{cm_df_str}\n"


        # Metrics for reg_delta
        mae_delta_val = "N/A"
        if reg_delta_model and not y_test_delta.empty:
            try:
                y_pred_delta_test = reg_delta_model.predict(X_test_sel)
                mae_delta_val = mean_absolute_error(y_test_delta, y_pred_delta_test)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ MAE Delta –¥–ª—è {log_context_str}: {e}")
        else:
            logging.warning(f"MAE Delta –Ω–µ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –¥–ª—è {log_context_str} (–º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏–ª–∏ y_test_delta –ø—É—Å—Ç).")
        metrics_output += f"   üìà MAE Delta: {mae_delta_val:.6f}\n" if isinstance(mae_delta_val,
                                                                                 float) else f"   üìà MAE Delta: {mae_delta_val}\n"


        # Metrics for reg_vol
        mae_vol_val = "N/A"
        if reg_vol_model and not y_test_vol.empty:
            try:
                y_pred_vol_test = reg_vol_model.predict(X_test_sel)
                mae_vol_val = mean_absolute_error(y_test_vol, y_pred_vol_test)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ MAE Volatility –¥–ª—è {log_context_str}: {e}")
        else:
            logging.warning(f"MAE Volatility –Ω–µ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –¥–ª—è {log_context_str} (–º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏–ª–∏ y_test_vol –ø—É—Å—Ç).")
        metrics_output += f"   ‚ö° MAE Volatility: {mae_vol_val:.6f}\n" if isinstance(mae_vol_val,
                                                                                    float) else f"   ‚ö° MAE Volatility: {mae_vol_val}\n"


        # Metrics for clf_tp_hit
        if train_tp_hit_model_flag: # Check if TP-hit training was attempted
            metrics_output += "\n--- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä TP-Hit (clf_tp_hit) ---\n"
            report_tp_hit_str, acc_tp_hit_val = "N/A", "N/A"
            f1_tp_hit_val = "N/A"
            cm_tp_hit_df_str = "N/A"

            # Check if the model exists and test data is available
            if clf_tp_hit_model and y_test_tp_hit is not None and not y_test_tp_hit.empty:
                try:
                    # Ensure y_test_tp_hit is integer type for evaluation
                    y_test_tp_hit_int = y_test_tp_hit.astype(int)

                    y_pred_tp_hit_test = clf_tp_hit_model.predict(X_test_sel)
                    # Ensure predictions are in the expected format (flat list/array)
                    y_pred_tp_hit_flat = [item[0] if isinstance(item, (np.ndarray, list)) and len(item) == 1 else item
                                          for item in y_pred_tp_hit_test]

                    # Ensure targets and predictions are flat and valid (not NaN)
                    y_test_tp_hit_flat = y_test_tp_hit_int.squeeze()
                    y_pred_tp_hit_flat = pd.Series(y_pred_tp_hit_flat).squeeze().astype(int) # Ensure int type

                    # Align indices and drop any potential NaNs introduced by alignment
                    # This might not be necessary if X_test_sel index matches y_test_tp_hit index
                    # but good practice if there were any previous data manipulations.
                    # Let's assume indices align because they came from the same split.
                    # Just ensure they are series for consistent handling.


                    if not y_test_tp_hit_flat.empty and not y_pred_tp_hit_flat.empty:
                         # Check unique values for reporting
                         unique_labels_test_set_tp = set(y_test_tp_hit_flat.unique())
                         unique_labels_pred_set_tp = set(y_pred_tp_hit_flat.unique())
                         all_present_labels_set_tp = unique_labels_test_set_tp | unique_labels_pred_set_tp

                         report_labels_tp_int = [0, 1]
                         target_names_tp = ['No TP Hit (0)', 'TP Hit (1)']

                         if not all_present_labels_set_tp.issubset(set(report_labels_tp_int)):
                              logging.warning(f"–ú–µ—Ç–∫–∏ –≤ y_test/y_pred –¥–ª—è TP-hit ({all_present_labels_set_tp}) –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –æ–∂–∏–¥–∞–µ–º—ã—Ö –º–µ—Ç–∫–∞—Ö {set(report_labels_tp_int)} –¥–ª—è {log_context_str}. Classification report may fail or be incomplete.")
                              report_labels_tp_int = sorted(list(all_present_labels_set_tp))
                              target_names_tp = [f'Class_{i}' for i in report_labels_tp_int]


                         try:
                            report_tp_hit_str = classification_report(y_test_tp_hit_flat, y_pred_tp_hit_flat,
                                                                      labels=report_labels_tp_int,
                                                                      target_names=target_names_tp,
                                                                      digits=4, zero_division=0)
                         except Exception as e_report_tp:
                             logging.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ classification_report –¥–ª—è clf_tp_hit ({log_context_str}): {e_report_tp}. –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏.")
                             report_tp_hit_str = "Classification report failed."


                         acc_tp_hit_val = accuracy_score(y_test_tp_hit_flat, y_pred_tp_hit_flat)
                         # Calculate F1 for the positive class (1)
                         f1_tp_hit_val = f1_score(y_test_tp_hit_flat, y_pred_tp_hit_flat, zero_division=0, pos_label=1)

                         # Calculate Confusion Matrix
                         try:
                             cm_tp_hit = confusion_matrix(y_test_tp_hit_flat, y_pred_tp_hit_flat, labels=[0, 1]) # Always use [0, 1] for CM labels if possible
                             cm_tp_hit_df = pd.DataFrame(cm_tp_hit, index=["True_0", "True_1"], columns=["Pred_0", "Pred_1"])
                             logging.info(f"üß† Confusion Matrix (clf_tp_hit) –¥–ª—è {log_context_str}:\n{cm_tp_hit_df}")
                             cm_tp_hit_df_str = cm_tp_hit_df.to_string()
                         except Exception as e_cm_tp:
                              logging.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Confusion Matrix –¥–ª—è clf_tp_hit ({log_context_str}): {e_cm_tp}")
                              cm_tp_hit_df_str = "N/A (–æ—à–∏–±–∫–∞)"

                    else:
                        report_tp_hit_str = "N/A (–Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–µ—Ç—Ä–∏–∫)"
                        acc_tp_hit_val = "N/A (–Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)"
                        f1_tp_hit_val = "N/A (–Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)"
                        cm_tp_hit_df_str = "N/A (–Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)"
                        logging.warning(f"–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ y_test_tp_hit_flat –∏–ª–∏ y_pred_tp_hit_flat –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ TP-hit ({log_context_str}).")

                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –º–µ—Ç—Ä–∏–∫ clf_tp_hit –¥–ª—è {log_context_str}: {e}", exc_info=True)
            else:
                logging.warning(f"–ú–µ—Ç—Ä–∏–∫–∏ clf_tp_hit –Ω–µ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –¥–ª—è {log_context_str} (–º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏–ª–∏ y_test_tp_hit –ø—É—Å—Ç).")


            metrics_output += report_tp_hit_str + "\n"
            metrics_output += f"   üéØ Accuracy (TP-hit): {acc_tp_hit_val:.4f}\n" if isinstance(acc_tp_hit_val,
                                                                                              float) else f"   üéØ Accuracy (TP-hit): {acc_tp_hit_val}\n"
            metrics_output += f"   üß† F1-score (TP-hit): {f1_tp_hit_val:.4f}\n" if isinstance(f1_tp_hit_val,
                                                                                             float) else f"   üß† F1-score (TP-hit): {f1_tp_hit_val}\n"
            metrics_output += f"   üß© Confusion Matrix (clf_tp_hit):\n{cm_tp_hit_df_str}\n"


        print(metrics_output)
        # Use file_prefix for metrics log file
        log_file_path = f"logs/train_metrics_{file_prefix}.txt"
        # Append metrics if the file already exists from a previous run in the same session (e.g., group training)
        # If it's the start of the main script, it's cleared earlier.
        mode = "a" if os.path.exists(log_file_path) else "w"
        try:
            with open(log_file_path, mode, encoding="utf-8") as f_log:
                # Don't write header if appending
                # if mode == "w": f_log.write(f"=== –ù–∞—á–∞–ª–æ –ª–æ–≥–∞ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è {log_context_str} ({pd.Timestamp.now()}) ===\n")
                f_log.write(metrics_output)
                f_log.write(f"\n–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(feature_cols_final)} —à—Ç—É–∫):\n" + ", ".join(
                    feature_cols_final) + "\n\n")
            logging.info(f"–ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ª–æ–≥: {log_file_path}")
        except Exception as e_log_save:
             logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ª–æ–≥–∞ –º–µ—Ç—Ä–∏–∫ ({log_context_str}): {e_log_save}")


    logging.info(f"‚úÖ  –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è {log_context_str} –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
    if train_tp_hit_model_flag and clf_tp_hit_model:
        logging.info(f"–ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ: –¥–ª—è predict_all.py —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ predict_proba –¥–ª—è clf_tp_hit ({log_context_str}) –¥–ª—è –≥–∏–±–∫–æ—Å—Ç–∏.")


if __name__ == "__main__":
    # Define SYMBOL_GROUPS again if running directly, or rely on it being global
    # It's defined globally at the top, so this block is redundant here but harmless
    # SYMBOL_GROUPS = { ... } # Removed redundant definition

    parser = argparse.ArgumentParser(description="–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π CatBoost.")
    parser.add_argument('--tf', type=str, required=True, help="–¢–∞–π–º—Ñ—Ä–µ–π–º (1m, 5m, ...)")
    parser.add_argument('--symbol-group', type=str, help="–ü—Å–µ–≤–¥–æ–Ω–∏–º –≥—Ä—É–ø–ø—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: top8, meme)")
    # Add --symbol argument
    parser.add_argument('--symbol', type=str, default=None, help="–°–∏–º–≤–æ–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä: BTCUSDT)")
    args = parser.parse_args()

    # Determine which symbols/groups to process
    symbols_to_process = []
    if args.symbol_group:
        if args.symbol_group in SYMBOL_GROUPS:
            # If a symbol group is specified, train a single model for the group
            # The data loading logic in train_all_models already handles the group case
            # by looking for a file like features_top8_5m.pkl if symbol is set to 'top8'.
            symbols_to_process = [args.symbol_group] # Use the group name as the 'symbol' argument
            logging.info(f"üß© –û–±—É—á–µ–Ω–∏–µ –≥—Ä—É–ø–ø–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è: {args.symbol_group} ‚Üí –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª–æ–≤: {SYMBOL_GROUPS[args.symbol_group]}")
        else:
            logging.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –≥—Ä—É–ø–ø–∞: {args.symbol_group}. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {list(SYMBOL_GROUPS.keys())}")
            sys.exit(1)
    elif args.symbol:
        # If a single symbol is specified, train a model for that symbol
        symbols_to_process = [args.symbol]
        logging.info(f"üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞: {args.symbol}")
    else:
        logging.error("–ù–µ —É–∫–∞–∑–∞–Ω –Ω–∏ --symbol, –Ω–∏ --symbol-group. –£–∫–∞–∂–∏—Ç–µ –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö.")
        sys.exit(1)


    # Process each symbol/group in the list
    for current_symbol in symbols_to_process:
        # Define prefix and context for main log file for the current task
        main_log_file_prefix = f"{current_symbol}_{args.tf}" if current_symbol else args.tf
        main_log_context_str = f"—Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {args.tf}"
        if current_symbol:
            main_log_context_str += f", —Å–∏–º–≤–æ–ª–∞ {current_symbol}"

        log_file_path_main = f"logs/train_metrics_{main_log_file_prefix}.txt"

        # Clear or start the log file for this specific training task
        try:
            with open(log_file_path_main, "w", encoding="utf-8") as f_clear:
                f_clear.write(f"=== –ù–∞—á–∞–ª–æ –ª–æ–≥–∞ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è {main_log_context_str} ({pd.Timestamp.now()}) ===\n")
                f_clear.write(f"–ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ train_model.py –¥–ª—è {main_log_context_str}\n\n")
        except Exception as e:
             logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏/–æ—á–∏—Å—Ç–∫–µ –ª–æ–≥ —Ñ–∞–π–ª–∞ {log_file_path_main}: {e}")


        try:
            # Pass the current symbol (which might be a group name) and timeframe
            train_all_models(args.tf, current_symbol)
        except KeyboardInterrupt:
            print(f"\n[TrainModel] üõë –û–±—É—á–µ–Ω–∏–µ –¥–ª—è {main_log_context_str} –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
            logging.info(f"–û–±—É—á–µ–Ω–∏–µ –¥–ª—è {main_log_context_str} –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
            sys.exit(130)
        except Exception as e:
            logging.error(f"[TrainModel] üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ {main_log_context_str}: {e}", exc_info=True)
            # Continue to the next symbol/group if processing a list,
            # but if only one was specified, exit.
            if len(symbols_to_process) == 1:
                 sys.exit(1)
            else:
                 logging.warning(f"–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤/–≥—Ä—É–ø–ø –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏ –Ω–∞ {main_log_context_str}.")